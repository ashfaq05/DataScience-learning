{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What are the POS of the word 'answer' in the following sentences:\n",
    "\n",
    "Sentence 1: He was afraid to give an answer\n",
    "\n",
    "Sentence 2: He answered the question incorrectly\n",
    "\n",
    "A. Sentence 1: Verb , Sentence 2: Noun \n",
    "B. Sentence 1: Noun , Sentence 2: Verb [Correct Answer]\n",
    "\n",
    "\n",
    "Explanation: In sentence 1 answer is used as a noun to describe the solution. In sentence 2, answer is used as a verb to describe the person's action of replying to the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: With respect to POS tagging using Hidden Markov Models, which part is hidden?\n",
    "\n",
    "A. Words\n",
    "\n",
    "B. Tags [Correct Answer]\n",
    "\n",
    "Explanation:For POS tagging, HMM allows us to take into consideration observed event (words of the sentence) and hidden events(POS Tags) that we know are the causal factors in our probabilistic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Which of the following are the two methods of Parsing a tree?\n",
    "    \n",
    "A. Top-Down, Bottom-Up [Correct Answer]    \n",
    "B. East-West, West-East\n",
    "\n",
    "Explanation: Top-Down and Bottom-Up are the two approaches of Parsing a tree because they either allow words to POS tags searching(Bottom-Up) or POS tags to words searching(Top-Down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Which of the following is an optimal way of parsing for Czech language?\n",
    "    \n",
    "A. CFG parsing\n",
    "B. Dependency parsing [Correct Answer]\n",
    "\n",
    "Explanation: Dependency grammars can deal with languages that have a relatively free word order like Czech language. That's because in dependency grammar parsing, word-order information is handled in an abstract way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: The method in which we calculate the number of constituents in which the hypothesis parse has a bracketing as ((A B) C) whereas the reference parse has a bracketing as (A (B C)) is called?\n",
    "\n",
    "A. Inter-Brackets\n",
    "\n",
    "B. Cross-Brackets [Correct Answer]\n",
    "\n",
    "Explanation: The method in which we calculate the number of constituents in which the hypothesis parse has a bracketing as ((A B) C) whereas the reference parse has a bracketing as (A (B C)) is called Cross-Brackets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: PCFG is defined by the same four parameters(N,Σ, R, S) like CFG but with an update to R:\n",
    "\n",
    "A. True [Correct Answer]\n",
    "\n",
    "B. False\n",
    "\n",
    "Explanation:\n",
    "\n",
    "In CFG: R is the set of rules/productions of the form X →y[p] where\n",
    "      \n",
    "      X is a nonterminal, \n",
    "\n",
    "      y is a sequence of terminals and nonterminals (Σ∪N)∗\n",
    "\n",
    "     \n",
    "\n",
    "In PCFG: R is the set of rules/productions of the form X →y[p] where\n",
    "      \n",
    "      X is a nonterminal, \n",
    "\n",
    "      y is a sequence of terminals and nonterminals (Σ∪N)∗\n",
    "\n",
    "      p is a number between 0 and 1 expressing P(y|X)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: The method used by PARSEVAL are standard methods of Recall and Precision\n",
    "\n",
    "A. True [Correct Answer]\n",
    "\n",
    "B. False\n",
    "\n",
    "\n",
    "Explanation: \n",
    "\n",
    "The method used by PARSEVAL are standard methods of Recall and Precision:\n",
    "\n",
    "***Labeled recall (LR):*** $\\frac{\\text{No. of correct constituents in hyp. parse}}{\\text{No. of constituents in reference parse}}$ \n",
    "\n",
    "***Labeled precision (LP):*** $\\frac{\\text{No. of correct constituents in hyp. parse}}{\\text{No. of constituents in hyp. parse}}$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: The transition matrix of a Markov Model will always be a:\n",
    "\n",
    "A. Stoichastic Matrix [Correct Answer]\n",
    "\n",
    "B. Invertible Matrix\n",
    "\n",
    "C. Diagonal Matrix\n",
    "\n",
    "Explanation: Each row in a transition matrix represents all the transition probabilities from that particular i to different states j. All probabilities for a particular event must add up to 1, hence the row values of transition matrix always adds up to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Every unique word is associated with the same POS tag irrespective of the sentence.\n",
    "\n",
    "A. True \n",
    "\n",
    "B. False[Correct Answer]\n",
    "\n",
    "Explanation: POS tags are identified based on the word's usage in sentence and is not independent of the sentence.\n",
    "\n",
    "For eg, the word fish has different tags depending on the sentence:\n",
    "\n",
    "- Tuna is a type of fish\n",
    "    \n",
    "- I went to fish yesterday with my father\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Given the following weather transition matrix\n",
    "\n",
    "|-|Sunny|Cloudy|Rainy|\n",
    "|---|---|------|-----|\n",
    "|Sunny|0.6|0.25|0.15|\n",
    "|Cloudy|0.5|0.4|0.1|\n",
    "|Rainy|0.3|0.2|0.5|\n",
    "\n",
    "What is the probability of Rain today given that yesterday was Rainy and day before that was Sunny?\n",
    "\n",
    "A. 0.5 [Correct Answer]\n",
    "\n",
    "B. 0.075\n",
    "\n",
    "Explanation: We just have to calculate the probability(Rainy|Rainy) which is 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Which of the following is a flaw of 'Top-Down' parsing?\n",
    "\n",
    "A. Top-Down will never explore subtree that cannot find a place in some S-rooted tree [Correct Answer] \n",
    "\n",
    "B. In Top-Down parsing, trees which will never become S-rooted tree are generated too much.\n",
    "\n",
    "\n",
    "Explanation: It's in Bottom-Up parsing, trees which will never become S-rooted tree are generated too much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: There is a writer who likes to clear his mind by walking, running or swimming. His choice of activity depends on the weather of the given day.\n",
    "\n",
    "Following is the weather transition probability:\n",
    "        \n",
    "|-|Sunny|Rainy|\n",
    "|---|---|------|\n",
    "|Sunny|0.5|0.5|\n",
    "|Rainy|0.1|0.9|\n",
    "\n",
    "\n",
    "Following is the emission probability:\n",
    "\n",
    "|-|Walk|Run|Swim|\n",
    "|---|---|------|-----|\n",
    "|Sunny|0.6|0.15|0.25|\n",
    "|Rainy|0.5|0.45|0.05|\n",
    "\n",
    "If today is Rainy and he went for a swim, what's the probability tomorrow is Sunny and he will go for a walk?\n",
    "\n",
    "\n",
    "A. 0.06 [Correct Answer]\n",
    "\n",
    "\n",
    "B. 0.3\n",
    "\n",
    "Explanation: The probability will be P(Sunny|Rainy) * P(Swim|Sunny) which is equal to  0.06(0.1 * 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: There is a writer who likes to clear his mind by walking, running or swimming. His choice of activity depends on the weather of the given day.\n",
    "\n",
    "Following is the weather transition probability:\n",
    "        \n",
    "|-|Sunny|Rainy|\n",
    "|---|---|------|\n",
    "|Sunny|0.5|0.5|\n",
    "|Rainy|0.1|0.9|\n",
    "\n",
    "\n",
    "Following is the emission probability:\n",
    "\n",
    "|-|Walk|Run|Swim|\n",
    "|---|---|------|-----|\n",
    "|Sunny|0.6|0.15|0.25|\n",
    "|Rainy|0.5|0.45|0.05|\n",
    "\n",
    "If it was Sunny for the past two days, what's the probability that he will go for a swim today irrespective of the weather?\n",
    "\n",
    "A. 0.15 [Correct Answer]\n",
    "\n",
    "\n",
    "B. 0.125\n",
    "\n",
    "C. 0.025\n",
    "\n",
    "\n",
    "Explanation: \n",
    "\n",
    "Case 1: It's sunny today\n",
    "\n",
    "The probability will be [P(Sunny|Sunny) * P(Swim|Sunny)] = [0.5 * 0.25]= 0.125 \n",
    "\n",
    "\n",
    "Case 2: It's rainy today\n",
    "The probabolity will be [P(Rainy|Sunny) * P(Swim|Rainy)] = [0.5 * 0.05] = 0.025\n",
    "\n",
    "Adding both probabilities, we get total probability =0.125 + 0.025= 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: There is a writer who likes to clear his mind by walking, running or swimming. His choice of activity depends on the weather of the given day.\n",
    "\n",
    "Following is the weather transition probability:\n",
    "        \n",
    "|-|Sunny|Rainy|\n",
    "|---|---|------|\n",
    "|Sunny|0.5|0.5|\n",
    "|Rainy|0.1|0.9|\n",
    "\n",
    "\n",
    "Following is the emission probability:\n",
    "\n",
    "|-|Walk|Run|Swim|\n",
    "|---|---|------|-----|\n",
    "|Sunny|0.6|0.15|0.25|\n",
    "|Rainy|0.5|0.45|0.05|\n",
    "\n",
    "If it was Sunny today and he went for a run, what is the probability that for two consecutive days it will be rainy and he will go for a walk on both days \n",
    "\n",
    "A. 0.016\n",
    "\n",
    "B. 0.1125 [Correct Answer]\n",
    "\n",
    "\n",
    "Explanation: \n",
    "The probability will be P(Rainy|Sunny) * P(Walk|Rainy) * P(Rainy|Rainy) * P(Walk|Rainy) which is equal to 0.5 * 0.5 * 0.9 * 0.5 = 0.1125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Given the sentence:\n",
    "\n",
    "\"I am so not looking forward to the trip\"\n",
    "\n",
    "Which parser is most likely to correctly classify the sentiment of the sentence?\n",
    "\n",
    "A. Dependency Parser [Correct Answer]\n",
    "\n",
    "B. CFG Parser\n",
    "\n",
    "Explanation:\n",
    "\n",
    "![](images/negative.PNG)\n",
    "Its only if you know the dependency neg(looking, not) that we can classify the above example to have a negative sentiment. Without knowing this dependency we would probably classify the sentence as positive and hence Dependency parser would be more likely than a CFG parser.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: In the sentence 'I like Data', what would be the terminal symbols with respect to CFG parsing\n",
    "    \n",
    "A. ('I','like','Data') [Correct Answer]\n",
    "\n",
    "B. ('N','V','NP')\n",
    "\n",
    "\n",
    "Explanation: \n",
    "\n",
    "The symbols used in CFG are divided into two classes. \n",
    "\n",
    "Terminal Symbols: In terms of natural language modeling, these symbols are those correspond to actual words in the language (\"i\",\"like\" ,\"data\") \n",
    "\n",
    "Non Terminal Symbols: In terms of natural language modeling, these symbols are those that express abstractions over these terminals(\"NP\",\"Nominal\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
