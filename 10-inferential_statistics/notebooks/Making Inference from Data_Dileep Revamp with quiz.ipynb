{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: Introduction to Inference\n",
    "In this chapter, you will understand the fundamentals of inferential statistics and learn about basic statistical terms like sample, population, and estimation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 1.1 What is Inferential Statistics?\n",
    "\n",
    "The role of a data scientist is to answer questions on data and give insights. Think of a data scientist trying to do research on fellow data scientists. If we want to research about the Data Scientists some of the examples of research questions we would like to ask are as follows\n",
    "\n",
    " - What is the average salary of a Data Scientist?\n",
    " - What percentage of Data Scientist hold a doctorate?\n",
    " - Are data scientist paid more than data engineers?\n",
    "\n",
    "To answer the above questions accurately we will have to conduct a census and ask each and every data scientist the questions, but as you may have realized we cannot ask every person in this `population` of data scientists. Instead what we can do is pick out a random `sample` out of the population and ask these questions and `make inference` from the response received.\n",
    "\n",
    "![big picture](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b890/efe4fec7-9321-4489-84c3-e707644a3057/file.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For the above mentioned research questions, the population comprises of all the Data Scientists on planet earth. The key point here for the data scientist is decide whether **the observation on the small sample hold for the complete data or not**. For example, if a data scientist's average salary based on the sample is found to be $100,000 does it hold true for the entire population of data scientists? Inference is all about finding answers to such questions. \n",
    "\n",
    "Statistical inference is the process of making judgment about a population based on sampling properties. An important aspect of statistical inference is using estimates to approximate the value of an unknown population parameter.\n",
    "\n",
    "Let's try and understand the words \"Sample\" & \"Population\".\n",
    "First watch this video to get an overview and understand the difference between a sample and a population. \n",
    "[Population vs Sample](https://www.youtube.com/watch?v=viuSbrKlmZU). Now let us try to understand further with an example below. \n",
    "\n",
    "\n",
    "Leading up to U.S. presidential elections it could be very useful to know the political leanings of every single eligible voter, but surveying every voter is not feasible. Instead, we could poll some subset of the population, such as a thousand registered voters, and use that data to make inferences about the population as a whole.\n",
    "\n",
    "\n",
    "![paramvstats](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b-686/c65fd9cd-816e-4502-ad5a-f75dc816caf2/file.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This *\"subset\"* of the **population** is nothing but the **sample** data. We carry out various tests on the Sample to gain insight on the larger population out there! \n",
    " \n",
    "Statistical inference helps us to answer various such questions based on the samples drawn from the entire population. There are two broad areas of statistical inference that we are going to discuss in this chapter viz. **Statistical Estimation** and **Hypothesis Testing**.\n",
    "\n",
    "**Statistical Estimation**\n",
    "\n",
    "Following are some of the questions that we can answer using Statistical Estimation\n",
    " - What is the average salary of a Data Scientist in bay area?\n",
    " - What proportion of Data Scientists hold a doctorate degree?\n",
    "\n",
    "Here as you can see we are trying to find the values of population parameters based on the sample.\n",
    "\n",
    "A parameter is a descriptive measure of the population.\n",
    "    - Example: Population mean, Population variance etc.\n",
    "A statistic is a  descriptive measure of the sample.\n",
    "    - Example: Sample mean, Sample variance etc.\n",
    "\n",
    "|Population Parameter   |Sample Statistic   |  \n",
    "|---|---|\n",
    "|Population Mean -  $\\mu$  |Sample mean  - $\\bar{x}$   |\n",
    "|Population Std Dev -  $\\sigma$   |Sample Std Dev - s  |\n",
    "|Population Variance -  $\\sigma^2$  |Sample Variance -  $s^2$   |\n",
    "\n",
    "**Hypothesis Testing**\n",
    "\n",
    "Following are some of the questions that we can answer using Hypothesis Testing\n",
    " - Is the average salary of Data Scientists in Bay Area and Montreal same?\n",
    " - Is the salary of the Data Scientist and his Education independent of each other?\n",
    " - Is the average salary of Data Scientists in Montreal greater than $100k\n",
    "\n",
    "Here you can see that we are trying to answer certain questions regarding the population. Most of the times we have certain assumptions about population parameters, hypothesis testing is a way to decided whether these assumption stand true based on the data from a sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 1.1 What is Inferential statistics?\n",
    "\n",
    "Add 2 questions to make learners understand the difference between population and sample. Reference : https://lagunita.stanford.edu/courses/course-v1:OLI+ProbStat+Open_Jan2017/courseware/pd_sampling/_m1_sampling/?activate_block_id=block-v1%3AOLI%2BProbStat%2BOpen_Jan2017%2Btype%40sequential%2Bblock%40_m1_sampling\n",
    "\n",
    "1. A coach was interested in the effectiveness of a given practice program in preparing 25 football players from five different teams for a new play-memorizing system. What is the population?\n",
    "\n",
    "    a. 25 football players\n",
    "    \n",
    "    b. professional athletes\n",
    "    \n",
    "    c. all football players\n",
    "    \n",
    "    d. five different teams\n",
    "\n",
    "Ans : c\n",
    "\n",
    "Explanation :\n",
    "All football players are a part of the population and the chosen 25 players is the sample.\n",
    "\n",
    "2. A researcher was interested in the effectiveness of a given learning program in preparing 100 male college seniors from five different schools for the LSAT. What is the sample?\n",
    "\n",
    "    a. 100 college students\n",
    "    \n",
    "    b. the LSAT\n",
    "    \n",
    "    c. 100 male college seniors from five different schools \n",
    "    \n",
    "    d. five different schools\n",
    "  \n",
    "Ans : c\n",
    "\n",
    "Explanation :\n",
    "\n",
    "The total students from all the 5 colleges is the population and 100 male college seniors from five different schools are a subset that is the sample of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Statistical Estimation\n",
    "In this chapter you will learn about the Central Limit Theorem, and how to calculate point and interval estimates which are important for hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 2.1 Central Limit Theorem (CLT)\n",
    "\n",
    "Lets begin with the statement of this theorem and then explain along the way its usefulness.\n",
    "\n",
    "**Statement of CLT**\n",
    "\n",
    "The central limit theorem (CLT) is a statistical theory that states that given a sufficiently large sample size from a population with a finite level of variance, the **`mean`** of all samples from the same population will be approximately equal to the **`mean`** of the population. Furthermore, on taking multiple samples from the same population, the mean of the individual samples will form a normal distribution pattern, with all variances being approximately equal to the variance of the population divided by each sample's size.\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "Seems esoteric? Don't worry. First, let's understand the central limit through the video. \n",
    "[Central Limit Theorem](https://www.youtube.com/watch?v=YAlJCEDH2uY)\n",
    "\n",
    "Now Let's break the statement of CLT into a series of steps:\n",
    "\n",
    "\n",
    "**Simplifying CLT**\n",
    "\n",
    "- Take a random sample ( $S_1$ ) of size (n) from your data/population \n",
    "- Take the average of this sample ( $\\bar x_1$ )\n",
    "- Take another sample ( $S_2$ ) of the same size and calculate its average ( $\\bar x_2$ )\n",
    "- In this way calculate  $\\bar x_3$ ,  $\\bar x_4$ , .... etc \n",
    "- Plot all the sample averages using a histogram i.e. plot  $\\bar x_1, \\bar x_2, \\bar x_3,......, \\bar x_n$ \n",
    "\n",
    "The shape that you observe will look like a normal distribution bell curve. The image below is a pictorial representation of what the Central Limit Theorem does.\n",
    "\n",
    "\n",
    "![clt](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b528/9eb969d7-ab26-41f8-b8c4-12538020a316/file.png)\n",
    "\n",
    "\n",
    "\n",
    "**Pythonic implementation of CLT**\n",
    "\n",
    "Lets now see this theorem in action with Python with the underlying population distributions as Flat, Exponential and Beta:\n",
    "\n",
    "```python\n",
    "# provides capability to define function with partial arguments\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "N = 1000 # number of times n samples are taken. Try varying this number.\n",
    "nobb = 101 # number of bin boundaries on plots\n",
    "n = np.array([1,2,3,5,10,100,200]) # number of samples to average over\n",
    "\n",
    "exp_mean = 3 # mean of exponential distribution\n",
    "a,b = 0.7,0.5 # parameters of beta distribution\n",
    "\n",
    "dist = [partial(np.random.random),partial(np.random.exponential,exp_mean),partial(np.random.beta,a,b)]\n",
    "title_names = [\"Flat\", \"Exponential (mean=%.1f)\" % exp_mean, \"Beta (a=%.1f, b=%.1f)\" % (a,b)]\n",
    "drange = np.array([[0,1],[0,10],[0,1]]) # ranges of distributions\n",
    "means = np.array([0.5,exp_mean,a/(a+b)]) # means of distributions\n",
    "var = np.array([1/12,exp_mean**2,a*b/((a+b+1)*(a+b)**2)]) # variances of distributions\n",
    "\n",
    "binrange = np.array([np.linspace(p,q,nobb) for p,q in drange])\n",
    "ln,ld = len(n),len(dist)\n",
    "plt.figure(figsize=((ld*4)+1,(ln*2)+1))\n",
    "\n",
    "for i in range(ln): # loop over number of n samples to average over\n",
    "    for j in range(ld): # loop over the different distributions\n",
    "        plt.subplot(ln,ld,i*ld+1+j)\n",
    "        plt.hist(np.mean(dist[j]((N,n[i])),1),binrange[j],normed=True)\n",
    "        plt.xlim(drange[j])\n",
    "        if j==0:\n",
    "            plt.ylabel('n=%i' % n[i],fontsize=15)        \n",
    "        if i==0:\n",
    "            plt.title(title_names[j], fontsize=15)\n",
    "        else:\n",
    "            clt=(1/(np.sqrt(2*np.pi*var[j]/n[i])))*np.exp(-(((binrange[j]-means[j])**2)*n[i]/(2*var[j])))\n",
    "            plt.plot(binrange[j],clt,'y',linewidth=2)     \n",
    "plt.show()\n",
    "```\n",
    "\n",
    "The output of the above code snippet is the image below. You can clearly observe that as the sample size ($n$) increases, the distribution of the sample means approaches a more normal curve, irrespective of the underlying distribution\n",
    "\n",
    "\n",
    "![cltpython](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b-617/c9da86b2-0ddc-4fbc-9ef6-6d16eacfc3bb/file.png)\n",
    "\n",
    "\n",
    "**Important pointers** \n",
    " \n",
    "- Mean of a sample of data will be closer to the mean of the overall population in question as the sample size increases, notwithstanding the actual distribution of the data, and whether it is normal or non-normal.\n",
    "- Sample sizes equal to or greater than 30 are considered sufficient for this theorem to hold, meaning the distribution of the sample means is fairly normally distributed.\n",
    "\n",
    "\n",
    "**Applications of Central Limit Theorem**\n",
    "\n",
    "Perhaps one of the most misunderstood things in statistics is the **Central Limit Theorem**. The central limit theorem can be used to help evaluate data from various distribution patterns. **Using this theorem we can apply statistical methods that would otherwise only apply to normal distributions of data**.\n",
    "\n",
    "The first question that comes to the mind is: **Okay, I have bell curve now, who cares?** \n",
    "\n",
    "Once you have a normal bell curve, I now know something very powerful. Known as the 68,95,99 rule, I know that 68% of my sample is going to be within one standard deviation of the mean. 95% will be within 2 standard deviations and 99.7% within 3. It can then be used to calculate something called a **p-value** which will helps us in making inferences and forms the final step in hypothesis testing.\n",
    "\n",
    "\n",
    "![sigma](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b715/eaddfd29-00e5-4eaa-b001-2dc8087f26a7/file.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2.1\n",
    "\n",
    "One simple question to test their application of central limit theorem...\n",
    "Like... There is a distribution that is a mixture of two exponential distributions. If you sample the means from this distribution, what distribution would the means have? \n",
    "\n",
    "1. The mean is 200 and standard deviation is 24 of a population. Sample size is 30. What is the mean of sampling distribution?\n",
    "    \n",
    "    a. 24\n",
    "    \n",
    "    b. 200\n",
    "    \n",
    "    c. 30\n",
    "    \n",
    "    d. None of the above\n",
    "    \n",
    "Ans : b\n",
    "\n",
    "Explanation : The central limit theorem states that the mean of the sampling distribution of the mean\n",
    "is the mean of the population from which the scores were sampled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 2.3 Variance and Degrees of Freedom\n",
    "\n",
    "**Estimates first!**\n",
    "\n",
    "Recall that standard deviation for population is denoted by  $\\sigma$  while the sample standard deviation is given by  $s = \\frac{\\sigma}{\\sqrt {n}}$ . This sample standard deviation s is said to be an estimate of the population standard deviation  $\\sigma$  and can be used as a substitute for the same in case we don't know  $\\sigma$ . You will learn more about **estimates** in the next topic. Similarly the sample mean ( $\\bar x$ ) can be considered as an estimate of the population mean ( $\\mu$ ).\n",
    "\n",
    "\n",
    "**What is degree of freedom and how is it related to estimates?**\n",
    "\n",
    "Some estimates are based on more information than others. For example, an estimate of the variance based on a sample size of  $200$  is based on more information than an estimate of the variance based on a sample size of  $10$ . The concept of degrees of freedom is central to the principle of estimating statistics of populations from samples of them. Degrees of freedom is commonly abbreviated to `df`. \n",
    "\n",
    "You can think of `df` as a mathematical restriction that needs to be put in place when estimating one statistic from an estimate of another. **The degrees of freedom (`df`) of an estimate is the number of independent pieces of information on which the estimate is based**.\n",
    "\n",
    "\n",
    "**Examples calculating degree of freedom**\n",
    "\n",
    "As an example, let's say that you know that the mean height of all the employees at your company is 6 feet and wish to estimate the variance of their heights. Lets consider separate instances and look at the outcomes:\n",
    "\n",
    "- **Case I**: We randomly sample one employee out of all and find that the employee's height is 8 feet. Recall that the variance is defined as the mean squared deviation of the values from their population mean. We can compute the squared deviation of our value of 8 from the population mean of 6 to find a single squared deviation from the mean. This single squared deviation from the mean,   $(8-6)^2 = 4$  , is an estimate of the mean squared deviation for all the employees. Therefore, based on this sample of one, we would estimate that the population variance is 4. \n",
    "\n",
    "  **Since this estimate is based on a single piece of information, therefore it has 1 `df`**. If we sampled another employee and obtained a height of 5 feet, then we could compute a second estimate of the variance,  $(5-6)^2 = 1$ . We could then average our two estimates (4 and 1) to obtain an estimate of 2.5. **Since this estimate is based on two independent pieces of information, it has two degrees of freedom**. \n",
    "  \n",
    "  *NOTE*: **The two estimates are independent because they are based on two independently and randomly selected employees**.\n",
    "\n",
    "- **Case II**: Usually it is pretty rare that we know the population mean when we are estimating the variance. Instead, we have to first estimate the population mean ( $\\mu$ ) with the sample mean ( $\\bar x$ ). The process of estimating the mean affects our degrees of freedom as described below.\n",
    "\n",
    "  Returning to your problem of estimating the variance in the employee heights, let's assume you do not know the population mean ( $\\mu$ ) and therefore we have to estimate it from the sample mean ( $\\bar x$ ). You have sampled two employees and found that their heights are 8 and 5. Therefore $\\bar x$ , your estimate of the population mean, is  $\\bar x = (8+5)/2 = 6.5$ .\n",
    "\n",
    "  You can now compute two estimates of variance:\n",
    "\n",
    "  $$\\text{Estimate 1} = (8-6.5)^2 = 2.25$$\n",
    "  \n",
    "  $$\\text{Estimate 2} = (5-6.5)^2 = 2.25$$\n",
    "\n",
    "  **Are these two estimates independent?** The answer is **`NO`** because each height contributed to the calculation of  $\\bar x$ . Since the first employee's height of 8 influenced  $\\bar x$ , it also influenced Estimate 2. If the first height had been, for example, 10, then  $\\bar x$  would have been 7.5 and Estimate 2 would have been  $(5-7.5)^2 = 6.25$  instead of 2.25. \n",
    "  \n",
    "  The important point is that the two estimates are not independent and therefore we do not have two degrees of freedom. Another way to think about the non-independence is to consider that if you knew the mean and one of the scores, you would know the other score. For example, if one score is 5 and the mean is 6.5, you can compute that the total of the two scores is 13 and therefore that the other score must be  $13-5 = 8$ .\n",
    "\n",
    "\n",
    "**In general, the degrees of freedom for an estimate is equal to the number of values minus the number of parameters estimated en route to the estimate in question**. In the employees example, there are two values (8 and 5) and we had to estimate one parameter ( $\\mu$ ) on the way to estimating the parameter of interest ( $\\sigma$ ). Therefore, the estimate of variance has  $2 - 1 = 1$  degree of freedom. If we had sampled 12 employees instead, then our estimate of variance would have had 11 degrees of freedom. Therefore, the degrees of freedom of an estimate of variance is equal to $n-1$ , where n is the number of observations.\n",
    "\n",
    "And this is the reason why the denominator while calculating sample variance is  $n-1$  instead of n so that it provides an unbiased estimator. \n",
    "\n",
    "$$s^2 = \\frac{\\sum (x_i - \\bar x)^2}{n - 1}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2.3 \n",
    "\n",
    "#### Quiz : Varuance and degrees of freedom\n",
    "\n",
    "Put across a question on degrees of freedom. One or two questions that will clarify what degrees of freedom are.\n",
    "\n",
    "1. What is the best definition of degrees of freedom?\n",
    "\n",
    "    a. A mathematical formula used to figure triangle measurements.\n",
    "    \n",
    "    b. how many values involved in our calculations do not vary\n",
    "    \n",
    "    c. a number that can help us compare triangles\n",
    "    \n",
    "    d. number of values involved in our calculation have freedom to vary\n",
    "\n",
    "Ans : d\n",
    "\n",
    "Explanation : \n",
    "\n",
    "The degrees of freedom (df) of an estimate is the number of independent pieces of information on which the estimate is based.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 2.4 Point Estimates\n",
    "\n",
    "In the previous topic you came across the term **estimates**. They are approximations of a statistic as a parameter when the actual value of the parameter is unknown. Now lets learn about the first type of estimates i.e. point estimates.\n",
    "\n",
    "\n",
    "**What is point estimate**?\n",
    "\n",
    "In point estimation, we estimate an unknown parameter using a single number that is calculated from the sample data. Here, a single value estimates the population parameter. The sample mean ( $\\bar x$ ) can be considered as a point estimate of the population mean ( $\\sigma$ ). Lets take a more concrete example to understand point estimation. \n",
    "\n",
    "\n",
    "**Example of point estimate**\n",
    "\n",
    "Consider the following situation: \n",
    "\n",
    "`Suppose that we are interested in studying the IQ levels of students at State University (SU). In particular (since IQ level is a quantitative variable), we are interested in estimating μ, the mean IQ level of all the students at SU.`\n",
    "\n",
    "`A random sample of 100 SU students was chosen, and their (sample) mean IQ level was found to be 115.\n",
    "If we wanted to estimate μ, the population mean IQ level, by a single number based on the sample, it would make intuitive sense to use the corresponding quantity in the sample, the sample mean . We say that 115 is the point estimate for μ, and in general, we'll always use  as the point estimator for μ. (Note that when we talk about the specific value (115), we use the term estimate, and when we talk in general about the statistic , we use the term estimator. The following figure summarizes this example:`\n",
    "\n",
    "\n",
    "![point](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b-389/17426fe7-1c5a-44b8-99e1-ed526ff3e717/file.gif)\n",
    "\n",
    "Let us walk through another example of point estimation in the video: [Point Estimators](https://www.youtube.com/watch?v=4v41z3HwLaM)\n",
    "\n",
    "\n",
    "**Intuitive explaination of point estimate**\n",
    "\n",
    "You may feel that since it is so intuitive, you could have figured out point estimation on your own as our intuition tells us that the best estimator for  $\\mu$  should be  $\\bar x$ .  \n",
    "\n",
    "Probability theory does more than this; it actually gives an explanation why  $\\bar x$  is a good choice as point estimator for  $\\mu$ . You already know from the section on **Central Limit Theorem** that as long as a sample is taken at random, the distribution of sample means is exactly centered at the value of population mean. \n",
    "\n",
    " $\\bar x$  is therefore said to be an unbiased estimator for  $\\mu$ . Any particular sample mean ( $\\bar x_i$ ) might turn out to be less than the actual population mean ( $\\mu$ ), or it might turn out to be more. But in the long run, such sample means are *on target* in that they will not underestimate any more or less often than they overestimate. Hence  $\\bar x$  can be considered as what we term as an unbiased estimator of the population mean  $\\mu$  under the condition that the samples are drawn at random.\n",
    "\n",
    "\n",
    "![mean](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b774/c37613c6-9a31-4ccc-9e31-3b3049ac9fbe/file.gif)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz: \n",
    "2 numerical problems on point estimates. Use this as reference https://lagunita.stanford.edu/courses/course-v1:OLI+ProbStat+Open_Jan2017/courseware/_u5_inference/_m1_estimation/?child=last\n",
    "\n",
    "\n",
    "#### Quiz : Point Estimates\n",
    "\n",
    "1. Suppose we want to select a random sample of size 5 from a batch of current students of a class. Which of the following strategies is the best:\n",
    "\n",
    "    a. Pick 5 students from the first row.\n",
    "    \n",
    "    b. Pick 5 of your friends from the class.\n",
    "    \n",
    "    c. Assign a number to each student in the class and use a random number generator to pick 5students.\n",
    "    \n",
    "    d. Post a note on eLearning and get the first 5 students who respond.\n",
    "    \n",
    "Ans : c\n",
    "\n",
    "Explanation :\n",
    "\n",
    "Strategy (c) is the best as this is the only strategy that ensures that each possible sample of 5students is equally likely to be selected. The other strategies lead to ”convenience” samples.\n",
    "\n",
    "\n",
    "2. There are 100 students in a batch. Suppose the following data shows the number of the problems from the Practice Problems Set attempted in the past week by 6 randomly selected students:\n",
    "\n",
    "                                            4, 5, 8, 9, 10, 6\n",
    "                                            \n",
    "What is the mean number of problems solved by this sample of students?\n",
    "\n",
    "    a. 42\n",
    "    \n",
    "    b. 7\n",
    "    \n",
    "    c. 8.4\n",
    "    \n",
    "    d. none of the above\n",
    "    \n",
    "Ans : b\n",
    "\n",
    "Explanation : \n",
    "\n",
    "Our sample contains 6 students so we will add the problems solved by each student and divide it by 6 \n",
    "\n",
    "$\\frac{4 + 5 + 8 + 9 + 10 + 6}{6} = \\frac{42}{6} = 7$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 2.5 Interval Estimates\n",
    "\n",
    "**Problem with point estimates alone**\n",
    "\n",
    "In the previous topic you learnt about point estimation where you estimate a population parameter ( $\\sigma$ ) with the sample statistic ( $\\bar x$ ) . But this is a bit problematic. Why? When we estimate, say,  $\\mu$  by the sample mean ( $\\bar x$ ) , we are almost guaranteed to make some kind of error. Even though we know that the values of  fall around  $\\mu$  , it is very unlikely that the value of  will fall exactly at  $\\mu$  .\n",
    "\n",
    "**Interval estimation to the rescue**\n",
    "\n",
    "In point estimation we used  $\\bar x$  as the point estimate for  $\\mu$ . However, we had no idea of what the estimation error involved in such an estimation might be. Interval estimation takes point estimation a step further and says something like we are 95% sure that  $\\bar x$ lies between  $X_1$ and $X_2$ . \n",
    "\n",
    "\n",
    "\n",
    "Now lets understand interval estimation in context of our previous example:\n",
    "\n",
    "\n",
    "![point](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b80/84137b6c-00f1-425c-86e9-46f8da7184bf/file.gif)\n",
    "\n",
    "\n",
    "Lets say that you are 95% confident that by using the point estimate  $\\bar x$  to estimate  $\\mu$  , you are off by no more than 3 IQ points. In other words, you are 95% confident that  $\\mu$  is within 3 of 115 , or between 112 (115 - 3) and 118 (115 + 3) .\n",
    "\n",
    "**Construction and Interpretation of the confidence interval**\n",
    "\n",
    "Let us understand confidence intervals with the help of the video: [Confidence Intervals](https://www.youtube.com/watch?v=TqOeMYtOc1w)\n",
    "\n",
    "Lets also assume that you know the population standard deviation  $\\sigma$ , which is 15. The problem now looks somewhat like this: \n",
    "\n",
    "\n",
    "![interpretation](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b131/f8fcc3ec-0e67-4c8d-97ed-d170e824e132/file.gif)\n",
    "\n",
    "\n",
    "\n",
    "- You already know that according to the **Central Limit Theorem**, the sampling distribution of the sample mean  is approximately normal with a mean of $\\mu$ and standard deviation of  $\\frac{\\sigma}{n}$  where n is the sample size. In our example, the possible values of  $\\bar x$ , the sample mean IQ level of 100 randomly chosen students, is approximately normal, with mean  $\\mu$  and standard deviation  $\\frac{15}{\\sqrt{100}} = 1.5$ .\n",
    "\n",
    "- Next, apply the Standard Deviation Rule for the normal distribution. **We are considering a 95% confidence level which means that we are 95% sure that the sample mean ( $\\bar x$ ) falls within this interval**. The `z-value` corresponding to 95 is 2 (from the normal distribution curve). So, there is a 95% chance that the sample mean we get in our sample falls within  $2 * 1.5 = 3$  units of $\\mu$ .\n",
    "\n",
    "\n",
    "![explain](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b232/85d3b86f-f72a-4bb9-b866-692111c6187b/file.gif)\n",
    "\n",
    "\n",
    "\n",
    "- Finally you can say that there is a 95% chance that the sample mean  $\\bar x$  falls within 3 units of  $\\mu$  or You are 95% confident that the population mean  $\\mu$  falls within 3 units of $\\bar x$ .\n",
    "\n",
    "**Other Confidence Levels calculation**\n",
    "\n",
    "Now lets calculate the confidence levels with other confidence levels. Their calculations are shown below:\n",
    "\n",
    "- 90% confidence interval for  $\\mu$  is $$\\bar x \\pm 1.645\\frac{\\sigma}{\\sqrt{n}} = 115 \\pm 1.645 \\frac{15}{\\sqrt{100}} = 115 \\pm 2.5 = (112.5, 117.5)$$ .\n",
    "\n",
    "- 95% confidence interval for  $\\mu$  is $\\mu$ is $$\\bar x \\pm 2\\frac{\\sigma}{\\sqrt{n}} = 115 \\pm 2 \\frac{15}{\\sqrt{100}} = 115 \\pm 3 = (112, 118)$$ .\n",
    "\n",
    "- 99% confidence interval for  $\\mu$  is $\\mu$ is $$\\bar x \\pm 2.576\\frac{\\sigma}{\\sqrt{n}} = 115 \\pm 2.576 \\frac{15}{\\sqrt{100}} = 115 \\pm 4 = (111, 119)$$ .\n",
    "\n",
    "**General structure of confidence interval calculation**\n",
    "\n",
    "In general, the confidence interval has the form: $\\bar x \\pm z^\\star\\frac{\\sigma}{\\sqrt{n}}$ where:\n",
    "\n",
    "- $z^\\star$ is a general notation for the multiplier that depends on the level of confidence. As we discussed before:\n",
    "\n",
    "    For a 90% level of confidence, $z^\\star$ = $1.645$\n",
    "\n",
    "    For a 95% level of confidence, $z^\\star$ = $2$ (or $1.96$ if you want to be really precise)\n",
    "\n",
    "    For a 99% level of confidence, $z^\\star$ = $2.576$\n",
    "\n",
    "\n",
    "![img](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b473/9e94fb6a-0898-4b75-b6a7-48ce6dedc594/file.gif)\n",
    "\n",
    "\n",
    "**When is it safe to use the confidence interval you developed?**\n",
    "\n",
    "Now you have learnt everything that you need in order to calculate the confidence intervals. Time to learn when you can actually use it to calculate confidence intervals. Lets look at them:\n",
    "- Firstly, sample must be random and not biased\n",
    "- Assuming that the sample is random, recall that the Central Limit Theorem works when the sample size is large (a common rule of thumb for *large* is $n > 30$), or, for smaller sample sizes, if it is known that the quantitative variable of interest is distributed *normally* in the population.\n",
    "- The only situation in which we cannot use the confidence interval, is when the sample size is small and the variable of interest is not known to have a normal distribution. \n",
    "\n",
    "In the upcoming task you will be calculating the confidence interval for the `SalePrice` feature of the Iowa Housing dataset. The `SalePrice` feature has values something like these: \n",
    "```python\n",
    "[208500, 181500, 223500, 140000, 250000, 143000, 307000, 200000, 129900, 118000, 129500, 345000, 144000, 279500, 157000, 132000, 149000,  90000, 159000, 139000, 325300, 139400, 230000, 129900, 154000, 256300, 134800, 306000, 207500,  68500,  40000, 149350, 179900, 165500, 277500, 309000, 145000, 153000, 109000, 82000, 160000, 170000, 144000, 130250, 141000, 319900, 239686, 249700, 113000, 127000, 177000, 114500, 110000, 385000, 130000, 180500, 172500, 196500, 438780, 124900, 158000, 101000, 202500, 140000, 219500, 317000, 180000, 226000,  80000, 225000, 244000, 129500, 185000, 144900, 107400,  91000, 135750, 127000, 136500, 110000, 193500, 153500, 245000, 126500, 168500, 260000, 174000, 164500, 85000, 123600, 109900,  98600, 163500, 133900, 204750, 185000, 214000,  94750,  83000, 128950, ......]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz\n",
    "\n",
    "2 word problems on confidence intervals.\n",
    "\n",
    "#### Quiz : Interval Estimates\n",
    "\n",
    "1. A sample of sizen= 100 produced the sample mean of ̄x = 16.  Assuming thepopulation standard deviation σ= 3, compute a 95% confidence interval for the population mean μ. Click [here](http://www.z-table.com/) for Z-table.\n",
    "\n",
    "    a. 14-18\n",
    "    \n",
    "    b. 15-17\n",
    "    \n",
    "    c. 15.112 - 16.888\n",
    "    \n",
    "    d. 15.412-16.588\n",
    "\n",
    "Ans : d\n",
    "\n",
    "Explanation : \n",
    "\n",
    "A 95% confidence interval for μ is\n",
    "\n",
    "̄$\\bar x \\pm z^\\star\\frac{\\sigma}{\\sqrt{n}}$ \n",
    "\n",
    "where z = 1.96from the table of Normal distribution.Then, the 95% confidence interval for μ is 16 ± ((1.96)3/√100)= 16 ± 0.588 = [15.412,16.588]\n",
    "\n",
    "2. A random sample of 30 households was selected as part of a study on electricity usage, and the number of kilowatt-hours (kWh) was recorded for each household in the sample for the March quarter of 2006. The average usage was found to be 375kWh. In a very large study in the March quarter of the previous year it was found that the standard deviation of the usage was 81kWh. Assuming the standard deviation is unchanged and that the usage is normally distributed, provide an expression for calculating a 99% confidence interval for the mean usage in the March quarter of 2006. Exactly one option must be correct). Z score for 0.99 is 2.575.\n",
    "\n",
    "    a. 375 ± 2.756 × $\\frac{81}{\\sqrt{30}}$ \n",
    "    \n",
    "    b. 375 ± 2.575 × $\\frac{81}{\\sqrt{30}}$\n",
    "    \n",
    "    c. 375 ± 2.575 × $\\frac{9}{\\sqrt{30}}$\n",
    "    \n",
    "    d. 456 ± 2.756 × $\\frac{81}{\\sqrt{30}}$\n",
    "    \n",
    "Ans : b\n",
    "\n",
    "Explanation : \n",
    "\n",
    "The formula to calculate confidence interval is \n",
    "\n",
    "̄$\\bar x \\pm z^\\star\\frac{\\sigma}{\\sqrt{n}}$ \n",
    "\n",
    "we know z = 2.575 as well as the  other values. Substitute the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: Test of Hypothesis\n",
    "In this chapter you will learn about how to perform hypothesis testing on data and also understand the errors you can encounter while testing  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 3.1 What is hypothesis?\n",
    "In the previous chapter we learnt about statistical methods of estimation where we estimated the population parameters using the data from sample. We were trying to answer the question like, 'What is the average salary of Data Scientist in Bay Area and Montreal?'. In this section we will be answering slightly different questions like 'Is the average salary of Data Scientist in Bay Area and Montreal different?'.\n",
    "\n",
    "If you closely look at the two questions stated above there is a clear distinction, in the first question we are trying to find a value for the population mean, whereas in the second we have certain assumption about the population average and we just want to answer whether this assumption is correct or not.\n",
    "\n",
    "Let us now take a closer look into understanding what exactly a hypothesis is and a brief about the process of conduction a hypothesis test.\n",
    "\n",
    "**Null Hypothesis and Alternate Hypothesis**\n",
    "\n",
    "Before we take a deep dive, let's understand the differences between null hypothesis and alternative hypothesis through the video - [Null and Alternative Hypothesis](https://www.youtube.com/watch?v=WtdiMUwWX0k). \n",
    "\n",
    "**Hypothesis** is a statement about the population that might be true.The beauty of these Hypotheses are that they can be TESTED! \n",
    "\n",
    "Example: We have a hypothesis that the 'the average salary of the Data Scientists in Bay Area and Montreal is different'.\n",
    "\n",
    "Statistical hypothesis tests are based a statement called the null hypothesis that assumes nothing interesting is going on between whatever variables you are testing. \n",
    " \n",
    "Therefore, in our case the Null Hypothesis is that 'The average salary of Data Scientsts in Bay Area and Montreal is **same**'\n",
    "\n",
    " - The purpose of a hypothesis test is to determine whether the null hypothesis is likely to be true given sample data.\n",
    " - If there is little evidence against the null hypothesis given the data, you accept the null hypothesis.\n",
    " - If the null hypothesis is unlikely given the data, you might reject the null in favor of the alternative hypothesis: that something interesting is going on.\n",
    " \n",
    "**Alternate Hypothesis**\n",
    "This is nothing but the question you ask which kind of \"opposes\" the Null Hypothesis. Therefore, in our case the Alternative Hypothesis is that: \"The average salary of Data Scientists in Bay Area and Montreal **is different**\"\n",
    "     \n",
    "Only 1 Hypothesis out of Null and Alernate can be right. In hypothesis testing we test a sample, with the goal of accepting or rejecting a null hypothesis which is our assumption or the default position. The test tells us whether or not our primary hypothesis is true.\n",
    "\n",
    "**Important: The null hypothesis is assumed true and statistical evidence is required to reject it in favor of an alternative hypothesis.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz\n",
    "\n",
    "Put 2 questions asking the learners to frame what is the null hypothesis and what the alternate hypothesis is. \n",
    "\n",
    "### Quiz : What is hypothesis testing?\n",
    "\n",
    "1. A researcher believes that the average cost of college textbooks is 180 . She samples 30 textbooks and calculates the mean of the sample, X, to be 205. What is the null hypothesis in this situation?\n",
    "\n",
    "    a. The average cost of college textbooks is 180?.\n",
    "    \n",
    "    b. The average cost of college textbooks is not 180?.\n",
    "    \n",
    "    c. None of the above\n",
    "    \n",
    "Ans : b\n",
    "\n",
    "Explanation :\n",
    "\n",
    "Null hypothesis is the opposite of the question you are asking.\n",
    "\n",
    "2. A tyre manufacturer believes that an experiment with the tyres has increased the average life of tyres by 25%. What is the alternate hypothesis in this case?\n",
    "\n",
    "    a. The average life of tyres increased by 25%?.\n",
    "    \n",
    "    b. The average life of tyres did not increase by 25%?.\n",
    "    \n",
    "    c. None of the above\n",
    "    \n",
    "Ans : a\n",
    "\n",
    "Explanation : \n",
    "\n",
    "Alternate Hypothesis is nothing but the question you are asking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 3.2 Process of Hypothesis Testing\n",
    "\n",
    "First let's watch a video that would introduce hypothesis testing in general - [Introduction to Hypothesis Testing](https://www.youtube.com/watch?v=DlwOTOydeyk).\n",
    "\n",
    "Let us understand the process involved in Hypothesis testing with a simple example in this video - [An example walkthrough for Hypothesis Testing](https://www.youtube.com/watch?v=pfrZYfcfJEA). Now let's try to work through another example to understand the process better. \n",
    "\n",
    ">A company uses a semi-automatic process to fill coffee powder in 200 gm jars and this fill is known to have a\n",
    "standard deviation of 4 gm. For long, the amount of coffee powder filled is observed to be normally distributed\n",
    "with a mean of 200 gm. The manager is concerned with ensuring that the process is working satisfactorily so\n",
    "that the average amount of coffee powder filled in jars is 200 gm. She has currently taken sample of 25 jars,\n",
    "weighs the amount of coffee in each of them and finds the average amount equal to 202 gm. Now, her problem\n",
    "is as to how this difference of 2 gm be interpreted. Is it a small difference and may be ignored or is it large\n",
    "enough to conclude that the process is not working properly and some action is warranted.\n",
    "\n",
    "We will break down this example into four broad steps and delve with them in detail one by one.\n",
    "\n",
    "### 1. State the Hypothesis\n",
    "In this example we are concerned about the average amount of coffee powder that is being filled by the machine in the jars. As discussed in the previous topic, null hypothesis is that which assumes nothing interesting is going on i.e. in our case we can state our null hypothesis that 'the machine is filling 200gms of coffee on an average'. To put more details what we are assuming is that for the entire population of the bottles filled by the machine the average amount is 200 gms. We represent it as follows\n",
    "\n",
    "** $H_0$ : The machine is filling 200gms of coffee on an average or $\\mu = 200$ **\n",
    "\n",
    "The alternate or opposing hypothesis to this is that the machine is not filling 200gms of coffee on an average. This can be represented as \n",
    "\n",
    "** $H_1$ : The machine is not filling 200gms of coffee on an average or $\\mu \\neq 200$ **\n",
    "\n",
    "Note that we are concerned about the average amount of coffee filled by the machine and not with each and every individual bottle.\n",
    "\n",
    "This completes out first step where based on the problem statement we have stated our hypothesis.\n",
    "\n",
    "### 2. Formulate the plan for analysis\n",
    "Based on the hypothesis that we have stated in the previous step now we need to determine a plan to make our decision. \n",
    "\n",
    "The first thing that we need to determine is the test statistic that we will be calculating for our data. We can determine this test statistic based on what population parameter we are testing. In our example we want to check the **average** amount of coffee filled by the machine. For such cases we use a `z-statistic` calculated as follows\n",
    "\n",
    "$$z = \\frac{\\bar{x} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}$$\n",
    "where\n",
    "\n",
    " $\\bar{x} - sample \\ mean$ \n",
    "\n",
    " $\\mu - population \\ mean$ \n",
    "\n",
    " $\\sigma - population \\ standard \\ deviation$ \n",
    "\n",
    " $n - sample \\ size$ \n",
    "\n",
    "We will take a look at different types of test statistics is later topics.\n",
    "\n",
    "### 3. Analyze sample data\n",
    "Now that we have decided upon which test statistic to use, we need to calculate the value for the same based on the information that we have regarding the sample and the population. From the example given above we can clearly write the information as follows\n",
    "\n",
    " $population \\ mean = \\mu = 200gms$ \n",
    "\n",
    " $population \\ standard \\ deviation = \\sigma = 4gms$ \n",
    "\n",
    " $sample \\ size = n = 25$ \n",
    "\n",
    " $sample \\ mean = \\bar{x} = 202gms$ \n",
    "\n",
    "Here we have all the information that we need to caluculate our test statistic.\n",
    "$$z = \\frac{\\bar{x} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}} =\\frac{202 - 200}{\\frac{4}{\\sqrt{25}}}  = 2.5$$\n",
    ". \n",
    "### 4. Interpreting the result\n",
    "This is one of the most critical steps in hypothesis testing. Based on the test statistic that we have calculate in the previous step we need to make a decision regarding our hypothesis. As stated in the earlier topic we are looking for an evidence to reject the null hypothesis. In this step we will be calculating a`p-value` based on which we will be interpreting the result.\n",
    "\n",
    "Now `p-value` is quite misunderstood by a lot of people. Before proceeding further, let's go through a video explaining it through a simple example - [p-values made easy](https://www.youtube.com/watch?v=9jW9G8MO4PQ).\n",
    "With the intuitive understanding in the background, let's do a more technical deep dive - [p-values clearly explained](https://www.youtube.com/watch?v=5Z9OIYA8He8). \n",
    "\n",
    "\n",
    "The `p-value`, or calculated probability, is the probability of finding the observed, or more extreme, results when the null hypothesis ( $H_0$ ) of a study question is true – the definition of ‘extreme’ depends on how the hypothesis is being tested.\n",
    "\n",
    "In our example `p-value` is the probability of finding the average coffee filled to be 202 grams when the null hypothesis is correct. \n",
    "\n",
    "So, if `p-value` is very small then we can safely say the there is a **strong evidence against** the null hypothesis whereas on the flipside if `p-value` is large we can say that there is **weak evidence against** the null hypothesis.\n",
    "\n",
    "Now the question is how do we calculate this `p-value`. From the central limit theorem we are aware from the Cental Limit Theorem that the sampling distribution of sample means is normally distributed. As we are dealing with samples in this case, we can use a normal distribution to calculate the `p-value`.\n",
    "\n",
    "In our example we can calculate the `p-value` as follows\n",
    "\n",
    " $p-value = P(z \\geq 2.5) = 0.0062$  (remmember the calculation from probability)\n",
    "\n",
    "Now we know that the probability of finding a average of 202 grams is 0.0062 when the null hypothesis is true. As you can observe this is a very small probability, but we need some threshold to define what probability is small or big. This threshold is called as significance level. \n",
    "\n",
    "The choice of significance level at which you reject H0 is arbitrary. Conventionally the 5% (less than 1 in 20 chance of being wrong), 1% and 0.1% (p < 0.05, 0.01 and 0.001) levels have been used.\n",
    "\n",
    "Now for our example we select level of significance of 5% i.e. 0.05. As our calculated p-value is less than the threshold we can say that there is strong evidence against the Null Hypothesis and hence we reject the null hypothesis in favour of alternate hypothesis\n",
    "\n",
    "**Conclusion: From out test of hypothesis we can say that the average amount of coffee filled by the machine is significantly different that 200 grams and hence some action is warranted**\n",
    "\n",
    "Now as you are well versed with the process of hypothesis testing we will apply the test to some of our hypothesis to the housing dataset in the next topic. We will use the python library of `statsmodels` to perform this testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz\n",
    "\n",
    "2 problems on hypothesis testing\n",
    "\n",
    "1. A principal at a certain school claims that the student in his school are above average intelligence. A random sample of 36 students IQ score has a mean score of 112. Is there sufficient evidence to support the principal's claim? The mean population IQ is 100 with a standard deviation of 15. IQ scores are normally distributed. p-value is 0.05. Click [here](http://www.z-table.com/) for Z-table.\n",
    "\n",
    "    a. Yes, there is enough evidence to support principal's claim.\n",
    "    \n",
    "    b. No, there is not enough evidence to support the principal's claim.\n",
    "    \n",
    "    c. We do not have enough data.\n",
    "    \n",
    "Ans : a\n",
    "\n",
    "Explanation :\n",
    "\n",
    "Null hypothesis: Mean IQ score is 100\n",
    "\n",
    "Alternate hypothesis : Mean IQ score is greater than 100\n",
    "\n",
    "Here we will want to check the z-score at 95%, so if we look into the table, we find out that the z-score for 95% is 1.645.\n",
    "\n",
    "To support our claim of mean IQ score being more than 100, we want the Z-score of the mean to be more than 1.645 so that we can reject the null hypothesis.\n",
    "\n",
    "So, we will calculate the Z-score for mean IQ score of 112. We already have the formula, so we will substitute the values:\n",
    "\n",
    "$$z = \\frac{\\bar{x} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}} =\\frac{112 - 100}{\\frac{15}{\\sqrt{36}}} = 4.8$$\n",
    "\n",
    "So, 4.8 is greater than 1.645, so we will reject the null hypothesis and accept alternate hypothesis.\n",
    "\n",
    "2. The life span of light bulbs manufactured by a particular company follows a normal distribution with a standard deviation of 120 hours and its half-life is guaranteed under warranty for a minimum of 800 hours. At random, a sample of 50 bulbs from a lot is selected and it is revealed that the half-life is 750 hours. With a significance level of 0.01, should the lot be rejected by not honoring the warranty? Click [here](http://www.z-table.com/) for Z-table.\n",
    "\n",
    "    a. Yes, there is enough evidence to support null hypothesis .\n",
    "    \n",
    "    b. No, there is not enough evidence to support the null hypothesis.\n",
    "    \n",
    "    c. We do not have enough data.\n",
    "\n",
    "\n",
    "Ans : b\n",
    "\n",
    "Explanation:\n",
    "\n",
    "1. State the null and alternative hypothesis:\n",
    "\n",
    "H0 : µ ≥ 800     \n",
    "\n",
    "H1 : µ < 800    \t\n",
    "\n",
    "2. Calculate the limit of acceptance:\n",
    "\n",
    "α = 0.01;   zα = 2.33\n",
    "\n",
    "Calculate the confidence interval:\n",
    "\n",
    "Confidence Interval\n",
    "\n",
    "3. Verify:\n",
    "\n",
    "x = 750\n",
    "\n",
    "4. Decide:\n",
    "\n",
    "The null hypothesis, H0, cannot be accepted with a significance level of 1%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 3.4 Hypothesis testing using statsmodels library\n",
    "\n",
    "We can perform the test of hypothesis of means i.e.`z-test` with the help of statsmodels library in Python.\n",
    "\n",
    "We are using the housing dataset from the previous chapter. Let us formulate and test a hypothesis regarding the `SalePrice` of the houses from this dataset. \n",
    "\n",
    "You as a buyer of a house think that the avergae price of a house is $175,000. Let us check whether this assumption is correct or not based on the sample data we have. Our null and alternate hypothesis over here can be stated as follows\n",
    "\n",
    " $H_0$ : The average SalePrice of house is 175,000 i.e. $\\mu = 175,000$ \n",
    "\n",
    " $H_1$ : The average SalePrice of house is not 175,000 i.e. $\\mu \\neq 175,000$ \n",
    "\n",
    "Now we can now use the `statsmodel` library to perfrom the next steps of hypothesis testing i.e. calulcating the `z-statistic` an d`p-value`.\n",
    "\n",
    "~~~python\n",
    "z_statistic, p_value = ztest(df.SalePrice,value=175000)\n",
    "print(\"Z-statistics = \",z_statistic)\n",
    "print(\"p-value = \",p_value)\n",
    "~~~\n",
    "Output\n",
    "~~~python\n",
    "Z-statistics =  3.9272834547730024\n",
    "p-value =  8.591071063153728e-05\n",
    "~~~\n",
    "\n",
    "We can see that the p-value is less that the significane level of 5% i.e. 0.05 hence we haev enough evidence against the null hypothesis. In this case we reject the null hypothesis in favour of alternate hypothesis. So from the sample we can statistically conclude that **the average SalePrice of the houses is not $175,000**. \n",
    "\n",
    "**Two-sided vs. One-sided tests**\n",
    "\n",
    "The hypothesis for the tests that we have discussed earlier are of the following pattern\n",
    "\n",
    "$$H_0: \\mu = some \\ value$$\n",
    "$$H_1: \\mu \\neq some \\ value$$\n",
    "\n",
    "In these tests we are testing whether the population mean is equal to some value or not. These are called as two sided hypothesis test i.e. the null hypothesis is rejected if the value is greater or smaller. \n",
    "Let us now understand one-sided hypothesis test. Let us rephrase the previous hypothesis on SalePrice. You as a buyer think that the average SalePrice of the house is **greater than** $175,000. In this case our alternate hypothesis will change as follows\n",
    "\n",
    " $H_0$ : The average SalePrice of house is 175,000 i.e. $\\mu = 175,000$ \n",
    "\n",
    " $H_1$ : The average SalePrice of house is greater than 175,000 i.e. $\\mu > 175,000$ \n",
    "\n",
    "In this scenario the calculation of p-value is changes. Let us use statsmodel to conduct the test. We need to set the parameter of `alternative` to `greater` to get the result.\n",
    "\n",
    "~~~python\n",
    "z_statistic, p_value = ztest(df.SalePrice,value=175000,alternative='larger')\n",
    "print(\"Z-statistics = \",z_statistic)\n",
    "print(\"p-value = \",p_value)\n",
    "~~~\n",
    "Output\n",
    "~~~python\n",
    "Z-statistics =  3.9272834547730024\n",
    "p-value =  4.295535531576864e-05\n",
    "~~~\n",
    "\n",
    "Over here you can observe that the value of `z-statistic` is similar to the one that we calculated in previous example, but the p-value has changed. Although, even here the p-value is less that significance level of 5% hence we can say that **the average SalePrice of the house is greater than $175,000**\n",
    "\n",
    "A similar one-sided hypothesis test can be conducted for smaller than values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 3.5  Errors in hypothesis testing\n",
    "\n",
    "To understand what types of errors can be committed in hypothesis testing, first let's look at a video explaining the various types of errors - [Type I and Type II Errors](https://www.youtube.com/watch?v=5Z9OIYA8He8)\n",
    "\n",
    "If we again think of hypothesis test as a criminal trial then it makes sense to frame the verdict in terms of null and alternate hypothesis:\n",
    "\n",
    " - Null Hypothesis: Defendant is innocent\n",
    " - Alternate Hypothesis: Defendant is guilty\n",
    "\n",
    "\n",
    "What type of error is being committed in the following circumstances?\n",
    "\n",
    "- Declaring the defendant guilty when they are actually innocent? Essentially it implies that the evidence leads the jury to convict an innocent person. By analogy, we reject a true null hypothesis and accept a false alternative hypothesis.\n",
    "\n",
    "- Declaring the defendant innocent when they are actually guilty? It implies that the evidence leads the jury to declare a defendant not guilty, when he is in fact guilty. By analogy, we fail to reject a null hypothesis that is false. In other words, we do not accept an alternative hypothesis when it is really true.\n",
    "\n",
    "    \n",
    ">*Type I error*: The first one is a **`Type I`** error also known as a **`false positive (FP)`** or **`false hit`**. Type I error describes a situation where you reject the null hypothesis when it is actually true. The type I error rate is equal to the significance level, so setting a lower significance level reduces the chances of getting a false positive. It is typically denoted by  $\\alpha$ .\n",
    "\n",
    ">*Type II error*: The second one is a **`Type II`** error also known as a **`false negative (FN)`** or **`miss`**. Type II error describes a situation where you fail to reject the null hypothesis when it is actually false. The higher your confidence level (1-significance level), the more likely you are to make a type II error. It is denoted by  $\\beta$ .\n",
    "\n",
    "\n",
    "\n",
    "![types](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b-232/6a070e23-f860-4a0e-a4da-ebf69bc4c2ae/file.png)\n",
    "\n",
    "\n",
    "\n",
    "Since statistical decisions are based on evidence gathered through sampling, and due to randomness involved, sampling evidence will sometimes fool everyone. As long as we are making a decision, we will never be able to eliminate the potential for these two types of errors.\n",
    "\n",
    "\n",
    "**What is the probability that we will make a Type I error?**\n",
    "\n",
    "If the significance level is 5 percent ( $\\alpha = 0.05$ ), then 5 percent of the time, we will reject the null hypothesis, even if it is true. Obviously we will not know whether the null hypothesis is true. But if it is, the natural variability that we expect in random samples will produce *rare* results 5 percent of the time. Similarly, if the significance level is 1 percent, then we can expect the sample results to lead us to reject the null hypothesis 1 percent of the time. Therefore, **probability of a Type I error is  $\\alpha$  or the significance level**.\n",
    "\n",
    "\n",
    "**What is the probability that we will make a Type II error?**\n",
    "\n",
    "The probability of a Type II error is much more complicated to calculate, but *it is inversely related to the probability of making a Type I error*. Thus, reducing the chance of making a Type II error causes an increase in the likelihood of a Type I error.\n",
    "\n",
    "\n",
    "\n",
    "This image will make your understanding of Type I and Type II errors more clear. \n",
    "\n",
    "![errors](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b954/0a281806-7e60-4cfd-aa50-8156a4ce55e2/file.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Which type (Type I or Type II) to minimize?**\n",
    "\n",
    "You must have already realized that Type I and Type II errors are inversely related i.e. increasing one decreases the other and vice-versa. And since they are errors they must be reduced (if not removed) to prevent making erronous decisions. In general the choice of error type to reduce depends on the business problem at hand. Lets look at some examples where we will illustrate which error type to reduce depending on the business context. \n",
    "\n",
    "- **Cancer detection**: In cancer detections two types of errors can arise: \n",
    "    - Patient is cancer free but detected as a cancer patient (Type I)\n",
    "    - Patient has cancer but detected as cancer free (Type II)\n",
    "    \n",
    "  So, which error can be more disastrous? Obviously the second situation i.e. Type II error. In this case our choice of error to reduce must be the **Type II** error by reducing the number of patients having cancer but detected as cancer free (False Negatives)\n",
    "  \n",
    "- **Guilty conviction**: Here also you can come across two situations:\n",
    "    - Person is judged as guilty when the person actually did not commit the crime i.e. convicting an innocent person (Type I)\n",
    "    - Person is judged not guilty when they actually did commit the crime i.e. letting a guilty person go free (Type II)\n",
    "    \n",
    "   In modern society the social costs of sending an innocent person to prison and denying them their personal freedoms is considered an almost unbearable act and hence in this case Type I error should be the focus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz \n",
    "\n",
    "Add questions on Type I and Type II errors. \n",
    "\n",
    "\n",
    "1. A Type I error occurs when:\n",
    "\n",
    "    a. a null hypothesis is rejected but should not be rejected.\n",
    "\n",
    "    b. a null hypothesis is not rejected but should be rejected.\n",
    "    \n",
    "    c. a test statistic is incorrect.\n",
    "    \n",
    "Ans : a\n",
    "\n",
    "Explanation :\n",
    "\n",
    "Type I error describes a situation where you reject the null hypothesis when it is actually true. \n",
    "\n",
    "1. A Type II error occurs when:\n",
    "\n",
    "    a. a null hypothesis is rejected but should not be rejected.\n",
    "\n",
    "    b. a null hypothesis is not rejected but should be rejected.\n",
    "    \n",
    "    c. a test statistic is incorrect.\n",
    "    \n",
    "Ans : b\n",
    "\n",
    "Explanation :\n",
    "\n",
    "Type II error describes a situation where you fail to reject the null hypothesis when it is actually false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 3.6 t - test\n",
    "\n",
    "Let us relook at the formula used to calculate the `z-statistic`\n",
    "\n",
    "$$z = \\frac{\\bar{x}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}$$\n",
    "\n",
    "Over here we assume that the population standard deviaton ( $\\sigma$ ) is know to us, but in reality that is hardly the case. We generally don't have information about the population and that is when we use a `t-statistic` given by \n",
    "\n",
    "$$z = \\frac{\\bar{x}-\\mu}{\\frac{s}{\\sqrt{n}}}$$\n",
    "where, s - sample standard deviation\n",
    "\n",
    "Let us understand in detail the difference between a z-statistic and t-statistic - [Z-statistic vs t-statistic](https://www.youtube.com/watch?v=5ABpqVSx33I)\n",
    "\n",
    "In this case we use a `t-distribution` to calculate the p-value instead of normal distribution in `z-test`.\n",
    "\n",
    "The key differences between a t-test and z-test are as follows\n",
    "\n",
    "The difference between t-test and z-test can be drawn clearly on the following grounds:\n",
    "\n",
    " - The t-test is based on Student’s t-distribution. On the contrary, z-test relies on the assumption that the distribution of sample means is normal. Both student’s t-distribution and normal distribution appear alike, as both are symmetrical and bell-shaped. However, they differ in the sense that in a t-distribution, there is less space in the centre and more in the tails.\n",
    " - One of the important conditions for adopting t-test is that population variance is unknown. Conversely, population variance should be known or assumed to be known in case of a z-test.\n",
    " - Z-test is used to when the sample size is large, i.e. n > 30, and t-test is appropriate when the size of the sample is small, in the sense that n < 30.\n",
    " \n",
    "We can use `scipy` library to conduct the test on the data in a similar fashion as we saw for z-test.\n",
    "\n",
    "**Test of equality of two means**\n",
    "\n",
    "The examples that we discussed uptill now involved testing value of one sample. There may be cases where we need to test that the values of two means from same population are equal. Such test are called as two sample t-test. Let us look at an example. From our data we have a feature of `Sale.Condition` which specified the condition of sale of house. The categories of this condition are Normal, Partial, Abnorml, Family, Alloca, AdjLand. Now we are interested to know whether the average `Sale.Price` for `Sale.Condition` Normal and Partial are same or not.\n",
    "\n",
    "The hypothesis can be formulated as follows\n",
    "\n",
    " $H_0$ : The mean Sale.Price of Normal and Partial condition homes are same i.e.  $\\mu_N = \\mu_P$ \n",
    "\n",
    " $H_1$ : The mean Sale.Price of Normal and Partial condition homes are not same i.e. $\\mu_N \\neq \\mu_P$ \n",
    "\n",
    "In this scenario we will use a two-sample t-test to validate our hypothesis.\n",
    "\n",
    "~~~python\n",
    "# subset the dataframe\n",
    "normal = df[df['Sale.Condition'] == 'Normal']['SalePrice']\n",
    "partial = df[df['Sale.Condition'] == 'Partial']['SalePrice']\n",
    "\n",
    "# conduct two sample t-test\n",
    "t_stat, p_value = scipy.stats.mstats.ttest_ind(normal,partial)\n",
    "\n",
    "# print the results\n",
    "print('t-statistic = ',t_stat)\n",
    "print('p-value = ',p_value)\n",
    "~~~\n",
    "Output\n",
    "~~~python\n",
    "t-statistic =  -19.6793088005836\n",
    "p-value =  1.3616391052606246e-80\n",
    "~~~\n",
    "\n",
    "Over here we can observe that the p-value is less that the significance level of 5% hence we have evidence against the null hypothesis and conclude that **the mean Sale.Price of Normal and Partial condition homes are not same.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz\n",
    "\n",
    "2 Problems on calculating the t-test\n",
    "\n",
    "1. In the population, the average IQ is 100. A team of scientist wants to test a new medication to see if it has a positive or negative or no effect at all. A random sample of 25 participants who have taken the medication has a mean of 140 with a standard deviation of 20. Did the medication effect intelligence? α = 0.05. Here you can find the [t-table](https://www.statisticshowto.datasciencecentral.com/tables/t-distribution-table/)\n",
    "\n",
    "    a. medications deeply affected intelligence\n",
    "    \n",
    "    b. medications did not affect the intelligence\n",
    "    \n",
    "    c. Not enough data\n",
    "    \n",
    "Ans : a\n",
    "\n",
    "Explanation :\n",
    "\n",
    "Null hypothesis ; $$H_0: \\mu = 100$$\n",
    "\n",
    "Alternate hypothesis ; $$H_1: \\mu \\neq 100 $$\n",
    "\n",
    "here α = 0.05 is given\n",
    "\n",
    "Now, we will calculate the degrees of freedom, the formula for which is:\n",
    "\n",
    "df = N-1\n",
    "\n",
    "Where N is the number of values in the data set (sample size). Take a look at the sample computation.\n",
    "\n",
    "df = 25 - 1 = 24\n",
    "\n",
    "From the t-table  we will find the t- score for α(0.05) and df(24) that is 2.064.\n",
    "\n",
    "So, if t is less than -2.064 or more than 2.064 we reject the null hypothesis.\n",
    "\n",
    "Now we will calculate the t-statistic, we have the formula as : $$t = \\frac{\\bar{x}-\\mu}{\\frac{s}{\\sqrt{n}}}$$\n",
    "where s - sample standard deviation\n",
    "\n",
    "so by substituting the values we get t-score as 10 which is clearly greater than 2.064. So, we will reject the null hypothesis.\n",
    "\n",
    "So, the conclusion is that the medications deeply affected intelligence.\n",
    "\n",
    "2. Average heart rate for Americans is 72 beats/minute. A group of 25 individuals participated in an aerobics fitness program to lower their heart rate. After six months the group was evaluated to identify is the program had significantly slowed their heart. The mean heart rate for the group was 69 beats/minute with a standard deviation of 6.5. Was the aerobics program effective in lowering heart rate?\n",
    "\n",
    "\n",
    "    a. There is an insignificant effect of the ind. var. of fitness.\n",
    "    \n",
    "    b. There is a significant effect of the ind. var. of fitness.\n",
    "    \n",
    "    c. no\n",
    "    \n",
    "Ans : b\n",
    "\n",
    "Explanation :\n",
    "\n",
    "The pop. mean is given as 72 beats per minutes.\n",
    "\n",
    "The sample of 25 has an average of 69 with a standard dev. of 6.5.  \n",
    "\n",
    "Step One: Again you need to solve for st. error.   St. error = 1.30\n",
    "\n",
    "Step Two: Solve for t test for single samples t = -2.31 \n",
    "\n",
    "Step Three: Evaluate. The critical value is 2.064. The computed value exceeds this value so there is a significant effect of the ind. var. of fitness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 3.7 Chi-squared test of independence\n",
    "\n",
    "The chi-squared test of independence is used when you have two categorical variables from the same population. The test of independence is used to determine whether the two categorical variables are inter-related to each other.\n",
    "\n",
    "Many a times it would occur that the features in a dataset are related to each other, such features do not add much information while building a machine learning model and it is best to remove one of these related feature. Chi-squared test of independence is one of the ways to determine this.\n",
    "\n",
    "The procedure for the test remains same as discussed in the previous topic. The hypothesis for a chi-square test of independence are as follows.\n",
    "\n",
    " $H_0$ : Variable A and Variable B are independent.\n",
    "\n",
    " $H_1$ : Variable A and Variable B are not independent.\n",
    "\n",
    "In this case we will be calculating a chi-square test statistic as follows\n",
    "$$\\chi ^2 = \\sum \\frac{(observed-expected)^2}{expected}$$\n",
    "\n",
    "Before we further explore and understand the data, let us look at a video to understand the difference between observed and expected values in the test - [Chi-squared test explained](https://www.youtube.com/watch?v=1Ldl5Zfcm1Y)\n",
    "\n",
    "In the formula, observed is the actual observed count for each category and expected is the expected count based on the distribution of the population for the corresponding category.\n",
    "\n",
    "Let us understand it with an example from the data. We will be using `scipy` library to perform the test.\n",
    "\n",
    "From our dataset we have divided the sale price of the houses in three categories viz. High, Medium and Low. We have then mapped these to the feature of Land.Contour. The observed values for these two variables now as per the following table\n",
    "\n",
    "\n",
    "|Land.Contour/SalePrice|     High|  Medium|  Low|\n",
    "|----|----|----|-----|                   \n",
    "|Bnk|61|34|22|\n",
    "|HLS |21|23|76|\n",
    "|Low|15|18|27|\n",
    "|Lvl|884|905|844|\n",
    "\n",
    "Now we want to determine whether these Land.Contour of the property is dependent on the Sale.Price of the property. We will apply a simple chi-squared test of independence as follows\n",
    "\n",
    " $H_0$ : Land.Contour and Sale.Price are independent.\n",
    "\n",
    " $H_1$ : Land.Contour and Sale.Price are not independent.\n",
    "\n",
    "~~~python\n",
    "import scipy.stats as stats\n",
    "\n",
    "# categorize the SalePrice into three buckets\n",
    "price = pd.qcut(df['SalePrice'], 3, labels = ['High', 'Medium', 'Low'])\n",
    "\n",
    "# make a frequency table with Land.Conotur\n",
    "observed = pd.crosstab(df['Land.Contour'],price)\n",
    "\n",
    "print(observed)\n",
    "\n",
    "# conduct the chi-square test with the above frequency table\n",
    "chi2, p, dof, ex = stats.chi2_contingency(observed)\n",
    "\n",
    "print(\"Chi-square statistic = \",chi2)\n",
    "print(\"p-value = \",p)\n",
    "~~~\n",
    "Output\n",
    "~~~python\n",
    "SalePrice     High  Medium  Low\n",
    "Land.Contour                   \n",
    "Bnk             61      34   22\n",
    "HLS             21      23   76\n",
    "Low             15      18   27\n",
    "Lvl            884     905  844\n",
    "Chi-square statistic =  5856.025316455696\n",
    "p-value =  0.0\n",
    "~~~\n",
    "\n",
    "Here we can observe that the p-value is less that 5% significance level hence there is enough evidence against the null hypothesis and hence we can state that **the variable of Land.Contour and Sale.Price are not independent of each other**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz\n",
    "\n",
    "2 problems on calculating chi-square statistic... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Is gender independent of education level? A random sample of 395 people were surveyed and each person was asked to report the highest education level they obtained. The data that resulted from the survey is summarized in the following table:\n",
    "\n",
    "                    High School \t Bachelors \tMasters \tPh.d. \tTotal\n",
    "\n",
    "        Female \t        60 \t         54 \t    46 \t     41 \t 201\n",
    "\n",
    "        Male \t          40 \t         44 \t     53 \t    57      194\n",
    "\n",
    "        Total \t          100 \t        98 \t     99 \t    98 \t395\n",
    "\n",
    "| |High School|   Bachelors|  Masters|  Ph.d.|Total|\n",
    "|----|----|----|----|-----|----|                   \n",
    "|Female|60|54|46|41|201\n",
    "|Male |40|44|53|57|194|\n",
    "|Total|100|98|99|98|395|\n",
    "\n",
    "\n",
    "Are gender and education level dependent at 5% level of significance? In other words, given the data collected above, is there a relationship between the gender of an individual and the level of education that they have obtained?\n",
    " \n",
    "Here's the table of expected counts:\n",
    "\n",
    "| |High School|   Bachelors|  Masters|  Ph.d.|Total|\n",
    "|----|----|----|----|-----|----|                   \n",
    "|Female|50.886|49.868|50.377|49.868|201|\n",
    "|Male |49.114|48.132|48.623|48.132|194|\n",
    "|Total|100|98|99|98|395|\n",
    "\n",
    "\n",
    "    a. There is no relationship between gender and education\n",
    "    \n",
    "    b. There is a relationship between gender and education\n",
    "    \n",
    "    c. Data available is not enough\n",
    "    \n",
    "Ans : b\n",
    "\n",
    "Explanation :\n",
    "\n",
    "In this case we will be calculating a chi-square test statistic as follows\n",
    "$$\\chi ^2 = \\sum \\frac{(observed-expected)^2}{expected}$$\n",
    "\n",
    "We will get a chi score of 8.006\n",
    "\n",
    "Expected value can be calculated as follows :\n",
    "\n",
    "So, working this out,\n",
    "\n",
    "The critical value of $\\chi ^2$ with 3 degree of freedom is 7.815. Since 8.006 > 7.815, therefore we reject the null hypothesis and conclude that the education level depends on gender at a 5% level of significance.\n",
    "\n",
    "\n",
    "2. 1. A sample of 100 voters are asked which of four candidates they would vote for in an election. The number supporting each candidate is given below:\n",
    "\n",
    " \n",
    "\n",
    "                        Higgins             Reardon            White                Charlton\n",
    "\n",
    "                        41                     19                     24                     16\n",
    "\n",
    " \n",
    "\n",
    "Does the data suggest that all candidates are equally popular? [Chi-Square = 14.96, with 3 d.f.: p<0.05].\n",
    "\n",
    "    a. There is no preference to for any of the candidates.\n",
    "    \n",
    "    b. All the candidates are equally popular\n",
    "    \n",
    "    c. Not enough data\n",
    "\n",
    "\n",
    "Ans : b\n",
    "\n",
    "Explanation :\n",
    "\n",
    "A Chi-Squared Goodness-of-Fit test is appropriate here. The null hypothesis is that there is no preference for any of the candidates: if this is so, we would expect roughly equal numbers of voters to support each candidate. Our expected frequencies are therefore 100/4 = 25 per candidate.\n",
    "\n",
    " \n",
    "\n",
    "|O|E|(O-E)| $\\frac{(O-E)^2}{E}$ |\n",
    "|----|----|----|----|                   \n",
    "|41|25|16|10.24|\n",
    "|19 |25|-6|1.44|\n",
    "|24|25|-1|0.04|\n",
    "|16|25|-9|3.24|\n",
    "\n",
    "Adding the last column gives us a value of 10.24+ 1.44 + 0.04 + 3.24 = 14.96, with 4 - 1 = 3 degrees of freedom.\n",
    "\n",
    "\n",
    "The critical value of Chi-Square for a 0.05 significance level and 3 d.f. is 7.82. Our obtained Chi-Square value is bigger than this, and so we conclude that our obtained value is unlikely to have occurred merely by chance. In fact, our obtained value is bigger than the critical Chi-Square value for the 0.01 significance level (13.28). In other words, it is possible that our obtained Chi-Square value is due merely to chance, but highly unlikely: a Chi-Square value as large as ours will occur by chance only about once in a hundred trials. It seems more reasonable to conclude that our results are not de to chance, and that the data do indeed suggest that voters do not prefer the four candidates equally.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
