{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "Learn what series and dataframes are, how to create them and use the power of the pandas library for deriving results \n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "- Pandas overview\n",
    "- Creating dataframes and series\n",
    "- Indexing, selection, addition and deletion of rows and columns\n",
    "- Apply, map, grouby functions\n",
    "- Plotting\n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Create dataframes\n",
    "- Perform common data manipulation tasks\n",
    "- Visualize data with pandas\n",
    "\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "- Base Python\n",
    "- Numpy\n",
    "- Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: Pandas DataFrames \n",
    "\n",
    "\n",
    "### Description: In this chapter, you will be introduced to `pandas` library and learn about the available data structures inside it and how to create them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Introduction to pandas\n",
    "\n",
    "***\n",
    "\n",
    "**Why pandas for data analysis?**\n",
    "\n",
    "An important step for any data scientist is to prepare and clean the data so that it could be used later for deeper analysis. Analysis on raw and unclean data could lead to wrong insights which could derail the organization. Real 'raw' data needs a lot of 'wrangling' operations before it can be ready for dissection by a data scientist. One of the popular tools for data wrangling in python is `pandas`. \n",
    "\n",
    "One of the reasons why Python is used extensively for Data Science is the availability of widespread packages for almost every possible function. The library `pandas` is one such package which makes life easier especially for data analysis through its extensive in-built functions for manipulations and visualizations. It is built on top of the `NumPy` and `matplotlib` library and one can harness the power of both these libraries in tandem with the power of `pandas`. Besides, there is huge community support especially for `pandas` and there are very high chances that you will get an answer for your query (if and when you get stuck) on the Internet. Take a look at the trend below to realize its popularity amongst users.\n",
    "\n",
    "<img src=\"../images/pandas_popularity.png\" width=\"800\" height=\"400\" />\n",
    "\n",
    "\n",
    "**Data structures in pandas**\n",
    "\n",
    "Pandas deals with the three data structures:\n",
    "- Series (Labeled 1 dimensional with homogeneous data but immutable size)\n",
    "<img src=\"../images/series.jpg\" width=\"400\" height=\"400\" />\n",
    "\n",
    "- DataFrame (Labeled 2 dimensional size-mutable tabular structure with potentially heterogeneously typed columns)\n",
    "<img src=\"../images/dataframe.jpg\" width=\"400\" height=\"400\" />\n",
    "\n",
    "- Panel (Labeled 3 dimensional size-mutable array)\n",
    "\n",
    "The one with that we mostly deal with in our day-to-day life is the DataFrame type which is nothing but tabular data that we frequently encounter, particularly while using **Excel**. \n",
    "\n",
    "In the next part of the course you will learn more about the **Series** and **DataFrame** variant of `pandas` data structures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Series \n",
    "\n",
    "***\n",
    "\n",
    "A Series is a single vector of data (like a `NumPy` array) with an **index** that labels each element in the vector. **The main difference between a series and NumPy array is that series may have axis labels, a NumPy array doesn't**.  A `NumPy` array comprises the values of the series, while the index is a pandas `Index` object. It can hold any type of data (integer, string, float, python objects, etc.) as long as the data is homogeneous throughout the series. If an index is not specified, a default sequence of integers is assigned as the index.\n",
    "\n",
    "**Creating series**\n",
    "\n",
    "The constructor for series is : `pandas.Series(data, index, dtype, copy)`\n",
    "\n",
    "Here, \n",
    "- **data**: data (can be lists, ndarrays, dictionaries etc.)\n",
    "- **index**: unique, hashable and same length as data (default is `np.arange(n)` where n is length of data)\n",
    "- **dtype**: data type of series values\n",
    "- **copy**: copy data (default `False`)\n",
    "\n",
    "Now lets look at the different ways to create a series using `pandas`:\n",
    "\n",
    "1) From **NumPy ndarray**\n",
    "\n",
    "   - In the first series indices are from $0$ to $2$ \n",
    "   - In the second series they are as specified by ['a', 'b', 'c']\n",
    "\n",
    "<img align=\"left\" src=\"../images/series_1.png\" width=\"1000\" height=\"400\" />\n",
    "\n",
    "2) From **Dictionary**\n",
    "\n",
    "   - When index is not specified, then the **keys** are taken in a **sorted order** as index values.\n",
    "   - If index is passed, values in data corresponding to the labels in the index will be accessed, the index which are absent in the keys of the dictionary will have **NaN** values.\n",
    "    \n",
    "<img align=\"left\" src=\"../images/series_2.png\" width=\"1000\" height=\"400\" />\n",
    "\n",
    "\n",
    "3) From **Scalar**\n",
    "\n",
    "   - Index is provided and scalar will be repeated to match the value and the length of it. \n",
    "    \n",
    "<img align=\"left\" src=\"../images/series_3.png\" width=\"1000\" height=\"200\" />\n",
    "\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your first `pandas` Series\n",
    "\n",
    "In this task you will create a `pandas` series yourself (for the first time) and look at its output.\n",
    "\n",
    "### Instructions\n",
    "- Create a list `nums` containing the phone numbers `800678` and `800456`\n",
    "- Create a list `names` containing the names `'Richie'` and `'Mark'`\n",
    "- Next, create a `pandas` series consisting of phone numbers of `'Richie'` and `'Mark'` having values `800678` and `800456`  with default index (i.e. $0$ & $1$) and save it as `series_1`\n",
    "- Now create the same series as above but with names as index this time using `index=names` inside `.Series()` method of `pandas`. Save it as `series_2`\n",
    "- Print `series_1` and `series_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    800678\n",
      "1    800456\n",
      "dtype: int64\n",
      "==================================================\n",
      "Richie    800678\n",
      "Mark      800456\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Task 1 \n",
    "import pandas as pd\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "# initialize lists of numbers and names\n",
    "nums = [800678, 800456]\n",
    "names = ['Richie', 'Mark']\n",
    "\n",
    "series_1 = pd.Series(nums)\n",
    "print(series_1)\n",
    "print('='*50)\n",
    "series_2 = pd.Series(nums, index=names)\n",
    "print(series_2)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints\n",
    "- Initialize both lists as \n",
    "```python\n",
    "nums = [800678, 800456]\n",
    "names = ['Richie', 'Mark']\n",
    "```\n",
    "- Create `series_1` as\n",
    "```python\n",
    "series_1 = pd.Series(nums)\n",
    "```\n",
    "- Create `series_2` containing `names` as index as \n",
    "```python\n",
    "series_2 = pd.Series(nums, index=names)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Accessing data in Series\n",
    "\n",
    "***\n",
    "\n",
    "Locating data in a series is of prime importance in data analysis tasks. There are two ways by which you can access data in series objects:\n",
    "\n",
    "1) **By Position**: A series is very similar to a `NumPy` array (index starts at $0$), so data can be accessed in the same manner as we did for `NumPy` arrays. The syntax remains the same i.e. `series[start:stop:step]`. Let us understand with an example. \n",
    "\n",
    "<img align=\"left\" src=\"../images/series_4.png\" width=\"1000\" height=\"200\" />\n",
    "\n",
    "2) **By labels**: We can also use the index labels to access data given the condition that the label is in the index; otherwise it will throw a `KeyError`. Accessing data can be either:\n",
    "\n",
    "- Single element access: `series[index]`\n",
    "- Multiple element access: `series[[index1, index2, index3, .....]]`\n",
    "\n",
    "**Remember to use [[ ]] to access multiple elements via labels**\n",
    "\n",
    "The example below shows accessing data with labels\n",
    "\n",
    "<img align=\"center\" src=\"../images/series_5.png\" width=\"1000\" height=\"600\" />\n",
    "\n",
    "**NOTE:** It may happen that while combining series you arrive at another series which contains null values or **NaN**s. Most often they are undesirable and you can replace them with any value you want with the help of `.fillna()` method of pandas. Lets say you want to replace **NaN**s with value `a`; simply use `series.fillna(a)` and additionaly if you want the change to be permanent use `inplace=True` inside `.fillna()` method.   \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we add two Series with different indices?\n",
    "\n",
    "In this task you will add two series, with different indices. \n",
    "\n",
    "- Create two series with same values $[1,2,3,4]$ but having different indices; one with $[0,1,2,3]$ and the other $[0,1,3,4]$. Save the first series as `a` and the second one as `b` \n",
    "- Then add both the series as $series1 + series2$ and save it as `c`\n",
    "- Print it out to check `c` and you will observe some missing value as **`NaN`** s\n",
    "- Replace those **`NaN`** s permanently with `0`s using `.fillna(0, inplace=True)`\n",
    "- Again print out `c` and to confirm that **NaN**s have been replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2.0\n",
      "1    4.0\n",
      "2    NaN\n",
      "3    7.0\n",
      "4    NaN\n",
      "dtype: float64\n",
      "====================\n",
      "0    2.0\n",
      "1    4.0\n",
      "2    0.0\n",
      "3    7.0\n",
      "4    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "a = pd.Series([1,2,3,4], index=[0,1,2,3])\n",
    "b = pd.Series([1,2,3,4], index=[0,1,3,4])\n",
    "\n",
    "c = a + b\n",
    "print(c)\n",
    "print('='*20)\n",
    "\n",
    "c.fillna(0, inplace=True)\n",
    "print(c)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints\n",
    "- Create series `a` and `b` as:\n",
    "```python\n",
    "a = pd.Series([1,2,3,4], index=[0,1,2,3])\n",
    "b = pd.Series([1,2,3,4], index=[0,1,3,4])\n",
    "```\n",
    "- Add the two series as\n",
    "```python\n",
    "c = a + b\n",
    "```\n",
    "- To replace **NaN**s with $0$s use\n",
    "```python\n",
    "c.fillna(0, inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Dataframes\n",
    "\n",
    "***\n",
    "\n",
    "**What is a dataframe?**\n",
    "\n",
    "The concept of a dataframe comes from the world of statistical software used in empirical research. It generally refers to **tabular** data: a data structure representing **instances(rows)**, each of which consists of a number of **measurements(columns)**. Alternatively, each row may be treated as a single observation of multiple **variables**. An example of dataframe that we commonly come across in Excel is shown below:\n",
    "\n",
    "<img align=\"center\" src=\"../images/excel.png\" width=\"1000\" height=\"600\" />\n",
    "\n",
    "Here,\n",
    "\n",
    "- $2, 3, 4, .....$ are the **rows/instances**\n",
    "- `account`, `name`, `street`, `city` etc. are the **measurements/variables** for each instance\n",
    "\n",
    "***\n",
    "\n",
    "**Features of `pandas` dataframe**\n",
    "\n",
    "Due to the widespread use of 2-D tabular data, `pandas` is one of the most widely used packages especially for dataframes. Dataframes have the following features:\n",
    "\n",
    "- Columns can be of different types\n",
    "- Size is mutable\n",
    "- Labeled axes (rows and columns)\n",
    "- Can perform arithmetic operations on rows and columns\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Creating dataframes\n",
    "\n",
    "***\n",
    "\n",
    "**How to create dataframes?**\n",
    "\n",
    "The constructor for `pandas` dataframe object is `pandas.DataFrame( data, index, columns, dtype, copy)`.\n",
    "\n",
    "Here, \n",
    "- `data`: various forms (ndarray, series, map, lists, dict, constants, another DataFrame)\n",
    "- `index`: index labels (default `np.arange(n)`) \n",
    "- `columns`: column names (default `np.arange(n)`); True only when `index` is not specified\n",
    "- `dtype`: Data type of each column\n",
    "- `copy`: copying of data (default `False`)\n",
    "\n",
    "\n",
    "Now depending on the form of the `data` we can construct dataframes from different sources. Let us discuss few of them: \n",
    "\n",
    "1) From **lists**:\n",
    "\n",
    "<img align=\"left\" src=\"../images/pandas_list_1.png\" width=\"1000\" height=\"600\" />\n",
    "\n",
    "   Here, we pass the names ['Rob', 'Bobby', 'John', 'Danny', 'Manny'] as the values of a column/feature titled `Name` and having indices [0, 1, 2, 3, 4].Now let us pass a list of lists as values so that we can accomodate more than single column/feature. It is demonstrated below:\n",
    "   \n",
    "<img align=\"left\" src=\"../images/pandas_list_2.png\" width=\"1000\" height=\"600\" />\n",
    "\n",
    "   We have simply added `Age` column for each and every instance (rows)\n",
    "   \n",
    "2) From **dictionary**\n",
    "\n",
    "We can also use dictionaries for creating dataframes. Lets see how:\n",
    "\n",
    "- **Dictionary of ndarrays/lists**: The **keys** of the dictionary will be the **feature names** and the **values** will be the values for that feature across the dataframe. Remember that the ndarrays/lists must have the same length. \n",
    "\n",
    "<img align=\"left\" src=\"../images/pandas_dict_1.png\" width=\"1000\" height=\"600\" />\n",
    "\n",
    "In the above example we have constructed the same dataframe as in the previous example but using a dictionary this time, albeit with an index. Observe closely to make out the syntax. \n",
    "\n",
    "3) From **list of dictionaries**: Here, each element correspinds to a row/instance and every element is a dictionary. This dictionary in turn contains the feature names as the keys and feature values as the values of that key. We create the same dataframe as the previous example this time but now as a list of dictionaries.\n",
    "\n",
    "<img align=\"left\" src=\"../images/dataframe_lod.png\" width=\"1000\" height=\"600\" />\n",
    "\n",
    "\n",
    "4) From **series**: \n",
    "\n",
    "<img align=\"left\" src=\"../images/pdtodf.png\" width=\"1000\" height=\"600\" />\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your first DataFrame\n",
    "\n",
    "In this task you will create a dataframe containing the phone numbers and pincodes of two persons `Richie` and `Mark` using any the methods explained in the topic.\n",
    "\n",
    "### Instructions \n",
    "- Save their pincodes as a list `pincodes` which has values `(800678, 2567890)`\n",
    "- Save their phone numbers as a list `numbers` containing values `(800456, 2567657)`\n",
    "- Create a list `labels` which you will be using as index for the dataframe. It contains the initials of `Richie` and `Mark` i.e. `R` and `M`\n",
    "- Use the dataframe constructor `.DataFrame()` to create the dataframe with `labels` as index and column names as `Number` and `Pincode`. Save it as `first`\n",
    "- Print out `first`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Number  Pincode\n",
      "R  2567890   800678\n",
      "M  2567657   800456\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "pincodes = [800678, 800456]\n",
    "numbers = [2567890, 2567657]\n",
    "labels = ['R', 'M']\n",
    "\n",
    "first = pd.DataFrame({'Number':numbers, 'Pincode':pincodes}, index=labels)\n",
    "print(first)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints\n",
    "- First create the series `pincodes`, `numbers` and `labels` in the following manner:\n",
    "```python\n",
    "pincodes = [800678, 800456]\n",
    "numbers = [2567890, 2567657]\n",
    "labels = ['R', 'M']\n",
    "```\n",
    "- We will show you how to create the dataframe using the dictionary method:\n",
    "```python\n",
    "first = pd.DataFrame({'Number':numbers, 'Pincode':pincodes}, index=labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "1. Which of the following thing can be data in Pandas?\n",
    "\n",
    "    a. Dictionary\n",
    "    \n",
    "    b. NumPy ndarray\n",
    "    \n",
    "    c. List\n",
    "    \n",
    "    d. All of the above\n",
    "    \n",
    "**ANS**: d. All of the above\n",
    "\n",
    "\n",
    "2. Will there be NaN values if we combine (add) two series with different indices?\n",
    "\n",
    "    a. YES\n",
    "    \n",
    "    b. NO\n",
    "    \n",
    "**ANS**: a. YES\n",
    "\n",
    "\n",
    "3. Which keyword is used to specify the index labels in pandas.DataFrame() function?\n",
    "\n",
    "    a. columns\n",
    "    \n",
    "    b. index\n",
    "    \n",
    "**ANS**: b. index\n",
    "\n",
    "\n",
    "4. Can a pandas Series object hold data of different types?\n",
    "\n",
    "    a. YES\n",
    "    \n",
    "    b. NO\n",
    "    \n",
    "**ANS**: a. YES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Basic pandas operations\n",
    "\n",
    "### Description: In this chapter you will learn about selecting, adding, deleting operations on rows and columns by taking you through the Pokemon dataset. It will prepare you to progress towards more advanced operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 File I/O\n",
    "\n",
    "***\n",
    "\n",
    "`pandas` I/O API provides a set of reader functions like `read_csv()`, `read_table()` and returns a `pandas` object. It parses the data and converts it intelligently into a DataFrame.\n",
    "\n",
    "If the file has a **.csv** format use `pandas.read_csv(filepath_or_buffer, sep=',', delimiter=None, header='infer',names=None, index_col=None, usecols=None`** to convert a file into a DataFrame. Most of the files you encounter will be in csv format.\n",
    "\n",
    "Here,\n",
    "\n",
    "- **filepath_or_buffer**: path to the file\n",
    "- **sep**: Delimiter to use\n",
    "- **delimiter**: Alternative argument name for sep (default `None`)\n",
    "- **header**: Row number(s) to use as the column names, and the start of the data \n",
    "- **names**: List of column names to use\n",
    "- **index_col**: Column to use as the row labels of the DataFrame\n",
    "- **usecols**: Return a subset of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Pokemon dataset\n",
    "\n",
    "In this task you will read the the file **'pokemon.csv'** using pandas `read_csv()` method to convert into a dataframe.\n",
    "\n",
    "### Instructions\n",
    "- Load the dataframe with `pandas.read_csv(filepath)` and save it as `df`. Here, filename is the name of the Pokemon csv file\n",
    "- Print out `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       #                    Name    Type 1  Type 2   HP  Attack  Defense  \\\n",
      "0      1               Bulbasaur     Grass  Poison   45      49       49   \n",
      "1      2                 Ivysaur     Grass  Poison   60      62       63   \n",
      "2      3                Venusaur     Grass  Poison   80      82       83   \n",
      "3      4           Mega Venusaur     Grass  Poison   80     100      123   \n",
      "4      5              Charmander      Fire     NaN   39      52       43   \n",
      "5      6              Charmeleon      Fire     NaN   58      64       58   \n",
      "6      7               Charizard      Fire  Flying   78      84       78   \n",
      "7      8        Mega Charizard X      Fire  Dragon   78     130      111   \n",
      "8      9        Mega Charizard Y      Fire  Flying   78     104       78   \n",
      "9     10                Squirtle     Water     NaN   44      48       65   \n",
      "10    11               Wartortle     Water     NaN   59      63       80   \n",
      "11    12               Blastoise     Water     NaN   79      83      100   \n",
      "12    13          Mega Blastoise     Water     NaN   79     103      120   \n",
      "13    14                Caterpie       Bug     NaN   45      30       35   \n",
      "14    15                 Metapod       Bug     NaN   50      20       55   \n",
      "15    16              Butterfree       Bug  Flying   60      45       50   \n",
      "16    17                  Weedle       Bug  Poison   40      35       30   \n",
      "17    18                  Kakuna       Bug  Poison   45      25       50   \n",
      "18    19                Beedrill       Bug  Poison   65      90       40   \n",
      "19    20           Mega Beedrill       Bug  Poison   65     150       40   \n",
      "20    21                  Pidgey    Normal  Flying   40      45       40   \n",
      "21    22               Pidgeotto    Normal  Flying   63      60       55   \n",
      "22    23                 Pidgeot    Normal  Flying   83      80       75   \n",
      "23    24            Mega Pidgeot    Normal  Flying   83      80       80   \n",
      "24    25                 Rattata    Normal     NaN   30      56       35   \n",
      "25    26                Raticate    Normal     NaN   55      81       60   \n",
      "26    27                 Spearow    Normal  Flying   40      60       30   \n",
      "27    28                  Fearow    Normal  Flying   65      90       65   \n",
      "28    29                   Ekans    Poison     NaN   35      60       44   \n",
      "29    30                   Arbok    Poison     NaN   60      85       69   \n",
      "..   ...                     ...       ...     ...  ...     ...      ...   \n",
      "770  771                 Sylveon     Fairy     NaN   95      65       65   \n",
      "771  772                Hawlucha  Fighting  Flying   78      92       75   \n",
      "772  773                 Dedenne  Electric   Fairy   67      58       57   \n",
      "773  774                 Carbink      Rock   Fairy   50      50      150   \n",
      "774  775                   Goomy    Dragon     NaN   45      50       35   \n",
      "775  776                 Sliggoo    Dragon     NaN   68      75       53   \n",
      "776  777                  Goodra    Dragon     NaN   90     100       70   \n",
      "777  778                  Klefki     Steel   Fairy   57      80       91   \n",
      "778  779                Phantump     Ghost   Grass   43      70       48   \n",
      "779  780               Trevenant     Ghost   Grass   85     110       76   \n",
      "780  781  Pumpkaboo Average Size     Ghost   Grass   49      66       70   \n",
      "781  782    Pumpkaboo Small Size     Ghost   Grass   44      66       70   \n",
      "782  783    Pumpkaboo Large Size     Ghost   Grass   54      66       70   \n",
      "783  784    Pumpkaboo Super Size     Ghost   Grass   59      66       70   \n",
      "784  785  Gourgeist Average Size     Ghost   Grass   65      90      122   \n",
      "785  786    Gourgeist Small Size     Ghost   Grass   55      85      122   \n",
      "786  787    Gourgeist Large Size     Ghost   Grass   75      95      122   \n",
      "787  788    Gourgeist Super Size     Ghost   Grass   85     100      122   \n",
      "788  789                Bergmite       Ice     NaN   55      69       85   \n",
      "789  790                 Avalugg       Ice     NaN   95     117      184   \n",
      "790  791                  Noibat    Flying  Dragon   40      30       35   \n",
      "791  792                 Noivern    Flying  Dragon   85      70       80   \n",
      "792  793                 Xerneas     Fairy     NaN  126     131       95   \n",
      "793  794                 Yveltal      Dark  Flying  126     131       95   \n",
      "794  795      Zygarde Half Forme    Dragon  Ground  108     100      121   \n",
      "795  796                 Diancie      Rock   Fairy   50     100      150   \n",
      "796  797            Mega Diancie      Rock   Fairy   50     160      110   \n",
      "797  798          Hoopa Confined   Psychic   Ghost   80     110       60   \n",
      "798  799           Hoopa Unbound   Psychic    Dark   80     160       60   \n",
      "799  800               Volcanion      Fire   Water   80     110      120   \n",
      "\n",
      "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
      "0         65       65     45           1      False  \n",
      "1         80       80     60           1      False  \n",
      "2        100      100     80           1      False  \n",
      "3        122      120     80           1      False  \n",
      "4         60       50     65           1      False  \n",
      "5         80       65     80           1      False  \n",
      "6        109       85    100           1      False  \n",
      "7        130       85    100           1      False  \n",
      "8        159      115    100           1      False  \n",
      "9         50       64     43           1      False  \n",
      "10        65       80     58           1      False  \n",
      "11        85      105     78           1      False  \n",
      "12       135      115     78           1      False  \n",
      "13        20       20     45           1      False  \n",
      "14        25       25     30           1      False  \n",
      "15        90       80     70           1      False  \n",
      "16        20       20     50           1      False  \n",
      "17        25       25     35           1      False  \n",
      "18        45       80     75           1      False  \n",
      "19        15       80    145           1      False  \n",
      "20        35       35     56           1      False  \n",
      "21        50       50     71           1      False  \n",
      "22        70       70    101           1      False  \n",
      "23       135       80    121           1      False  \n",
      "24        25       35     72           1      False  \n",
      "25        50       70     97           1      False  \n",
      "26        31       31     70           1      False  \n",
      "27        61       61    100           1      False  \n",
      "28        40       54     55           1      False  \n",
      "29        65       79     80           1      False  \n",
      "..       ...      ...    ...         ...        ...  \n",
      "770      110      130     60           6      False  \n",
      "771       74       63    118           6      False  \n",
      "772       81       67    101           6      False  \n",
      "773       50      150     50           6      False  \n",
      "774       55       75     40           6      False  \n",
      "775       83      113     60           6      False  \n",
      "776      110      150     80           6      False  \n",
      "777       80       87     75           6      False  \n",
      "778       50       60     38           6      False  \n",
      "779       65       82     56           6      False  \n",
      "780       44       55     51           6      False  \n",
      "781       44       55     56           6      False  \n",
      "782       44       55     46           6      False  \n",
      "783       44       55     41           6      False  \n",
      "784       58       75     84           6      False  \n",
      "785       58       75     99           6      False  \n",
      "786       58       75     69           6      False  \n",
      "787       58       75     54           6      False  \n",
      "788       32       35     28           6      False  \n",
      "789       44       46     28           6      False  \n",
      "790       45       40     55           6      False  \n",
      "791       97       80    123           6      False  \n",
      "792      131       98     99           6       True  \n",
      "793      131       98     99           6       True  \n",
      "794       81       95     95           6       True  \n",
      "795      100      150     50           6       True  \n",
      "796      160      110    110           6       True  \n",
      "797      150      130     70           6       True  \n",
      "798      170      130     80           6       True  \n",
      "799      130       90     70           6       True  \n",
      "\n",
      "[800 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# data source\n",
    "filepath = '../data/pokemon.csv'\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "df = pd.read_csv(filepath)\n",
    "print(df)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints\n",
    "- Use `.read_csv()` method as `df = pd.read_csv(filepath)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Functions for quick exploration\n",
    "\n",
    "***\n",
    "\n",
    "You will be working on the **'pokemon.csv'** data for your tasks and we will provide snapshot of operations which were carried out on a subset of the data.\n",
    "\n",
    "\n",
    "**About Pokemons**: The millenials must be well acquainted with Pokémons. For those of you that do not know about them, we will provide you with a brief background of what Pokémons are (those who know already can skip).\n",
    "\n",
    "\n",
    "Pokémon—short for pocket monsters—is the name of an anime series involving creatures called **pokémon** and **trainers**. Within the narrative of the series, the pokémon trainer catches pokémon in little holding containers (called **pokeballs**), and then uses those pokémon to fight other pokémon. On its surface, the fights have two reasons:\n",
    "- to weaken and capture wild pokémon\n",
    "- to defeat other pokémon trainers.\n",
    "\n",
    "The pokémon themselves are various, having different appearances, names, powers, potentials, weaknesses, and personalities. \n",
    "\n",
    "<img align=\"center\" src=\"../images/intro_to_pokemon.jpg\" width=\"1000\" height=\"600\" />\n",
    "\n",
    "\n",
    "\n",
    "**Dataset description**: This data set includes $721$ Pokemon, including their number, name, first and second type, and basic stats: `HP`, `Attack`, `Defense`, `Special Attack`, `Special Defense`, and `Speed`. \n",
    "\n",
    "\n",
    "**Feature description**:\n",
    "\n",
    "- `#`: ID for each pokemon\n",
    "- `Name`: Name of each pokemon\n",
    "- `Type 1`: Each pokemon has a type, this determines weakness/resistance to attacks\n",
    "- `Type 2`: Some pokemon are dual type and have 2\n",
    "- `Total`: sum of all stats that come after this, a general guide to how strong a pokemon is\n",
    "- `HP`: hit points, or health, defines how much damage a pokemon can withstand before fainting\n",
    "- `Attack`: the base modifier for normal attacks (eg. Scratch, Punch)\n",
    "- `Defense`: the base damage resistance against normal attacks\n",
    "- `SP Atk`: special attack, the base modifier for special attacks (e.g. fire blast, bubble beam)\n",
    "- `SP Def`: the base damage resistance against special attacks\n",
    "- `Speed`: determines which pokemon attacks first each round\n",
    "\n",
    "\n",
    "Now let us look and understand some of the functions that you will be using to have a quick glance and understanding of data. \n",
    "\n",
    "1) **Looking at the top few rows**: Use `.head(n)` to display first **n** rows. By default it displays first $5$ rows.\n",
    "\n",
    "<img align=\"center\" src=\"../images/head_1.png\" width=\"1000\" height=\"600\" />\n",
    "\n",
    "2) **Looking at the last few rows**: Use `.tail(n)` to display the last **n** rows. By default it displays the last $5$ rows\n",
    "\n",
    "<img align=\"center\" src=\"../images/tail.png\" width=\"1000\" height=\"600\" />\n",
    "\n",
    "3) **General information of every column**: Use `.info()` method to display datatypes for each column, number of non-missing values and memory usage by the dataframe.\n",
    "\n",
    "4) **Data type of every column**: Use `.dtypes` attribute  \n",
    "\n",
    "<img align=\"center\" src=\"../images/dtype.png\" width=\"200\" height=\"100\" />\n",
    "\n",
    "5) **Display column names**: Use `.columns` attribute to check all column names\n",
    "\n",
    "~~~python\n",
    "df.columns\n",
    "~~~\n",
    "\n",
    "\n",
    "\n",
    "6) **Check dimensions**: To check dimensions of dataframe, use `.shape` atttribute\n",
    "```python\n",
    "df.shape\n",
    "```\n",
    "\n",
    "7) **Check missing values per column**: Use `.isnull().sum()` to check missing values per column\n",
    "```python\n",
    "df.isnull().sum()\n",
    "```\n",
    "\n",
    "\n",
    "8) **Check number of unique values per column**: Use `.nunique()` to check unique values for every column\n",
    "```python\n",
    "df.nunique()\n",
    "```\n",
    "\n",
    "9) **Dropping missing values**: Use `.dropna()` to drop rows with missing values from the dataframe. You can use `inplace=True` if you want to modify the dataframe in-place.\n",
    "```python\n",
    "df.dropna()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickly explore the dataset\n",
    "\n",
    "In this task you will do a quick review of the data at hand i.e `df`.\n",
    "\n",
    "### Instructions\n",
    "- Look at the first 10 instances using `.head(10)` on the dataframe `df` and save it as `head`. Print `head` \n",
    "- Use the `.describe()` method and save it as `describe`. Print it out\n",
    "- Check its dimensions with `.shape` attribute and save it to a variable `shape`. Print it out to check the shape of the dataframe\n",
    "- Look at the number of missing values per attribute with `.isnull().sum()` and save it to a variable `null`. Print this one out too.\n",
    "- Find number of unique values per attribute with the `.nunique()` method and save it to a variable `unique`. As before, print `unique` out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    #              Name Type 1  Type 2  HP  Attack  Defense  Sp. Atk  Sp. Def  \\\n",
      "0   1         Bulbasaur  Grass  Poison  45      49       49       65       65   \n",
      "1   2           Ivysaur  Grass  Poison  60      62       63       80       80   \n",
      "2   3          Venusaur  Grass  Poison  80      82       83      100      100   \n",
      "3   4     Mega Venusaur  Grass  Poison  80     100      123      122      120   \n",
      "4   5        Charmander   Fire     NaN  39      52       43       60       50   \n",
      "5   6        Charmeleon   Fire     NaN  58      64       58       80       65   \n",
      "6   7         Charizard   Fire  Flying  78      84       78      109       85   \n",
      "7   8  Mega Charizard X   Fire  Dragon  78     130      111      130       85   \n",
      "8   9  Mega Charizard Y   Fire  Flying  78     104       78      159      115   \n",
      "9  10          Squirtle  Water     NaN  44      48       65       50       64   \n",
      "\n",
      "   Speed  Generation  Legendary  \n",
      "0     45           1      False  \n",
      "1     60           1      False  \n",
      "2     80           1      False  \n",
      "3     80           1      False  \n",
      "4     65           1      False  \n",
      "5     80           1      False  \n",
      "6    100           1      False  \n",
      "7    100           1      False  \n",
      "8    100           1      False  \n",
      "9     43           1      False  \n",
      "==================================================\n",
      "              #          HP      Attack     Defense     Sp. Atk     Sp. Def  \\\n",
      "count  800.0000  800.000000  800.000000  800.000000  800.000000  800.000000   \n",
      "mean   400.5000   69.258750   79.001250   73.842500   72.820000   71.902500   \n",
      "std    231.0844   25.534669   32.457366   31.183501   32.722294   27.828916   \n",
      "min      1.0000    1.000000    5.000000    5.000000   10.000000   20.000000   \n",
      "25%    200.7500   50.000000   55.000000   50.000000   49.750000   50.000000   \n",
      "50%    400.5000   65.000000   75.000000   70.000000   65.000000   70.000000   \n",
      "75%    600.2500   80.000000  100.000000   90.000000   95.000000   90.000000   \n",
      "max    800.0000  255.000000  190.000000  230.000000  194.000000  230.000000   \n",
      "\n",
      "            Speed  Generation  \n",
      "count  800.000000   800.00000  \n",
      "mean    68.277500     3.32375  \n",
      "std     29.060474     1.66129  \n",
      "min      5.000000     1.00000  \n",
      "25%     45.000000     2.00000  \n",
      "50%     65.000000     3.00000  \n",
      "75%     90.000000     5.00000  \n",
      "max    180.000000     6.00000  \n",
      "==================================================\n",
      "(800, 12)\n",
      "==================================================\n",
      "#               0\n",
      "Name            1\n",
      "Type 1          0\n",
      "Type 2        386\n",
      "HP              0\n",
      "Attack          0\n",
      "Defense         0\n",
      "Sp. Atk         0\n",
      "Sp. Def         0\n",
      "Speed           0\n",
      "Generation      0\n",
      "Legendary       0\n",
      "dtype: int64\n",
      "==================================================\n",
      "#             800\n",
      "Name          799\n",
      "Type 1         18\n",
      "Type 2         18\n",
      "HP             94\n",
      "Attack        111\n",
      "Defense       103\n",
      "Sp. Atk       105\n",
      "Sp. Def        92\n",
      "Speed         108\n",
      "Generation      6\n",
      "Legendary       2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Code starts here\n",
    "\n",
    "head = df.head(10)\n",
    "print(head)\n",
    "print('='*50)\n",
    "describe = df.describe()\n",
    "print(describe)\n",
    "print('='*50)\n",
    "shape = df.shape\n",
    "print(shape)\n",
    "print('='*50)\n",
    "null = df.isnull().sum()\n",
    "print(null)\n",
    "print('='*50)\n",
    "unique = df.nunique()\n",
    "print(unique)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints\n",
    "- Create `head` as `head = df.head(10)`\n",
    "- Create `describe` as `describe = df.describe()`\n",
    "- Create `shape` as `shape = df.shape`\n",
    "- Create `null` as `null = df.isnull().sum()`\n",
    "- Create `unique` as `unique = df.nunique()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Selection, creation and deletion\n",
    "\n",
    "***\n",
    "\n",
    "Before exploring further into the data, you need to learn how to create, select and delete values according to rows and columns. Let us look at some example to understand how it works. All of the examples have been performed on the Pokemon dataset only.\n",
    "\n",
    "1) **Column operations**\n",
    "\n",
    "  - **Selection**: If you have a DataFrame `df` and you want to select a column `col1` you can do it by `df[col1]`; if you have multiple columns `col1`, `col2`, `col3` you do it by `df[[col1, col2, col3]]`  \n",
    "  <img align=\"center\" src=\"../images/columns_1.png\" width=\"1000\" height=\"100\" />\n",
    "\n",
    "   Here, the column `Name` is selected and if you care to check its type, it is a **Series** object. \n",
    "\n",
    "  <img align=\"center\" src=\"../images/columns_2.png\" width=\"1000\" height=\"100\" />\n",
    "\n",
    "   Here, the columns `Name`, `HP` and `Attack` are selected \n",
    "   \n",
    "   - **Creation**: Now, you want to make a new column `Difference` which is the difference between `Attack` and `Defense` column for every Pokemon. How to do it? Its actually quite simple. As you already know every column is basically a pandas series object which is again a NumPy series. Provided the data types of the series match, you can add the values by a $+$ operator. In this case also, you will do the same and the syntax is: `df[new_column] = df[col1] + df[col2]` (You can also perform subtraction, division etc.)\n",
    "   \n",
    "   <img align=\"center\" src=\"../images/columns_3.png\" width=\"1000\" height=\"100\" />\n",
    "   \n",
    "   - **Deletion**: Now you want to delete the column `Difference` that you had just made. You can do it by `df.drop([col1, col2, ...], inplace=True, axis=0/1)`. Note that **inplace=True** deletes columns from the dataframe permanently and axis specifies whether to drop across columns (axis=$1$) or rows (axis=$0$) \n",
    "   \n",
    "   <img align=\"center\" src=\"../images/columns_4.png\" width=\"1000\" height=\"100\" />\n",
    "   \n",
    "2) **Row operations**\n",
    "\n",
    "  - **Selection**: You can access rows by either label of index using `loc` or integer (row number) using `iloc` keyword. \n",
    "  \n",
    "  Syntax using **`loc`**: `df.loc[index]`\n",
    "  \n",
    "  Syntax using **`iloc`**: `df.iloc[row number]`\n",
    "\n",
    "Example:\n",
    "\n",
    "| iloc | loc |\n",
    "| --- | --- |\n",
    "| <img align = \"left\" src=\"../images/iloc.png\" width=\"500\" height=\"100\" /> | <img src=\"../images/loc.png\" width=\"500\" height=\"100\" /> |\n",
    "   \n",
    "   In the images above both of them point to the same row; the first row can be accessed via `iloc[0]` and via `loc[299]` since it has index of $299$. Their output is also the same and it is:\n",
    "   \n",
    "   <img align=\"centre\" src=\"../images/result.png\" width=\"500\" height=\"100\" />\n",
    "\n",
    "   - **Slicing**: Use `df[start:end]` to slice rows according to **row number (not label)**; here end value is not inclusive. Heres how you can slice from row numbers $2$ and $3$: `df[2:4]`\n",
    "   \n",
    "   \n",
    "   - **Creation/Addition**:  Use `df.append(data)` where `data` is a DataFrame or Series/dictionary-like object, or list of these. In our Pokemon dataset, you want to add another Pokemon whose `#` value is $800$ and rest of its attributes are all $0$. Lets look at how you can add this new instance:\n",
    "   \n",
    "   <img align=\"left\" src=\"../images/add_row.png\" width=\"1000\" height=\"300\" />\n",
    "   \n",
    "   **Observe the last row. This is the one that we had created**.\n",
    "\n",
    "   \n",
    "   - **Deletion**: You can delete rows using the `.drop()` to drop rows by specifying **axis=0** inside the function. Also, you have the liberty to drop either by label or by position. In the example of addition of rows, observe that the new instance has an index label of $0$. Lets delete it permanently.\n",
    "   \n",
    "   <img align=\"center\" src=\"../images/delete_row.png\" width=\"1000\" height=\"500\" />\n",
    "\n",
    "   Now lets check whether this row was actually deleted; we already know that its index was $0$, so we will check its presence in the list of indices which are available in `df.index`\n",
    "   \n",
    "   <img align=\"center\" src=\"../images/check1.png\" width=\"1000\" height=\"500\" />\n",
    "  \n",
    "  Cool! This instance has been removed permanently. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find total power of the Pokemons\n",
    "\n",
    "In this task you will create a new column `Total` which is the sum of all the powers\n",
    "\n",
    "### Instructions\n",
    "- Make a new column `Total` which is the sum of all the powers i.e. `'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed'`\n",
    "- Print out the new column using `df[col]` where `col` is the column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      318\n",
      "1      405\n",
      "2      525\n",
      "3      625\n",
      "4      309\n",
      "5      405\n",
      "6      534\n",
      "7      634\n",
      "8      634\n",
      "9      314\n",
      "10     405\n",
      "11     530\n",
      "12     630\n",
      "13     195\n",
      "14     205\n",
      "15     395\n",
      "16     195\n",
      "17     205\n",
      "18     395\n",
      "19     495\n",
      "20     251\n",
      "21     349\n",
      "22     479\n",
      "23     579\n",
      "24     253\n",
      "25     413\n",
      "26     262\n",
      "27     442\n",
      "28     288\n",
      "29     438\n",
      "      ... \n",
      "770    525\n",
      "771    500\n",
      "772    431\n",
      "773    500\n",
      "774    300\n",
      "775    452\n",
      "776    600\n",
      "777    470\n",
      "778    309\n",
      "779    474\n",
      "780    335\n",
      "781    335\n",
      "782    335\n",
      "783    335\n",
      "784    494\n",
      "785    494\n",
      "786    494\n",
      "787    494\n",
      "788    304\n",
      "789    514\n",
      "790    245\n",
      "791    535\n",
      "792    680\n",
      "793    680\n",
      "794    600\n",
      "795    600\n",
      "796    700\n",
      "797    600\n",
      "798    680\n",
      "799    600\n",
      "Name: Total, Length: 800, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Code starts here\n",
    "\n",
    "# Create new column\n",
    "df['Total'] = df['HP'] + df['Attack'] + df['Defense'] + df['Speed'] + df['Sp. Atk'] + df['Sp. Def']\n",
    "print(df['Total'])\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints\n",
    "- Create the new column `'Total'` as \n",
    "```python\n",
    "df['Total'] = df['HP'] + df['Attack'] + df['Defense'] + df['Speed'] + df['Sp. Atk'] + df['Sp. Def']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Clean the data\n",
    "\n",
    "***\n",
    "\n",
    "The columns `Sp. Atk`, `Sp. Def` seem like really odd names to work with. Also, the `#` attribute doesn't seem to convey any type of information other than the fact that it is unique for every pokemon. So, the `Name` attribute is enough for describing and also it is convenient to call pokemons by their names rather than their ids. \n",
    "\n",
    "Also, instead of row labels as $[0,1,2,3,4,...]$ don't you think it would be helpful if you have Pokemons' names instead. Well, you should definitely do this!\n",
    "\n",
    "So, in this topic we will perform three operations which are described below:\n",
    "\n",
    "1) **Renaming columns**: To rename columns from `col1`, `col2` to `newcol1`, `newcol2`, use the function `.rename(columns={col1:newcol1, col2:newcol2}, inplace=True)` to permanently rename the columns.\n",
    "\n",
    "2) **Dropping columns**: You have already learnt how to do this.\n",
    "\n",
    "\n",
    "3) **Set index**: To set index labels for column `column`, use `set_index(column, inplace=True)`\n",
    "\n",
    "\n",
    "**Reset index in dataframes**\n",
    "\n",
    "Another operation which although is not covered in any of the tasks here but you would be frequently using while dealing with data is the `.reset_index()` method. In the image below in the first code snippet where we set the index of the dataframe according the values in `'#'` column.\n",
    "\n",
    "<img src='../images/set_index.png'>\n",
    "\n",
    "Now imagine you need to revert it to the original index form due to some reasons. You can do it with the `reset_index()` method. This method will simply push the index values into a column and set default values as index. \n",
    "\n",
    "This method is useful when the index needs to be treated as a column, or when the index is meaningless and needs to be reset to the default before another operation. \n",
    "\n",
    "<img src='../images/reset_index.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean !\n",
    "\n",
    "In this task you're going to apply some basic cleaning operations that you will encounter frequently while dealing with `pandas`. You're going to rename columns, drop columns permanently as well as re-index the dataframe.\n",
    "\n",
    "### Instructions\n",
    "- Rename the column `HP`, `Sp. Attack`, `Sp. Def` as `Health Points`, `Attack speed points` and `Defense speed points` respectively\n",
    "- Drop the column `#` permanently from the dataframe with `.drop()` method. Put `inplace=True` and `axis=1` inside the method\n",
    "- Set index to the `Name` column with `.set_index()` method. Here also, put `inplace=True` inside the method\n",
    "- Now look at the first five rows using `.head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Health Points</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Attack speed points</th>\n",
       "      <th>Defense speed points</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bulbasaur</th>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivysaur</th>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venusaur</th>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mega Venusaur</th>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charmander</th>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Type 1  Type 2  Health Points  Attack  Defense  \\\n",
       "Name                                                           \n",
       "Bulbasaur      Grass  Poison             45      49       49   \n",
       "Ivysaur        Grass  Poison             60      62       63   \n",
       "Venusaur       Grass  Poison             80      82       83   \n",
       "Mega Venusaur  Grass  Poison             80     100      123   \n",
       "Charmander      Fire     NaN             39      52       43   \n",
       "\n",
       "               Attack speed points  Defense speed points  Speed  Generation  \\\n",
       "Name                                                                          \n",
       "Bulbasaur                       65                    65     45           1   \n",
       "Ivysaur                         80                    80     60           1   \n",
       "Venusaur                       100                   100     80           1   \n",
       "Mega Venusaur                  122                   120     80           1   \n",
       "Charmander                      60                    50     65           1   \n",
       "\n",
       "               Legendary  Total  \n",
       "Name                             \n",
       "Bulbasaur          False    318  \n",
       "Ivysaur            False    405  \n",
       "Venusaur           False    525  \n",
       "Mega Venusaur      False    625  \n",
       "Charmander         False    309  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code starts here\n",
    "\n",
    "# Remove the '#' column permanently\n",
    "df.drop('#', inplace=True, axis=1)\n",
    "\n",
    "# Rename columns 'HP', 'Sp. Atk' and 'Sp. Def' as 'Health Points', 'Attack speed points' and 'Defense speed points'\n",
    "df.rename(columns={'HP':'Health Points', 'Sp. Atk': 'Attack speed points', 'Sp. Def': 'Defense speed points'}, inplace=True)\n",
    "\n",
    "# Set index as names\n",
    "df.set_index('Name', inplace=True)\n",
    "\n",
    "# Look at the first 5 observations\n",
    "df.head()\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints\n",
    "- To remove the `'#'` column permanently from `df` use:\n",
    "```python\n",
    "df.drop('#', inplace=True, axis=1)\n",
    "```\n",
    "- To rename the columns accordingly use:\n",
    "```python\n",
    "df.rename(columns={'HP':'Health Points', 'Sp. Atk': 'Attack speed points', 'Sp. Def': 'Defense speed points'}, inplace=True)\n",
    "```\n",
    "- To set index according to the names of the Pokemon i.e. by `'Name'` column:\n",
    "```python\n",
    "df.set_index('Name', inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Exploring categorical columns\n",
    "\n",
    "***\n",
    "\n",
    "Lets understand some functions which will help us analyse categorical columns better.\n",
    "\n",
    "1) `.value_counts()`: It gives a quick count of observations for each level. This doesn't count **NAs** and **can be applied on series objects; not dataframes**.\n",
    "\n",
    "2) `.unique()`: All the unique values present in the series, very similar to the `set()` function\n",
    "\n",
    "3) `nunique()`: Length of the list returned by `.unique()` method. It is the total number of unique elements in the series\n",
    "\n",
    "\n",
    "Now, we will take the help of the above three functions to answer these questions-\n",
    "\n",
    "- **How many different variants of Type 1 pokemons are there?**\n",
    "- **What are the different variants of Type 1?**\n",
    "- **What is the count for each variant of Type 1?**\n",
    "\n",
    "Look at the image below for the answers\n",
    "\n",
    " <img align=\"left\" src=\"../images/type_1.png\" width=\"700\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find out information of Pokemons based on `Type 2` attribute \n",
    "\n",
    "In this task you will answer three questions:\n",
    "- **How many different variants of `Type 2` pokemons are there?**\n",
    "- **What are the different variants of `Type 2`?**\n",
    "- **What is the count for each variant of `Type 2`?**\n",
    "- **How many Pokemons do not have `Type 2`?**\n",
    "\n",
    "### Instructions\n",
    "- Answer the above questions taking the help of the code snippet for `Type 2` attribute\n",
    "- The answer to the first question will be a number and save it as `type_two_num`. Use `.unique()` method on `'Type 2'` column\n",
    "- The second question will be a list containing the different types (ex: 'Grass', 'Fire' etc) for the type. Use `.unique()` on `'Type 2'` column and save it as `type_two`\n",
    "- To calculate the counts for different types for type, use `.value_counts()` on `'Type 2'`. Save it as `counts_type_two`. It will be a `Series` object\n",
    "- You can get the number of Pokemons which do not have any second type by simply inspecting the which values are null in `'Type 2'` column using `.isnull()` and then summing them up (use `.sum()` at the end of `isnull()`). Save it as `no_type_two`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "==================================================\n",
      "['Poison' nan 'Flying' 'Dragon' 'Ground' 'Fairy' 'Grass' 'Fighting'\n",
      " 'Psychic' 'Steel' 'Ice' 'Rock' 'Dark' 'Water' 'Electric' 'Fire' 'Ghost'\n",
      " 'Bug' 'Normal']\n",
      "==================================================\n",
      "Flying      97\n",
      "Ground      35\n",
      "Poison      34\n",
      "Psychic     33\n",
      "Fighting    26\n",
      "Grass       25\n",
      "Fairy       23\n",
      "Steel       22\n",
      "Dark        20\n",
      "Dragon      18\n",
      "Rock        14\n",
      "Water       14\n",
      "Ice         14\n",
      "Ghost       14\n",
      "Fire        12\n",
      "Electric     6\n",
      "Normal       4\n",
      "Bug          3\n",
      "Name: Type 2, dtype: int64\n",
      "==================================================\n",
      "386\n"
     ]
    }
   ],
   "source": [
    "# Code starts here\n",
    "\n",
    "# Different variants of `Type 2`\n",
    "type_two_num = df['Type 2'].nunique()\n",
    "print(type_two_num)\n",
    "print('='*50)\n",
    "\n",
    "# Total different types of `Type 2`\n",
    "type_two = df['Type 2'].unique()\n",
    "print(type_two)\n",
    "print('='*50)\n",
    "\n",
    "# Counts for different types of `Type 2`\n",
    "counts_type_two = df['Type 2'].value_counts()\n",
    "print(counts_type_two)\n",
    "print('='*50)\n",
    "\n",
    "# Number of Pokemons don't have `Type 2`\n",
    "no_type_two = df['Type 2'].isnull().sum()\n",
    "print(no_type_two)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints\n",
    "- The first question code is : `type_two_num = df['Type 2'].nunique()`\n",
    "- The second question can be answered as: `type_two = df['Type 2'].unique()`\n",
    "- The third question can be answered as: `counts_type_two = df['Type 2'].value_counts()`\n",
    "- The final question can be answered as: `no_type_two = df['Type 2'].isnull().sum()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Exploring numerical columns\n",
    "\n",
    "***\n",
    "\n",
    "Now you will explore the numerical attributes `'Health Points', 'Attack', 'Defense', 'Attack speed points', 'Defense speed points', 'Speed', 'Generation'`. Although they are numbers, we need to check if some of them actually represent categories. For example: We can bin $1000$ bats into $5$ categories and name them as $1$. $2$, $3$, $4$ and $5$. But that doesn't take away the fact that they are nothing but category. \n",
    "\n",
    "Let us check first which of these numberic attributes are actually categorical in nature. A simple strategy could be finding out the total number of unqiue values of the feature and dividing by the total number of instances of it. We will use `df[col].nunique` to calculate the number of unique values for `col` attribute.\n",
    "The ratio is around $0.0246$ which is very low. So, it can treated as representing a category.\n",
    "\n",
    "<img align=\"centre\" src=\"../images/categorical_check.png\" width=\"1000\" height=\"500\" />\n",
    "\n",
    "**So, can you answer which Pokemon has the highest `Attack` value? You can use the the `df[col].idxmax()` on a feature `col` to find this out. The output of this function gives the index for which the value/values of that column is maximum. Remember in our dataframe, the names of the Pokemon are in the index.**  \n",
    "\n",
    "A sample example is given below where we found the Pokemon with the highest `Attack` points:\n",
    "<img src='../images/idxmax.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Pokemon has the highest points?\n",
    "\n",
    "In this task you will inspect which Pokemon has the highest points in health, special attack, special defense and speed.\n",
    "\n",
    "### Instructions\n",
    "- You can find the index for a particular column at which the maximum value occurs by `dataframe[column].idxmax()`\n",
    "- Save the Pokemon with highest speed as `fastest_pokemon`, with highest health points as `healthiest_pokemon`, highest special attack points as `special_attack_pokemon` and highest special defense points as `special_defense_pokemon`\n",
    "- Print them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blissey\n",
      "==================================================\n",
      "Mega Mewtwo Y\n",
      "==================================================\n",
      "Shuckle\n",
      "==================================================\n",
      "Deoxys Speed Forme\n"
     ]
    }
   ],
   "source": [
    "# Code starts here\n",
    "\n",
    "# Which pokemon has the highest 'Health Points'?\n",
    "healthiest_pokemon = df['Health Points'].idxmax()\n",
    "print(healthiest_pokemon)\n",
    "print('='*50)\n",
    "\n",
    "# Which pokemon has the highest Special Atack points?\n",
    "special_attack_pokemon = df['Attack speed points'].idxmax()\n",
    "print(special_attack_pokemon)\n",
    "print('='*50)\n",
    "\n",
    "# Which pokemon has the highest Special Defense points?\n",
    "special_defense_pokemon = df['Defense speed points'].idxmax()\n",
    "print(special_defense_pokemon)\n",
    "print('='*50)\n",
    "\n",
    "# Which pokemon has highest Speed?\n",
    "fastest_pokemon = df['Speed'].idxmax()\n",
    "print(fastest_pokemon)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints:\n",
    "- The healthiest pokemon can be found out by: `df['Health Points'].idxmax()`\n",
    "- The Pokemon with highest Special Attack points can be found out by: `df['Attack speed points'].idxmax()`\n",
    "- The Pokemon with highest Special Defense points can be found out by: `df['Defense speed points'].idxmax()`\n",
    "- The fastest Pokemon can be found out by: `df['Speed'].idxmax()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "1. By which method can we get a summary of the numerical columns of a dataframe?\n",
    "\n",
    "    a. head()\n",
    "    \n",
    "    b. describe()\n",
    "    \n",
    "**ANS**: b. describe\n",
    "\n",
    "\n",
    "2. Which method is used to reset your index labels to a previous version?\n",
    "\n",
    "    a. index()\n",
    "    \n",
    "    b. reset_index()\n",
    "    \n",
    "**ANS**: b. reset_index()\n",
    "\n",
    "\n",
    "3. You have two columns col1 and col2; and now you want to add a third column col3 which is the product of the first two columns i.e. $col1*col2$. Which of the below is the appropriate syntax?\n",
    "\n",
    "    a. df[col3] = df[col1] + df[col2]\n",
    "    \n",
    "    b. df[col3] = df[col1] * df[col2]\n",
    "    \n",
    "    c. df[col1] * df[col2]\n",
    "    \n",
    "    d. None of the above\n",
    "    \n",
    "**ANS**: b. df[col3] = df[col1] * df[col2]\n",
    "\n",
    "\n",
    "4. How will you select the $200$th observation and its $5$th feature with pandas?\n",
    "\n",
    "    a. iloc[199,4]\n",
    "    \n",
    "    b. iloc[199,5]\n",
    "    \n",
    "    c. iloc[200,5]\n",
    "    \n",
    "    d. iloc[200,4]\n",
    "    \n",
    "**ANS**: a. iloc[199,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: Advanced pandas operations\n",
    "\n",
    "***\n",
    "\n",
    "### Description: In this chapter you will build on the basic operations and learn more about advanced operations in pandas\n",
    "\n",
    "### 3.1 Conditional filtering\n",
    "\n",
    "This is a very important way to filter out information according to some constraints. For example: We want to know in a sample of $50$ people how many of them are **man** but are **not wearing black**? You will often come across such type of conditional filtering operations where you will have to filter across multiple conditions on multiple features to prepare new data. \n",
    "\n",
    "You have already come across such a concept in NumPy where you use something like this `array[array > 5]` to mask or filter out values (in this example greater than 5). It works in the same way in `pandas` dataframes. \n",
    "\n",
    "Lets look at an example how it is done. Suppose you want only the Pokemons of the first generation, You can use `df[df['Generation'] == 1]` to do it which will generate a subset of data where pokemons are of first generation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer them\n",
    "\n",
    "In this task you will be answering the following questions:\n",
    "- Check if there any nan value present in the Pokemons names and remove them; if present\n",
    "- How many total possible combinations of `Type 1` and `Type 2` excluding Pokemons which do not have `Type 2`?\n",
    "- Which type (`Type 1`) has the highest number of Legendary Pokemons?\n",
    "- Find how many Pokemons which have a single type (`Type 1` present and `Type 2` absent)\n",
    "\n",
    "### Instructions\n",
    "**For the first question:**\n",
    "- First find the index where there is a `nan` value; the Boolean condition for finding that index is `dataframe.index.notnull()`\n",
    "- Put this condition on the dataframe with the help of conditional filtering by `dataframe[condition]` which will drop the row which has a `nan` index value\n",
    "- The new dataframe will not have any `nan` values in the index\n",
    "\n",
    "**For the second question:**\n",
    "- First create a new dataframe `both` which excludes all the missing values from the pokemon dataframe using `dataframe.dropna()`\n",
    "- On this new dataframe use `.drop_duplicates(subset=['Type1', 'Type 2'])` to find out the instances for unique combinations. Save the outcome to a variable `combinations`. To learn more about this function go through its [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop_duplicates.html)\n",
    "\n",
    "**For the third question:**\n",
    "- First use conditional filtering to get a dataframe that has only Legendary Pokemons\n",
    "- On this dataframe count the total number of unique instances of `Type 1` column with the help of `dataframe['Type 1'].value_counts()`. It will give you which types have how many legendary pokemons\n",
    "- To get the index with the maximum value use `.idxmax()` on the above series\n",
    "\n",
    "**For the fourth question:**\n",
    "- You'll create two Boolean conditions here; one will check if it has no `Type 2` and the other checks if it is `Legendary`\n",
    "- For the first Boolean condition (no `Type 2`) the condition will be `dataframe['Type 2'].isnull()` which returns a Boolean series consisting of `False` values for rows having null values on `Type 2` column\n",
    "- In the second condition, you can check for legendary status by `dataframe['Legendary'] == True` which returns `True` for all Legendary pokemons\n",
    "- Both these conditions need to be satisfied and hence join them by `and` keyword\n",
    "- Then apply conditional filtering on the dataframe and take its length using `len()` to get those Pokemons which have only `Type 1` and `Legendary`\n",
    "- Print out `combinations`, `highest_legendary` and `single_type_legendary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n",
      "Psychic\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "# Code starts here\n",
    "\n",
    "# Drop row with Name as nan\n",
    "df = df[df.index.notnull()]\n",
    "\n",
    "# Number of unique combinations of Type 1 and Type 2 (only for pokemons with both the types)\n",
    "both = df.dropna()\n",
    "combinations = len(both.drop_duplicates(subset=['Type 1', 'Type 2']))\n",
    "print(combinations)\n",
    "\n",
    "# Find out which type of pokemons (use only `Type 1`) have the highest chances of being Legendary\n",
    "highest_legendary = df[df['Legendary'] == True]['Type 1'].value_counts().idxmax()\n",
    "print(highest_legendary)\n",
    "\n",
    "# Pokemons which do not have 'Type 2' but are Legendary\n",
    "single_type_legendary = len(df[df['Type 2'].isnull() & df['Legendary'] == True])\n",
    "print(single_type_legendary)\n",
    "\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints\n",
    "**For the first question:**\n",
    "- The Boolean condition that checks for missing value is `df.index.notnull()`\n",
    "- Now apply this condition on `df` itself as `df = df[df.index.notnull()]`\n",
    "\n",
    "**For the second question:**\n",
    "- Create a new variable `both` which excludes Pokemons having no `Type 2` using `both = df.dropna()`\n",
    "- Then use `combinations = len(both.drop_duplicates(subset=['Type 1', 'Type 2']))` to find out the total number of possible combinations\n",
    "\n",
    "**For the third question:**\n",
    "- Use `highest_legendary = df[df['Legendary'] == True]['Type 1'].value_counts().idxmax()` to find out the answer\n",
    "\n",
    "**For the fourth question:**\n",
    "- Use `single_type_legendary = len(df[df['Type 2'].isnull() & df['Legendary'] == True])` to find out the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Apply functions\n",
    "\n",
    "Functions can be applied along the axes of a DataFrame using the `.apply()` method, which, like the descriptive statistics methods, takes an optional `axis` argument. By default, the operation performs column wise, taking each column as an array-like. Let us look at an example where we subtracted each value of the `Total` column by its mean over the feature and dividing by its range ($maximum - minimum$)\n",
    "\n",
    "\n",
    "<img align=\"centre\" src=\"../images/apply.png\" width=\"1000\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn to `apply`\n",
    "\n",
    "In this task you will make use of the `.apply()` function to modify the Pokemon names and both its types\n",
    "\n",
    "### Instructions\n",
    "- Convert index containing Pokemon names to upper case letters with `dataframe.index = dataframe.index.str.upper()`. **Remember that `.apply()` cannot be used with index labels**\n",
    "- Convert values in `Type 1` into lowercase letters with the `.lower()` method using `apply()`\n",
    "- Convert values in `Type 2` into lowercase if present and replace it with `None` if absent. The lambda function is `lambda x: x.lower() if isinstance(x, str) else None`; what it does essentially is convert the `Type 2` value to lowercase if it is a string or else it sets the value as `None` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code starts here\n",
    "\n",
    "# Convert 'Name' to uppercase\n",
    "index = [i.upper() for i in df.index.values]\n",
    "df.index = index\n",
    "\n",
    "# Convert 'Type 1' to lowercase\n",
    "df['Type 1'] = df['Type 1'].apply(lambda x: x.lower())\n",
    "\n",
    "# Convert 'Type 2' to lowercase if present else \n",
    "df['Type 2'] = df['Type 2'].apply(lambda x: x.lower() if isinstance(x, str) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints\n",
    "- To convert `'Name'` values to uppercase use `df.index = df.index.str.upper()` since you cannot use `apply` function for index labels\n",
    "- To convert `'Type 1'` values to lowercase use `df['Type 1'] = df['Type 1'].apply(lambda x: x.lower())`\n",
    "- To convert `'Type 2'` values to lowercase if present and replace by `'None'` if absent use `df['Type 2'] = df['Type 2'].apply(lambda x: x.lower() if isinstance(x, str) else None)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Groupby functions and sorting\n",
    "\n",
    "Now, we want to compare `Attack speed points` across categories of `Generation` for Pokemons. You might be tempted to use conditional filtering which in turn uses Boolean indexing to filter out values. But it has a downside; it will only result in binary outcomes i.e. either **Yes** or **No**. Writing separate functions for different categories is not advisable and here the `groupby` functions becomes important.\n",
    "\n",
    "As the name suggests, the groupby function divides our dataset into groups based on our choice of attribute. It is helpful in the sense that we can:\n",
    "- Compute summary statistics for every group\n",
    "- Perform group-specific transformations\n",
    "- Do filtration of data\n",
    "\n",
    "**Creating groups**\n",
    "\n",
    "In `pandas` we do it with the help of `.groupby()` function which returns a **GroupBy** object. Lets understand it through an example where we will group Pokemons according to `Generation`:\n",
    "\n",
    "<img align=\"centre\" src=\"../images/groupby_1.png\" width=\"1000\" height=\"500\" />\n",
    "\n",
    "You can also decide to group based on multiple attributes, for example:\n",
    "\n",
    "<img align=\"centre\" src=\"../images/groupby_2.png\" width=\"1000\" height=\"500\" />\n",
    "\n",
    "In this example, instances will are grouped according to their `Generation` and then for every category of `Generartion` are grouped by `Type 1` categories. We will see that in the later steps.\n",
    "\n",
    "\n",
    "**Inspecting groups**\n",
    "\n",
    "Now that we have created the groups, how to inspect them? Well, just use the `.groups` attribute of the groupby object. It returns a dictionary where **keys** are the categories and **values** are the row labels for that category. For example, if we do `df.groupby('Generation').groups` we will get a dictionary with categories of `Generation` as keys and row labels (names of Pokemons) as values.\n",
    "\n",
    "<img align=\"centre\" src=\"../images/groupby_5.png\" width=\"1000\" height=\"500\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Using aggregate functions on groups**\n",
    "\n",
    "The next logical step after grouping them is the operation we need to perform on these groups. Lets say we want to calculate the median value of `Attack speed points` for every `Generation`. \n",
    "\n",
    "<img align=\"centre\" src=\"../images/groupby_3.png\" width=\"1000\" height=\"500\" />\n",
    " \n",
    "Another way of doing the same operation is :\n",
    "\n",
    "<img align=\"centre\" src=\"../images/groupby_4.png\" width=\"1000\" height=\"500\" />\n",
    "\n",
    "Here we use `.agg()` inside which is a dictionary and the keys are the attributes and values are the statistic we want to calculate.\n",
    "\n",
    "\n",
    "\n",
    "**Sorting**\n",
    "\n",
    "Okay, now we want to sort the median value of `Attack speed points` for every `Generation` in descending order. We can do it with the help of `.sort_values(by=column, ascending=False)` where column is the name of the column we want to sort by and ascending=`True` if we want to sort in an ascending order. Lets see how it works out in our case\n",
    "\n",
    "<img align=\"centre\" src=\"../images/groupby_6.png\" width=\"1000\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which type (`Type 1`) Pokemons are the fastest?\n",
    "\n",
    "In this task you will use **groupby** to find the fastest Pokemons with the help of `Type 1` and `Speed` attributes. Also, you won't be using mean to aggregrate speed values for a group; you will use median.\n",
    "\n",
    "### Instructions\n",
    "- Groupby Pokemons on `Type 1` based on the attribute `Speed` and aggregate the types based on the median values of `Speed` using `.median()`\n",
    "- Then sort using `.sort_values(ascending=False)` to sort values in descending order\n",
    "- Pick out the index list using `.index` which gives the types (`Type 1`) and pick up the first index. Save it as `fastest_type` and print it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flying\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Code starts here\n",
    "\n",
    "# Determine which type (Type 1) pokemons are the fastest(Speed)\n",
    "fastest_type = df.groupby('Type 1')['Speed'].agg(np.median).sort_values(ascending=False).idxmax()\n",
    "print(fastest_type)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints\n",
    "- Use chaining of commands for getting the fastest Pokemon by: `fastest_type = df.groupby('Type 1')['Speed'].agg(np.median).sort_values(ascending=False).idxmax()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Pivot tables\n",
    "\n",
    "***\n",
    "\n",
    "You might be familiar with the concept of pivot tables ( if you use Excel) which enabled users to automatically sort, count, total, or average the data stored in one table. A typical example is shown below where we add the `Attack` values `Generation`-wise\n",
    "\n",
    "<img align=\"centre\" src=\"../images/pivot_excel.png\" width=\"1000\" height=\"500\" />\n",
    "\n",
    "The same operation can also be performed via `pandas.pivot(data, columns, index, aggfunc)` where\n",
    "- `data`: dataframe to be used for pivot operation\n",
    "- `columns`: Keys to group by on pivot table column\n",
    "- `index`: column/array to groupby our data (Will be displayed in the index column (or columns, if you're passing in a list)\n",
    "- `values` (optional): Column to aggregate (If we do not specify this then the function will aggregate all numeric columns)\n",
    "- `aggfunc`: Functions to be applied to for every group (by default computes mean)\n",
    "\n",
    "<img align=\"centre\" src=\"../images/pandas_pivot.png\" width=\"1000\" height=\"500\" />\n",
    "\n",
    "**The difference in the values is due to the cleaning we did, so do not get perplexed.**\n",
    "\n",
    "\n",
    "**Creating multi-index pivot tables**\n",
    "\n",
    "Let us observe an example where this time we will create a multi-index pivot table where we first group based on `Legendary` and then on `Generation` to find out the mean `Attack`. In other words, it gives us the mean `Attack` for every `Generation` and `Legendary` status \n",
    "\n",
    "<img align=\"centre\" src=\"../images/multiindex_pivot.png\" width=\"1000\" height=\"500\" />\n",
    "\n",
    "Another way to achieve the same result is using the `column` argument in the `.pivot_table()` method. If we pass `columns=Generation`, then it will group by `Legendary` and then group for every `Generation` and then calculate mean `Attack` across all of them.   \n",
    "\n",
    "<img align=\"centre\" src=\"../images/pivot_columns.png\" width=\"1000\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean value of Attack speed points across generations (on rows) and types (on columns)\n",
    "\n",
    "In this task you will use pivot tables to find mean `Attack speed points` for every `Generation` and within each generation for every type (`Type 1`)\n",
    "\n",
    "### Instructions\n",
    "- Use `.pivot_table()` on the dataframe with index as `Type 1`, values as `Attack speed points` and columns as `Generation`. Save it as `pivot` and print it out\n",
    "- By default pivot table calculates the mean for the column specified as the argument `values` inside `.pivot_table()` so no need to worry about that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation           1          2           3           4           5  \\\n",
      "Type 1                                                                  \n",
      "bug          46.428571  47.916667   48.333333   63.600000   62.888889   \n",
      "dark               NaN  85.000000   71.666667   95.000000   65.615385   \n",
      "dragon       73.333333        NaN  115.000000   72.500000   97.777778   \n",
      "electric     91.111111  91.428571   93.000000   90.416667   87.500000   \n",
      "fairy        77.500000  53.000000         NaN  120.000000         NaN   \n",
      "fighting     42.500000  35.000000   48.000000   96.666667   47.142857   \n",
      "fire         93.142857  83.625000   99.375000   99.000000   72.888889   \n",
      "flying             NaN        NaN         NaN         NaN  117.500000   \n",
      "ghost       128.750000  85.000000   65.800000   90.285714   91.000000   \n",
      "grass        90.538462  61.666667   80.923077   84.333333   69.266667   \n",
      "ground       39.375000  45.000000   76.428571   51.500000   61.600000   \n",
      "ice         105.000000  60.000000   82.142857   93.333333   80.000000   \n",
      "normal       55.125000  58.466667   53.222222   60.555556   54.473684   \n",
      "poison       57.142857  70.000000   72.000000   58.166667   50.000000   \n",
      "psychic     123.000000  84.285714   97.750000   80.625000   92.785714   \n",
      "rock         61.500000  66.000000   62.125000   44.833333   65.500000   \n",
      "steel              NaN  50.000000   65.416667   84.333333   68.750000   \n",
      "water        69.354839  68.277778   78.481481   81.153846   77.777778   \n",
      "\n",
      "Generation           6  \n",
      "Type 1                  \n",
      "bug          48.000000  \n",
      "dark         78.666667  \n",
      "dragon       82.250000  \n",
      "electric     83.666667  \n",
      "fairy        88.333333  \n",
      "fighting     63.000000  \n",
      "fire         88.500000  \n",
      "flying       71.000000  \n",
      "ghost        52.300000  \n",
      "grass        67.400000  \n",
      "ground             NaN  \n",
      "ice          38.000000  \n",
      "normal       46.750000  \n",
      "poison       78.500000  \n",
      "psychic     109.800000  \n",
      "rock         75.888889  \n",
      "steel        72.000000  \n",
      "water        85.200000  \n"
     ]
    }
   ],
   "source": [
    "# Code starts here\n",
    "\n",
    "# mean value of 'Attack speed points' according to 'Generation' and 'Type 1'\n",
    "pivot = df.pivot_table(index='Type 1', values='Attack speed points', columns='Generation')\n",
    "print(pivot)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints\n",
    "- To generate the pivot table use `pivot = df.pivot_table(index='Type 1', values='Attack speed points', columns='Generation')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Merge dataframes\n",
    "\n",
    "***\n",
    "\n",
    "**What do we mean by merging of dataframes?**\n",
    "\n",
    "If you have ever worked with databases you must be familiar with the concept of **merge** and **join** operations. The same behaviour in pandas can be achieved with the help of `pandas.merge()` and also the `pandas.join()` methods. **Merging** two or more datasets is the process of bringing them together into one, and aligning the rows from each based on common attributes or columns.\n",
    "\n",
    "\n",
    "**Avoid using for loops**\n",
    "\n",
    "Using `for` loops you can also achieve the same outcome; but it is not advisable as it results in more verbose code which runs slowly as compared to the `.merge()` and `.join()` functionalities provided by `pandas` module.\n",
    "So, if you ever come across such a situation, avoid using loops and isntead use the functionalities provided.\n",
    "\n",
    "\n",
    "**Syntax of merge**\n",
    "\n",
    "The syntax is `pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,\n",
    "left_index=False, right_index=False, sort=True)` where:\n",
    "- `left`: dataframe\n",
    "- `right`: dataframe\n",
    "- `on`: Columns (names) to join on. Must be found in both the left and right DataFrame objects.\n",
    "- `left_on`: Columns from the `left` DataFrame to use as keys (can either be column names or arrays with length equal to the length of the DataFrame).\n",
    "- `right_on`: Columns from the `right` DataFrame to use as keys (can either be column names or arrays with length equal to the length of the DataFrame).\n",
    "- `left_index`: If True, use the index (row labels) from the `left` DataFrame as its join key(s). In case of a DataFrame with a MultiIndex (hierarchical), the number of levels must match the number of join keys from the `right` DataFrame.\n",
    "- `right_index`: Same usage as `left_index` for the `right` DataFrame.\n",
    "- `how` − One of 'left', 'right', 'outer', 'inner'. Defaults to 'inner'\n",
    "- `sort` − Sort the result DataFrame by the join keys in lexicographical order. Defaults to `True`.\n",
    "\n",
    "**Remember that while using merge you should always specify the columns where to merge on (specified by the `on` argument inside `.merge()`)**\n",
    "\n",
    "\n",
    "### Joins in dataframes\n",
    " \n",
    "By default `pandas` merge function joins dataframes by inner join. An inner merge, (or inner join) keeps only the common values in both the left and right dataframes for the result. However, there are other types of joins or merge also possible with `pandas` module. Lets discuss them:\n",
    "\n",
    "1. **Inner Merge / Inner join:** The default `pandas` behaviour; only keep rows where the merge **on** value exists in both the left and right dataframes.\n",
    "2. **Left Merge / Left outer join(aka left merge or left join):** Keep every row in the `left` dataframe; where there are missing values of the **on** variable in the `right` dataframe, add empty / NaN values in the result.\n",
    "3. **Right Merge / Right outer join(aka right merge or right join):** Keep every row in the `right` dataframe; where there are missing values of the **on** variable in the `left` column, add empty / NaN values in the result.\n",
    "4. **Outer Merge / Full outer join** – A full outer join returns all the rows from the `left` dataframe, all the rows from the `right` dataframe, and matches up rows where possible, with NaNs elsewhere.\n",
    " \n",
    "The Venn diagram below will give you a more clear understanding of the merge operations \n",
    " \n",
    " <img align=\"centre\" src=\"../images/joins.png\" width=\"1000\" height=\"500\" />\n",
    " \n",
    " \n",
    "### Merge in practice\n",
    "\n",
    "Now lets take a look at how you can implement merging with `pandas`. Lets say we have two dataframes `attack` and `defense` describing the attacking and defensive powers of Pokemons along with their names present in both of the dataframes. The `attack` dataframe consists only of the row indices $[1,3,5,7,9]$ whereeas `defense` consists of the first $5$ rows.\n",
    "\n",
    "Left | Right \n",
    "- | - \n",
    " <img align=\"left\" src=\"../images/attack.png\" width=\"500\" height=\"500\" /> | <img align=\"right\" src=\"../images/defense.png\" width=\"500\" height=\"500\" />\n",
    " \n",
    "Now lets do some merge operations:\n",
    "\n",
    "1. **Inner merge:** Both the dataframes have only two rows in common; one with Pokemon `Ivysaur` and the other `Mega Venusaur` and since inner merge picks up only those rows common to both the dataframes, so we have the following result: Only two Pokemons **Ivysaur** and **Mega Venasaur** are common to the dataframes so while doing an inner merge it contains these two rows only.\n",
    "\n",
    " <img align=\"centre\" src=\"../images/inner.png\" width=\"1000\" height=\"500\" />\n",
    "\n",
    "\n",
    "2. **Outer merge:** It will return all the rows for both dataframes and will assign NaN values wherever the values are not present. The `attack` dataframe conatins Pokemons **Charmeleon, Mega Charizard X and Squirtle** which don't have any presence in the `defense` dataframe and so their defense attributes are **NaN**s. Similarly the instances which are in `defense` but not in `attack` will have their attack attributes represented by NaNs.\n",
    "\n",
    " <img align=\"centre\" src=\"../images/out.png\" width=\"1000\" height=\"500\" />\n",
    "\n",
    "\n",
    "3. **Left merge:** It will return a dataframe with all the possible columns from both `attack` and `defense` dataframe but containing only `attack` dataframe instances. So, there are **NaN**s where attribute values are absent.\n",
    "\n",
    " <img align=\"centre\" src=\"../images/left.png\" width=\"1000\" height=\"500\" />\n",
    "\n",
    "\n",
    "4. **Right merge:** It will return a dataframe with all the possible columns from both `attack` and `defense` dataframe but only for `defense` dataframe instances. So, there are **NaN**s where attribute values are absent\n",
    "\n",
    "\n",
    " <img align=\"centre\" src=\"../images/right.png\" width=\"1000\" height=\"500\" />\n",
    "\n",
    "\n",
    "### Can we track merges?\n",
    "\n",
    "In the process of merging dataframes you can often get confused where a particular instance came from; thanks to `pandas` you can now keep a track of the merge. Just pass the `indicator=True` inside the `.merge()` to view this. For example:\n",
    "\n",
    " <img align=\"centre\" src=\"../images/indicator.png\" width=\"1000\" height=\"500\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can you `merge`?\n",
    "\n",
    "In this task you will merge two dataframes `df1` and `df2` into one single dataframe. `df1` has column `fruit` and `df2` has column `product` which contain the same entity fruits; so you will be merging both of them. In a similar manner the columns `weight` and `kilo` on `df1` and `df2` respectively represent the weights of the fruits and so you will be merging on them as well. You will doing an `inner` merge operation that contains rows that are common to both these dataframes on these two pairs of columns.\n",
    "\n",
    "### Instructions\n",
    "- From the left dataframe i.e. `df1` you will be taking two columns for merging `fruit` and `weight`; so pass them as `left_on=['fruit','weight']` inside the `.merge()` method\n",
    "- Now from the right dataframe `df2` you are taking two columns for merging with the two columns from `df1`; so pass them as `right_on=['product', 'kilo']` inside `.merge()` method\n",
    "- Since it is an inner join pass `how='inner'` also\n",
    "- To distinguish the `price` attribute from the left and right dataframes for an instance, pass `suffixes=['_left', '_right']`\n",
    "- Store this dataframe inside a variable `merged` and print it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fruit weight  price_left product  kilo  price_right\n",
      "0   apple   high           4   apple  high           14\n",
      "1   apple   high           1   apple  high           14\n",
      "2   apple   high           4   apple  high           14\n",
      "3  orange    low           6  orange   low            7\n",
      "4  orange    low          13  orange   low            7\n",
      "5  orange    low           9  orange   low            7\n"
     ]
    }
   ],
   "source": [
    "# Input \n",
    "\n",
    "df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                    'weight': ['high', 'medium', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df2 = pd.DataFrame({'product': ['apple', 'orange', 'pine'] * 2,\n",
    "                    'kilo': ['high', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 6)})\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "merged = pd.merge(df1, df2, how='inner', left_on=['fruit', 'weight'], right_on=['product', 'kilo'], suffixes=['_left', '_right'])\n",
    "print(merged)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints\n",
    "- Remember you have to merge `df1` and `df2` by `inner` merge on columns `'fruit', 'weight'` coming from `df1` and `'product', 'kilo'` coming from `df2` with suffixes `'_left', '_right'`; so the commnand will be:\n",
    "```python\n",
    "merged = pd.merge(df1, df2, how='inner', left_on=['fruit', 'weight'], right_on=['product', 'kilo'], suffixes=['_left', '_right'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broad picture of pandas\n",
    "\n",
    "Before we close, let us reconcile the picture we began with - converting `raw` data into a cleaner form that is conducive for further processing. During this long journey of pandas you have done all sorts of data wrangling tasks (detecting missing values, renaming columns, dropping and replacing missing values) along with generating insights from the data. The raw data that we had was ambiguous which needed some amount of cleansing before we could gather any kind of information from it. \n",
    "\n",
    "<h3 style='color:red'>Before</h3>\n",
    "\n",
    "<img src='../images/before.png'>\n",
    "\n",
    "<h3 style='color:green'>After</h3>\n",
    "\n",
    "<img src='../images/after.png'>\n",
    "\n",
    "Look at this picture and reflect on the journey till now. If you are looking for insights and understanding from your data, think of which form of data you would prefer. \n",
    "- The new dataframe after all the tasks you have done has no ambiguity with the column names - the column names are more meaningful.\n",
    "- A new column `Total` was also created which is the sum of all the powers for a Pokemon - a value addition to previous dataframe.\n",
    "- `Type 2` null values were replaced with the `None` keyword and the row with null value for the name of the Pokemon was deleted. \n",
    "- Every instance has index as the name of the Pokemon which makes it more meaningful than random indices. \n",
    "\n",
    "Now all of these operations were possible due to the vast functions made available by `pandas`. **This dataset is now fit for doing any kind of Machine Learning task. For ex: Given other features predict whether the Pokemon is Legendary or not** and many more. Sometimes data wrangling alone might be insufficient and we might need to get visual summaries to get a better understanding on data. In the next chapter, we will look closely on how to visualize data effectively for insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "1. You have a pandas Series 'ser' which has numerical values in the range of 1-100. Suppose you apply conditional conditional filtering as mask = ser < 20. What data type is present in the variable mask?\n",
    "\n",
    "    a. Boolean\n",
    "    \n",
    "    b. Integers\n",
    "    \n",
    "    c. Floats\n",
    "    \n",
    "    d. None of the above\n",
    "    \n",
    "**ANS**: a. Boolean\n",
    "\n",
    "\n",
    "2. Which method you would use to group categories of a column using pandas?\n",
    "\n",
    "    a. groupby()\n",
    "    \n",
    "    b. describe()\n",
    "    \n",
    "    c. info()\n",
    "    \n",
    "**ANS**: a. groupby()\n",
    "\n",
    "\n",
    "3. Can we use the apply function for both rows and columns with dataframes?\n",
    "\n",
    "    a. YES\n",
    "    \n",
    "    b. NO\n",
    "    \n",
    "**ANS**: a. YES\n",
    "\n",
    "\n",
    "4. Can we track merges with merge() method of pandas?\n",
    "\n",
    "    a. YES\n",
    "    \n",
    "    b. NO\n",
    "    \n",
    "**ANS**: a. YES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept level quiz\n",
    "\n",
    "1. Pandas is designed to work with _______ data.\n",
    "\n",
    "    a. Relational \n",
    "    \n",
    "    b. Labeled\n",
    "    \n",
    "    c. Both of these\n",
    "    \n",
    "    d. None of these\n",
    "    \n",
    "**ANS**: c. Both of these\n",
    "\n",
    "\n",
    "2. DataFrame is usually a _______ labeled data structure.\n",
    "\n",
    "    a. 1-D\n",
    "    \n",
    "    b. 2-D\n",
    "    \n",
    "    c. None of these\n",
    "    \n",
    "    d. Both of them\n",
    "    \n",
    "**ANS** b. 2-D\n",
    "\n",
    "\n",
    "3. Pandas does easy handling of missing data in floating point as well as non-floating point data?\n",
    "\n",
    "    a. TRUE\n",
    "    \n",
    "    b. FALSE\n",
    "    \n",
    "**ANS**: a. TRUE\n",
    "\n",
    "\n",
    "4. Shape property in pandas is used to\n",
    "\n",
    "    a. Visualize the distribution of the data\n",
    "    \n",
    "    b. See the number of rows and columns of the data\n",
    "    \n",
    "    c. Visualise the shape of skewness of the data\n",
    "    \n",
    "    d. See the spread of data (mean, median etc.)\n",
    "    \n",
    "**ANS**: b. See the number of rows and columns of the data\n",
    "\n",
    "\n",
    "5. The _______ method allows us to retrieve rows and columns by position.\n",
    "\n",
    "    a. head\n",
    "    \n",
    "    b. getloc\n",
    "    \n",
    "    c. iloc\n",
    "    \n",
    "**ANS**: c. iloc\n",
    "\n",
    "\n",
    "6. Pivot table can aggregate the data and summarize it by grouping the columns\n",
    "\n",
    "    a. TRUE\n",
    "    \n",
    "    b. FALSE\n",
    "    \n",
    "**ANS**: a. TRUE\n",
    "\n",
    "\n",
    "7. _______ is a convenient method for combining the columns of two potentially differently-indexed DataFrames into a single result DataFrame.\n",
    "\n",
    "    a. concatenate\n",
    "    \n",
    "    b. merge\n",
    "    \n",
    "    c. join\n",
    "    \n",
    "    d. collaborate\n",
    "    \n",
    "**ANS**: c. join\n",
    "\n",
    "\n",
    "8. Dimensions should match along the axis you are _______ on\n",
    "\n",
    "    a. Concatenating\n",
    "    \n",
    "    b. Merging\n",
    "    \n",
    "    c. Joining\n",
    "    \n",
    "    d. Collaborating\n",
    "    \n",
    "**ANS**: a. Concatenating\n",
    "\n",
    "\n",
    "9. Series can have axis labels and it can be indexed by a label\n",
    "\n",
    "    a. TRUE\n",
    "    \n",
    "    b. FALSE\n",
    "    \n",
    "**ANS**: a. TRUE\n",
    "\n",
    "\n",
    "10. Which attribute is used to retrieve column names of a dataframe?\n",
    "\n",
    "    a. columns\n",
    "    \n",
    "    b. index\n",
    "    \n",
    "**ANS**: a. columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
