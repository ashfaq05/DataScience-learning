{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges in ML\n",
    "\n",
    "\"Machine learning is not rocket science, until you implement it\" \n",
    "\n",
    "-Anonymous\n",
    "\n",
    "\n",
    "Machine learning is one of the most interesting and intuitive concepts to learn but when dealing with real business data there comes certain challenges that a data scientist will have to figure out how to resolve.\n",
    "\n",
    "In this module, we will try to understand few of the common ML challenges and ways of overcoming them.\n",
    "\n",
    "## Overview:\n",
    "\n",
    "* What is Imbalanced Data\n",
    "\n",
    "\n",
    "* Dealing with imbalanced data\n",
    "    * Evaluation Metrics\n",
    "    * Resampling Techniques\n",
    "    * Algorithmic Techniques\n",
    "\n",
    "\n",
    "* Dealing with small datasets\n",
    "\n",
    "\n",
    "* Values of K in K-Fold validation\n",
    "\n",
    "\n",
    "* Do we need hundreds of classifiers?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: Black Art of Machine Learning\n",
    "\n",
    "### Description: This chapter will discuss few of the less discussed topics in ML textbooks which a practioner usually deals with on a daily basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Generalization of ML algorithms\n",
    "\n",
    "***\n",
    "\n",
    "Every machine learning algorithm can figure out how to perform important tasks by generalizing from examples. And this is often feasible and cost-effective than manual programming. With more availablilty of data, more ambitious problems can be tackled as a result of which the applications of machine learning is increasingly widely beyond the field of computer science. However, developing successful machine learning applications requires a substantial amount of \"black art\".\n",
    "\n",
    "One such hot topic is the **generizability** of ML algorithms. The fundamental goal of any ML algorithm is to perform well on unseen data, or in other words it should generalize well. To achieve it, one should **properly** set up development and test sets. \n",
    "\n",
    "Before the modern era of big data, it was a common rule in machine learning to use a random 70/30 split for training and test sets. This practice can work, but it's a bad idea for production grade ML algorithms. The purpose of the three splits viz. Training, Dev (Development) and Test sets:\n",
    "\n",
    "- __*Training set*__: Dataset where you run your learning algorithm on.\n",
    "- __*Dev (development) set*__: Dataset where you use to tune parameters, select features, and make other decisions regarding the learning algorithm (sometimes also called the hold-out cross validation set).\n",
    "- __*Test set*__: Dataset where you use to evaluate the performance of the algorithm, but not to make any decisions regarding what learning algorithm or parameters to use\n",
    "\n",
    "\n",
    "So, the **Dev** and **Test** sets will contribute a lot towards making the most important changes to your learning algorithm. With this thing in mind always: **\"Choose dev and test sets to reflect data you expect to get in the future and want to do well on\"** i.e. development and test sets must come from the same distribution. \n",
    "\n",
    "Lets take an example for this kind of scenario where your learning algorithm is performing well on the Dev set but on test set yields very poor results. What could have gone wrong? Multiple reasons are possible:\n",
    "- Overfitting is happening on dev set\n",
    "- Test set is harder than test set; in which case the algorithm is doing best but cannot improve further\n",
    "- The test set is different than the dev set. This scenario is the worst where one can spend lots of hours without improving the algorithmic performance.\n",
    "\n",
    "\n",
    "**Size of Dev and Test set**\n",
    "\n",
    "Another criteria while chosing dev and test sets is their size. In general, the size of the dev set should be big enough to detect performance differences between the algorithms that you are trying. For example, if classifier A has an accuracy of 90% and classifier B has an accuracy of 90.1%, then a dev set of 100 examples might not be able to detect this 0.1% difference. Another thing to ponder on is a 0.1% increase in peformance really desired? For companies dealing in advertisements, recommendations etc. this increase can drive significant revenues. But for research problems, this increase is not substantial at all and other avenues are often encouraged.\n",
    "\n",
    "\n",
    "**More data usually beats a cleverer algorithm**\n",
    "\n",
    "Situations may arise where you have to choose between more data and a more complex algorithm. Although you might be tempted to go with a more complex model, the more pragmatic choice is to add more training instances. As a rule of thumb, a dumb algorithm with lots and lots of data beats a clever one with modest amounts of it. Scalability is another issue that pops up with increase of data. Even though in principle more data means that more complex classifiers can be learned, in practice simpler classifiers wind up being used, because complex ones take too long to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 No Free Lunch\n",
    "\n",
    "***\n",
    "\n",
    "A machine learning model is a simplified representation of reality, and the simplifications are made to discard unnecessary detail and allow us to focus on the aspect of reality that we want to understand. However, these simplifications are grounded on some assumptions; these assumptions may hold in some situations, but may not hold in other situations. This implies that a model that explains a certain situation well may fail in another situation. That is why in both statistics and machine learning, we need to check our assumptions before relying on a model. And this is the very premise of the No Free Lunch Theorem\n",
    "\n",
    "\n",
    "**Statement of No Free Lunch Theorem (NFLT)**\n",
    "\n",
    "The **No Free Lunch Theorem** states that there is no one model that works best for every problem. Its essentially a proof that, averaged over all problems, no optimization algorithm is expected to perform better than any other search/optimization algorithm. The assumptions of a great model for one problem may not hold for another problem, so it is common in machine learning to try multiple models and find one that works best for a particular problem.\n",
    "\n",
    "\n",
    "**High level overview**\n",
    "\n",
    "The NLFT are a set of mathematical proofs and general framework that explores the connection between general-purpose algorithms that are considered \"black-box\" and the problems they solve. Many people often misunderstand it as it implies that there is not one single algorithm whose performance when averaged over every problem performs better than a random search. \n",
    "\n",
    "What it essentially implies is that one algorithm that searches for an optimal cost or fitness solution is not universally superior to any other algorithm. This is due to the huge potential problem space for the application of the general-purpose algorithm; if an algorithm is particularly adept at solving one class of problem, and the fitness surface that comes with it, then then it has to perform worse on the remaining average of problems. \n",
    "\n",
    "For ex: Suppose regression was your end goal and the data perfectly satisfies the assumptions of linear regression; then linear regression will do a great job at it while some complex model may perform worse. However, on another data source one may find out that a complex model like neural network satisfactorily outperforms any ML algorithm. \n",
    "\n",
    "Wolpert and Macready wrote in their paper, `No Free Lunch Theorems for Optimisation`:\n",
    "\n",
    "> “If an algorithm performs better than random search on some class of problems then in must perform worse than random search on the remaining problems.”\n",
    "\n",
    "<img src='../images/nlft.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Overfitting in high dimensional data\n",
    "\n",
    "***\n",
    "\n",
    "Probably the biggest problem after overfitting in machine learning is the curse of dimensionality. This expression was coined by Bellman in 1961 to refer to the fact that many algorithms that work fine in low dimensions become intractable when the input is high-dimensional.\n",
    "\n",
    "Lets take a sample use case where your goal is to build a classifier that classfies images as either cats or dogs. Also, you know that the color of the images is one key differentiator. \n",
    "\n",
    "So, you begin by taking the mean value of red color of the images as a single feature. So, you have a single feature and you decide to build a linear classifier with its help. Lets see how the decision boundary works:\n",
    "\n",
    "<img src='../images/1.png'>\n",
    "\n",
    "Since taking only one feature doesn't result in good partitioning, you decide to add another feature; the mean green color in the image. Lets see how this turns out:\n",
    "\n",
    "<img src='../images/2.png'>\n",
    "\n",
    "Still you are facing issues with classification and so you decide to add another feature this time; the mean value of blue color in the image. This turns out somewhat like this:\n",
    "\n",
    "<img src='../images/3.png'>\n",
    "\n",
    "In the three-dimensional feature space, you can now find a plane that perfectly separates dogs from cats. This means that a linear combination of the three features can be used to obtain perfect classification results for our case.\n",
    "\n",
    "<img src='../images/plane.png'>\n",
    "\n",
    "\n",
    "**Will performance keep increasing with increase in number of features?**\n",
    "\n",
    "Going by the cat-dog classifier logic, you might be tempted to think that as we go adding new features, the performance would increase. However, this is not the case and the performance actually goes down. \n",
    "\n",
    "This is due to overfitting as in higher dimensions the probability of finding a separable hyperplane is much more for the same number of training examples as compared to that of a hyperplane in a lower dimension. Again this is quite intuitive because the feature space (equal to number of dimensions) increases on addition of features but training data remains the same. This introduces a lot of sparsity in our feature space and for this reason it becomes much more easy to find a separable hyperplane because the likelihood that a training sample lies on the wrong side of the best hyperplane becomes infinitely small when the number of features becomes infinitely large. \n",
    "\n",
    "The performance varies with the number of dimensions as shown in the graph below i.e. performance increase only till you reach a certain optimal number of dimensions, then it starts reducing due to overfitting. \n",
    "\n",
    "<img src='../images/graph.png'>\n",
    "\n",
    "\n",
    "\n",
    "**How to avoid this overfitting problem?**\n",
    "\n",
    "A possible turnaround is to add more number of training examples. Lets understand how. Lets say we want to train a classifier using only a single feature whose value ranges from 0 to 1. Lets also assume that this feature is unique for each cat and dog. \n",
    "\n",
    "*With single feature*\n",
    "\n",
    "If we want our training data to cover 20% of this range, then the amount of training data needed is 20% of the complete population of cats and dogs. \n",
    "\n",
    "*With two features*\n",
    "\n",
    "Now, if we add another feature, resulting in a 2D feature space, things change; To cover 20% of the 2D feature range, we now need to obtain 45% of the complete population of cats and dogs in each dimension (0.45^2 = 0.2).\n",
    "\n",
    "*With three features*\n",
    "\n",
    "In the 3D case this gets even worse: to cover 20% of the 3D feature range, we need to obtain 58% of the population in each dimension (0.58^3 = 0.2).\n",
    "\n",
    "The phenomenon described by these three situations is appropriately summed up in the picture below. **So, the only way to avoid overfitting is by adding more number of training examples so that sparsity is not introduced.**\n",
    "\n",
    "<img src='../images/curse.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Intuition fails in higher dimensions\n",
    "\n",
    "***\n",
    "\n",
    "From the previous topic you know that as the number of features (dimensions) increases, there needs to be an exponential increase in the number of training examples in order to curb the problem of sparsity which can lead to overfitting if not dealt with properly. \n",
    "\n",
    "However, there is another problem with high dimensional data; **data is not distributed uniformly across all dimensions**. **In fact, data around the origin (at the center of the hypercube) is much more sparse than data in the corners of the search space**. This can be understood as follows:\n",
    "\n",
    "Imagine a unit square that represents the 2D feature space. The average of the feature space is the center of this unit square, and all points within unit distance from this center, are inside a unit circle that inscribes the unit square. The training samples that do not fall within this unit circle are closer to the corners of the search space than to its center. These samples are difficult to classify because their feature values greatly differs (e.g. samples in opposite corners of the unit square). Therefore, classification is easier if most samples fall inside the inscribed unit circle, illustrated by figure below:\n",
    "\n",
    "<img src='../images/circle.png'>\n",
    "\n",
    "\n",
    "An interesting question is now how the volume of the circle (hypersphere) changes relative to the volume of the square (hypercube) when we increase the dimensionality of the feature space. The volume of a unit hypercube of dimension d is always  $1^d = 1$ . The volume of the inscribing hypersphere of dimension d and with radius 0.5 can be calculated as:\n",
    "\n",
    "<img src='../images/eq.png'>\n",
    "\n",
    "<img src='../images/gp.png'>\n",
    "\n",
    "As seen from the above equation and the graph, the volume of the hypersphere tends to zero as the dimensionality tends to infinity, whereas the volume of the surrounding hypercube remains constant. This surprising and rather counter-intuitive observation partially explains the problems associated with the curse of dimensionality in classification: **In high dimensional spaces, most of the training data resides in the corners of the hypercube defining the feature space**. And as mentioned before, instances in the corners of the feature space are much more difficult to classify than instances around the centroid of the hypersphere.\n",
    "\n",
    "<img src='../images/wow.png'>\n",
    "\n",
    "The above image shows a 2D unit square, a 3D unit cube, and a creative visualization of an 8D hypercube which has 2^8 = 256 corners. For this 8-dimensional hypercube, about 98% of the data is concentrated in its 256 corners (found from the equation above). As a result, when the dimensionality of the feature space goes to infinity, the ratio of the difference in minimum and maximum Euclidean distance from sample point to the centroid, and the minimum distance itself, tends to zero: <img src='../images/eq_2.png'>\n",
    "\n",
    "Therefore, distance measures start losing their effectiveness to measure dissimilarity in highly dimensional spaces. Since classifiers depend on these distance measures (e.g. Euclidean distance, Mahalanobis distance, Manhattan distance), classification is often easier in lower-dimensional spaces where less features are used to describe the object of interest.\n",
    "\n",
    "\n",
    "**How to avoid curse of dimensionality?**\n",
    "\n",
    "As already seen above, the performance of a classifier decreases when the dimensionality of the problem becomes too large. The question then is what **too large’ means, and how overfitting can be avoided**. Regrettably there is no fixed rule that defines how many feature should be used in a classification problem. In fact, this depends on the amount of training data available, the complexity of the decision boundaries, and the type of classifier used.\n",
    "\n",
    "Some rules of thumb that you can follow are as follows:\n",
    "- *Training instances should be increased with addition of new features*: The smaller the size of the training data, the less features should be used. If N training samples suffice to cover a 1D feature space of unit interval size, then  $N^2$  samples are needed to cover a 2D feature space with the same density, and  $N^3$  samples are needed in a 3D feature space. In other words, the number of training instances needed grows exponentially with the number of dimensions used.\n",
    "- *Dimensionality should be kept low for algorithms with high variance*: Classifiers that tend to model non-linear decision boundaries very accurately (e.g. neural networks, KNN classifiers, decision trees) do not generalize well and are prone to overfitting. Therefore, the dimensionality should be kept relatively low when these classifiers are used.\n",
    "- *Dimensionality can be kept higher for algorithms with high bias*: For classifiers that generalize easily (e.g. naive Bayesian, linear classifier), the number of used features can be higher since the classifier itself is less expressive.\n",
    "- *Using feature selection techniques*: Use feature selection techniques like correlation, chi-square etc. to reduce the number of dimensions. Essentially what it achieves is select M features from a set of N features. \n",
    "- *Replace features by combination of features*: You can also try replacing set of N features by a set of M features, each of which is a combination of the original feature values. A very well known dimensionality reduction technique that yields uncorrelated, linear combinations of the original N features is Principal Component Analysis (PCA).\n",
    "- *Cross-validation techniques*: If the classification results on the subsets used for training greatly differ from the results on the subset used for testing, overfitting is in play. Several types of cross-validation such as k-fold cross-validation and leave-one-out cross-validation can be used if only a limited amount of training data is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Model interpretability\n",
    "\n",
    "***\n",
    "\n",
    "**What is interpretability and why is it important?**\n",
    "\n",
    "The use cases of ML algorithms are increasing day-by-day and along with that the impacts (direct or indirect) is increasing too. Naturally, the more a machine's decision affects a human's life, the more important it will be for the machine to explain its behaviour. So, interpretibility can be defined as **\"Interpretability is the degree to which a human can understand the cause of a decision\"**. \n",
    "\n",
    "\n",
    "**Interpretability helps in debugging and auditing ML models**\n",
    "\n",
    "Take the case of an ML model that decides on whether to approve loan applications or not. Due to some reasons, you suddenly find out that this model is biased towards one section of the society. Defintely you would want to avoid such a situation and debugging your model with the help of interpretibility can help you in finding out where your model is doing wrong. Even during production (assuming everything works fine before), your model might go wrong and starts discriminating. \n",
    "\n",
    "Interpreting a model can guide you as to where the model is making incorrect decisions and why is it doing so.\n",
    "\n",
    "\n",
    "**Interpretability for social acceptance**\n",
    "\n",
    "The process of integrating machines and algorithms into our daily lives demands interpretability to increase social acceptance. In a fast moving business world where decisions need to be taken quickly, a more interpretable model which explains the decision making process thoroughly will triumph over a very complex one with little or no interpretibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Data Imbalance\n",
    "\n",
    "***\n",
    "\n",
    "Spend enough time doing Machine Learning problems and you will definitely come across datasets having imbalanced data distribution. In imbalanced data, majority classes dominate over minority classes. In other words, number of observations belonging to one class are significantly higher(or lower) than the other class(es).\n",
    "\n",
    "Since most machine learning algoriths assume that data is equally distributed, applying them on imbalanced data often results in bias towards majority classes and poor classification of minority classes. That's why classical data imbalance problem is recognized as one of the major problems in the field of machine learning.\n",
    "\n",
    "Imbalanced datasets frequently occur in\n",
    "\n",
    "* Anomaly detection\n",
    "    * Fraudulent transactions in banks\n",
    "    * Electricity pilferage\n",
    "    \n",
    "* Predicting Rare events\n",
    "    * Ad click-through-rate (CTR) prediction (~1%)\n",
    "    * Identification of rare diseases\n",
    "    * User Churn (for example, user churn is ~2% in telecom industry)\n",
    "\n",
    "Let's look at detection of credit card fraud to understand this in more detail.\n",
    "\n",
    "\n",
    "**Credit Card Fraud Detection**\n",
    "\n",
    "Credit card fraud is a widespread problem and accounts for millions of dollars in loss.But, given the extremely high number of credit card transactions everyday, fraudulent transactions represent only a small fraction.\n",
    "\n",
    "Even then, fraudulent transactions have an outsized impact on the revenue, because almost the entire value of a fraudulent transaction counts towards loss (less insurance), whereas the profit from a genuine transaction is a fraction of the total transaction value.\n",
    "\n",
    "Thus it's more important to recall fraudulent transactions, even if that means we'll end up labeling some genuine transactions as fraud. \n",
    "\n",
    "Even though the typical datasets recording credit card transaction are very large (millions of row), the number of fraudulent records tend to be a very small fraction of the datasets - around 1% to 2%.\n",
    "Thus, if a given dataset of credit card transactions has a million row, only about 10,000 of them will be from fraudulent transactions.\n",
    "\n",
    "So why do machine learning models fail to predict the credit card frauds?\n",
    "\n",
    "\n",
    "**Bias in the model towards dominant class**\n",
    "\n",
    "Most machine learning models will end up predicting most of the transactions as genuine as they end up learning from mostly positive instances.\n",
    "\n",
    "Think of a scenario where you decide to go camping in a forest for two weeks. When you reach there, you find out that the forest is one of the largest habitat for snakes. During your first week, you do encounter lot of snakes and therefore become wary of them. In the next week, owing to rainfall, snakes sighting becomes less. Unfortunately though, you also become wary of long sticks and twigs. \n",
    "\n",
    "That is because you have formed a bias towards snakes(majority class) and end up labeling long twigs(minority class) as snakes\n",
    "\n",
    "\n",
    "**Difficulty in assessing model performance**\n",
    "\n",
    "For the credit card dataset discussed before, if we classify all transactions as genuine, we might still have an accuracy of 99%! (Bias towards dominant class)\n",
    "\n",
    "Let's look at a problem we are more likely to encounter in practice. \n",
    "\n",
    "Suppose we have built two models, A and B, to predict fraudulent transactions, and we want to select the one with better performance.\n",
    "\n",
    "\n",
    "**Model A**\n",
    "\n",
    "* Of the 99% genuine transactions, this model predicts 98.5% correctly\n",
    "* Of the 1% fraudulent transactions, this model predicts 0.25% correctly\n",
    "\n",
    "**Model accuracy: 98.75%**\n",
    "\n",
    "\n",
    "**Model B**\n",
    "\n",
    "* Of the 99% genuine transactions, this model predicts 98.25% correctly\n",
    "* Of the 1% fraudulent transactions, this model predicts 0.5% correctly\n",
    "\n",
    "**Model accuracy: 98.75%**\n",
    "\n",
    "* **Which of these two models performs better?**\n",
    "* **Which one of these two should we use?**\n",
    "\n",
    "\n",
    "* Clearly Model B is more valuable to us, but Accuracy, one of the most common metrics used in classification, fails to reflect that.\n",
    "\n",
    "* We need to use a metric that not only captures the class imbalance better, but one that also lets us make meaningful trade-offs between precision and recall.\n",
    "\n",
    "\n",
    "**Dealing with Imbalanced Data**\n",
    "\n",
    "Following are some of the ways to handle the imbalanced data:\n",
    "\n",
    "* More suited error metrics (comparatively immune to class imbalance)\n",
    "\n",
    "* Undersampling\n",
    "\n",
    "* Oversampling\n",
    "\n",
    "* Algorithmic techniques\n",
    "\n",
    "* Buy/Collect more data\n",
    "\n",
    "You will learn more about undersampling, oversampling and algorithmic techniques in the upcoming chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Better error metrics?\n",
    "\n",
    "## 2.1 Different error metrics\n",
    "\n",
    "The idea is to choose an error metric that is immune to class imbalance. As we saw earlier, accuracy is something that is not very robust against class imbalance. Following are a few examples of such error metrics\n",
    "\n",
    "* Confusion Matrix\n",
    "\n",
    "\n",
    "* Precision / Recall \n",
    "\n",
    "\n",
    "* F1 Score\n",
    "\n",
    "\n",
    "* AUC ROC\n",
    "\n",
    "\n",
    "* Cohen's Kappa\n",
    "\n",
    "\n",
    "We have already gone through all the metrics, except Cohen's kappa. \n",
    "Nevertheless let's refresh them one by one\n",
    "***\n",
    "**Confusion Matrix**\n",
    "\n",
    "The confusion matrix is a handy presentation of the accuracy of a model with two or more classes.\n",
    "\n",
    "Below is an example of a Confusion Matrix for our credit card fraud.\n",
    "\n",
    "\n",
    "\n",
    "| Value | Fraud  | Not Fraud |\n",
    "|---|---|---|\n",
    "| Predicted Fraud | 1 | 1 |\n",
    "| Predicted Not Fraud | 2 | 996 |\n",
    "\n",
    "Here,\n",
    "\n",
    "- **TP** = 1 i.e. actual **Fraud** and also predicted **Fraud**.\n",
    "\n",
    "- **FP** = 1 i.e. actual **Not Fraud** but predicted **Fraud**.\n",
    "\n",
    "- **FN** = 2 i.e. actual **Fraud** but predicted **Not Fraud**.\n",
    "\n",
    "- **TN** = 996 i.e. actual **Not Fraud** and predicted **Not Fraud**.\n",
    "\n",
    "***\n",
    "**Precision**\n",
    "\n",
    "For every predicted class, it is the fraction of the correct predictions to the total number of predictions for that class. It answers the question **Of all the values predicted as belonging to the class \"X\", what percentage is correct?** Mathematically,\n",
    "\n",
    "$$ Precision(P) = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "The precision in our example would be = $\\frac{1}{1 + 1} = \\frac{1}{2} = 0.5 $\n",
    "\n",
    "***\n",
    "**Recall**\n",
    "\n",
    "For every actual class, it is the fraction of the number of correct predictions to the total number of actual instances of the class. It answers the question **Of all the instances of the class \"X\", what percentage did we predict correctly?** Mathematically,        \n",
    "\n",
    "$$ Recall(R) = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "The recall in our previous example is = $\\frac{1}{1 + 2} = \\frac{1}{3} = 0.34$\n",
    "\n",
    "**Precision-Recall Tradeoff**\n",
    "\n",
    "Suppose two models: Model 1 and Model 2 are implemented on the credit fraud dataset. \n",
    "\n",
    "Following are the observations:\n",
    "\n",
    "* Model 1 is able to correctly predict `0`[Not Fraud] better than Model 2. Thereby Model 1 has lesser False Positives, thereby higher Precision \n",
    "\n",
    "* Model 2 is able to correctly predict `1`[Not Fraud] better than Model 1. Thereby Model 2 has lesser False Negatives, thereby higher Recall.\n",
    "\n",
    "Which model should we choose?\n",
    "\n",
    "This situation is what is known as **Precision-Recall Tradeoff!**\n",
    "For a given model, it is always possible to increase either statistic at the expense of the other.\n",
    "\n",
    "Choosing the preferred combination of precision and recall can be considered equivalent to sliding a dial between more or less conservative predictions (i.e. recall-focused vs. precision-focused). \n",
    "\n",
    "In the context of binary classification, examples are either positive or negative.\n",
    "\n",
    "The recall addresses the question: \"Given a positive example, will the classifier detect it ?\"\n",
    "\n",
    "The precision addresses the question: \"Given a positive prediction from the classifier, how likely is it to be correct ?\"\n",
    "\n",
    "So it depends if the focus is on positive examples or on positive predictions.\n",
    "\n",
    "**Precision** metric is more important for situations when you are more concerned about getting absolutely correct results.\n",
    "\n",
    "Some of the examples include:\n",
    "\n",
    "* YouTube video recommendations : You are concerned with giving few great recommendations than many average recommendations) \n",
    "\n",
    "* Stock prediction : Given the chance 200 of your units will stock out, you would be happy to get a list of high precision list of 60 units most likely to stock out than a list of 400 units which will result in wastage of money and resources spent on the extra 200 units)  \n",
    "\n",
    "**Recall** metric is more important when you really want to ensure you're definitely capturing positive cases or when the cost of missing a positive is more problematic than the cost of including a negative.\n",
    "\n",
    "Some of the examples include:\n",
    "\n",
    "* All disease prediction models: For eg: Not identifying a person having rare Cancer is much more fatal than accidentally identifying a healthy person having Cancer. \n",
    "\n",
    "* Identification of loan defaulters: The cost involved in letting a loan defaulter slip is more than the cost involved in surveying loan non-defaulters.\n",
    "\n",
    "Another thing to note that for a given model; a better model may in fact increase both precision and recall.\n",
    "\n",
    " \n",
    "***\n",
    "Getting back to our question, between Precision and Recall, which metric would have more importance in Credit Card Fraud Detection problem of ours?\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "**Ans.** The Credit Card Company would want higher recall over precision.That is, Credit Card Company would want a list that captures all the credit card frauds.\n",
    "\n",
    "Reason: The credit card company is ok with doing extra monitoring i.e. This list may also include cases where non fraud has been predicted as fraud(False positives).  The money spent on monitoring these already non fraud cases is worth it if we prevent just one major credit card fraud.\n",
    "\n",
    "What if we need a model that requires both good precision and recall?\n",
    "\n",
    "Enter `F1 Score`\n",
    "\n",
    "***\n",
    "\n",
    "**F1 Score**\n",
    "\n",
    "It is the harmonic mean of the precision and recall for a classifier. Mathematically, \n",
    "\n",
    "$$ F score = \\frac{2PR}{P + R}$$\n",
    "\n",
    "The F-score in our case is = $\\frac{2*0.5*0.34}{0.5 + 0.34} = \\frac{0.34}{0.84} = 0.40$\n",
    "\n",
    "***\n",
    "**Area under ROC Curve**\n",
    "\n",
    "Area under ROC Curve (or AUC for short) is a performance metric for binary classification problems.\n",
    "\n",
    "The AUC represents a model’s ability to discriminate between positive and negative classes.\n",
    "\n",
    "An area of 1.0 represents a model that made all predictions perfectly. An area of 0.5 represents a model as good as random.\n",
    "\n",
    "ROC is a graphical plot of **TPR** on the Y-axis and **FPR** on the X-axis\n",
    "\n",
    "\n",
    "**TPR** $=\\frac{TP}{TP + FN}$\n",
    "\n",
    "\n",
    "**FPR** $=\\frac{FP}{FP + FN}$\n",
    "\n",
    "***\n",
    "**Cohen's Kappa**\n",
    "\n",
    "The Kappa statistic (or value) is a metric that compares an Observed Accuracy with an Expected Accuracy (random chance). \n",
    "\n",
    "Let's understand how Cohen's kappa is defined using a confusion matrix\n",
    "![](../images/image20.png)\n",
    "\n",
    "Here, let's say rows (A) are the predicted values and columns (B) are the actual values.\n",
    "\n",
    "Now let's understand observed accuracy and expected accuracy.\n",
    "\n",
    "Observed Accuracy is simply the number of instances that were classified correctly throughout the entire confusion matrix.\n",
    "\n",
    "![](../images/image20.png)\n",
    "![](../images/image19.png)\n",
    "\n",
    "\n",
    "\n",
    "* Expected Accuracy is defined as the accuracy that any classifier would be expected to achieve by random chance.\n",
    "\n",
    "Sounds confusing? Let's break this down.\n",
    "\n",
    "Our classifier classifies \n",
    "* (a + b) observations as yes\n",
    "* (c + d) observations as no\n",
    "\n",
    "\n",
    "* Hence, the probability of a randomly chosen observation being classified as yes is (P1): (a + b) / (a + b + c + d)\n",
    "* And, the probability of a randomly chosen observation being classified as no is (P2): (c + d) / (a + b + c + d)\n",
    "\n",
    "\n",
    "Reality:\n",
    "* (a + c) observations as yes\n",
    "* (b + d) observations as no\n",
    "\n",
    "\n",
    "* Hence, the probability of a randomly chosen observation being classified as yes is (P3): (a + c) / (a + b + c + d)\n",
    "* And, the probability of a randomly chosen observation being classified as no is (P4): (b + d) / (a + b + c + d)\n",
    "\n",
    "Probability of a randomly chosen sample being *CORRECTLY* classified is \n",
    "\n",
    "* when the classifier classifies it as yes AND it is in reality yes: P1*P3\n",
    "* when the classifier classifies it as no AND it is in reality no: P2*P4\n",
    "\n",
    "Hence, Expected probability of a randomly chosen sample being *CORRECTLY* classified is: P1 x P3 + P2 x P4\n",
    "\n",
    "\n",
    "![](../images/image20.png)\n",
    "![](../images/image23.png)\n",
    "![](../images/image22.png)\n",
    "![](../images/image21.png)\n",
    "\n",
    "\n",
    "Great! now that we understand $P_o$ and $P_e$, Cohen's kappa is defined as\n",
    "\n",
    "![](../images/image24.png)\n",
    "\n",
    "* In essence, the kappa statistic is a measure of how closely the instances classified by the machine learning classifier matched the data labeled as ground truth, controlling for the accuracy of a random classifier as measured by the expected accuracy. \n",
    "\n",
    "\n",
    "* Not only can this kappa statistic shed light into how the classifier itself performed, the kappa statistic for one model is directly comparable to the kappa statistic for any other model used for the same classification task.\n",
    "\n",
    "\n",
    "* For any arbitrary accuracy value, more the Kappa value, better the performance.\n",
    "\n",
    "**Q:** Here is an example of 2 classifiers with given confusion matrix. Which one do you think is performing better? \n",
    "\n",
    "**Classifier A**\n",
    "\n",
    "![](../images/image25.png)\n",
    "\n",
    "**CLassifier B**\n",
    "\n",
    "![](../images/image27.png)\n",
    "\n",
    "**Ans:** It is apparent that for given accuracy, classifier A is doing a much better job at classifying than classifier B, which is also reflected in higher Kappa value attained by classifier A\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Python implementation\n",
    "\n",
    "Let's now deal with an actual credit card fraud dataset.\n",
    "\n",
    "**About the dataset**\n",
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. \n",
    "\n",
    "Feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. \n",
    "\n",
    "Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Logistic Regression model\n",
    "\n",
    "Let's create a logistic regression model for our credit card problem and check it's performance using the evaluation metrics we just discussed.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Load the dataset(zipped) from path using the `\"read_csv()\"` method from pandas with the parameters `path=path` and `compression='zip'` and store it in a variable called `'data'`\n",
    "\n",
    "- Store all the features of `'data'` in  a variable called `X`\n",
    "\n",
    "\n",
    "- Store the target variable (`Class`) of `'data'` in a variable called `y`\n",
    "\n",
    "\n",
    "- Split `'X'` and `'y'` into `X_train,X_test,y_train,y_test` using `train_test_split()` function. Use `test_size = 0.3` , `stratify=y`and `random_state = 0`\n",
    "\n",
    "**Note:** Here we are instead of normal split, we are doing 'statrified split'.\n",
    "\n",
    "'Stratified split' ensures that the proportion of majority class:minority class is same in both the test dataset and train dataset\n",
    "\n",
    "Hence we have given the value `y`(our target class) to the parameter `stratify`\n",
    "\n",
    "\n",
    "- Initialise a logistic regression model with `LogisticRegression()` with `random_state=0` and save it to a variable called `'model'`.\n",
    "\n",
    "\n",
    "- Fit the model on the training data `'X_train'` and `'y_train'` using the `'fit()'` method.\n",
    "\n",
    "- Store the prediction of `'X_test'` by `'model'` in a variable called `'y_pred'`\n",
    "\n",
    "\n",
    "- Find out the accuracy between `X_test` and `'y_test'` using the `'score()'` method and store it in a variable called `'accuracy'`\n",
    "\n",
    "- Find out the recall score between `y_test` and `'y_pred'` using the `'recall_score()'` method and store it in a variable called `'recall'`\n",
    "\n",
    "- Find out the precision score between `y_test` and `'y_pred'` using the `'precision_score()'` method and store it in a variable called `'precision'`\n",
    "\n",
    "- Find out the f1 score between `y_test` and `'y_pred'` using the `'f1_score()'` method and store it in a variable called `'f1'`\n",
    "\n",
    "- Find out the confusion matrix between `y_test` and `'y_pred'` using the `'confusion_matrix()'` method and store it in a variable called `'confusion_mat'`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9993270327998361\n",
      "recall: 0.6949152542372882\n",
      "precision: 0.8913043478260869\n",
      "f1_score: 0.780952380952381\n",
      "Confusion Matrix:\n",
      " [[34113     5]\n",
      " [   18    41]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#path\n",
    "path=\"../data/creditcard_new.zip\"\n",
    "\n",
    "#Code starts here\n",
    "#Reading of data file\n",
    "data= pd.read_csv(filepath_or_buffer =path,compression='zip' )\n",
    "\n",
    "\n",
    "#Extracting of features\n",
    "X=data.iloc[:,:-1]\n",
    "\n",
    "#Extracting of target\n",
    "y=data.iloc[:,-1]\n",
    "\n",
    "#Stratified splitting of test and train dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, stratify=y,random_state=0)\n",
    "                                         \n",
    "#Initialising model    \n",
    "model = LogisticRegression(random_state=0)\n",
    "\n",
    "#Fitting the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Making prediction of test values\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "#Finding accuracy score\n",
    "accuracy=model.score(X_test,y_test)\n",
    "print(\"Accuracy:\",accuracy)       \n",
    "\n",
    "#Finding recall score\n",
    "recall=recall_score(y_test, y_pred)\n",
    "print (\"recall:\",recall)\n",
    "\n",
    "#Finding precision score\n",
    "precision=precision_score(y_test, y_pred)\n",
    "print (\"precision:\",precision)\n",
    "\n",
    "#Finding f1 score\n",
    "f1=f1_score(y_test, y_pred)\n",
    "print (\"f1_score:\", f1)\n",
    "\n",
    "#Finding the confusion matrix\n",
    "confusion_mat=confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix:\\n\",confusion_mat)\n",
    "\n",
    "#Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3:  Undersampling\n",
    "\n",
    "## 3.1 What is Undersampling?\n",
    "\n",
    "Resampling methods are techniques in which , we try to **reduce the proportion of the dominant class by undersampling** from it, or we try to **increase the proportion of the minor class by oversampling** from it.\n",
    "\n",
    "However, some of the more successful approaches combine both oversampling and undersampling.\n",
    "\n",
    "Let's have a look at them one by one.\n",
    "\n",
    "\n",
    "Undersampling techniques try to balance out the classes by reducing the number of observations in the dominant classes. \n",
    "\n",
    "![](../images/image26.png)\n",
    "\n",
    "There are different approaches with which you can undersample. \n",
    "\n",
    "Few of the popular ones include:\n",
    "\n",
    "* Random Undersampling\n",
    "\n",
    "* Cluster Centroids\n",
    "\n",
    "* Tomek Links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.2 Random Undersampling\n",
    "***\n",
    "Random undersampling is one of the most intuitive and naive methods for undersampling. This method works by randomly choosing the samples from dominant classes. \n",
    "\n",
    "Let's understand the random undersampling by a few examples.\n",
    "\n",
    "**Example 1**\n",
    "* Total number of observations: 1000\n",
    "* Total number of classes: 2 (A, B)\n",
    "* Size of class A: 975\n",
    "* Size of class B: 25\n",
    "* Proportion of Minor class: 2.5%\n",
    "\n",
    "**Sampled Dataset**\n",
    "* From A, select 475 points randomly\n",
    "* From B, select all 25 points\n",
    "* Proportion of Minor class: 5%\n",
    "\n",
    "**Example 2**\n",
    "* Total number of observations: 1000\n",
    "* Total number of classes: 3 (A, B, C)\n",
    "* Size of class A: 925\n",
    "* Size of class B: 25\n",
    "* Size of class C: 50\n",
    "* Proportion of Minor classes: 2.5% (B) and 5% (C)\n",
    "\n",
    "**Sampled Dataset**\n",
    "* From A, select 425 points randomly\n",
    "* From B, select all 25 points\n",
    "* From C, select all 50 points\n",
    "* Proportion of Minor class: 5% (B) and 10% (C)\n",
    "\n",
    "\n",
    "**Python Implementation(using Imblearn)**\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "lis=np.zeros(970)\n",
    "\n",
    "y= np.ones(30) \n",
    "\n",
    "d=np.append(lis,y)\n",
    "\n",
    "e=np.asarray(list(range(0,len(lis)+len(y))))\n",
    "DF=pd.DataFrame({'Feature':e,'Class':d})\n",
    "\n",
    "# Before sampling \n",
    "print('\\nDistribution of target variable before Random UnderSampling:', Counter(DF['Class']))\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "\n",
    "x_sample,y_sample =  rus.fit_sample(DF['Feature'].values.reshape(-1,1),DF['Class'])\n",
    "    \n",
    "    \n",
    "#After Sampling    \n",
    "print('\\nDistribution of target variable after Random UnderSampling:', Counter(y_sample))\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Output\n",
    "\n",
    "```python\n",
    "Distribution of target variable before Random UnderSampling: Counter({0.0: 970, 1.0: 30})\n",
    "\n",
    "Distribution of target variable after Random UnderSampling: Counter({0.0: 30, 1.0: 30})\n",
    "```\n",
    "\n",
    "\n",
    "**Drawback:**\n",
    "\n",
    "Though one of the easiest sampling methods to implement, this method suffers from a major drawback of information loss.\n",
    "Add that with the random nature of this method of sampling and it results in unpredictable results\n",
    "\n",
    "In general, the more imbalanced the dataset the more samples will be discarded when undersampling, therefore throwing away potentially useful information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Random Undersampling\n",
    "\n",
    "Let's now try to see if random undersampling will improve the performance of our ML model\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Initialise a `RandomUnderSampler()` object with `random_state=0` and save it to a variable called `'rus'`.\n",
    "\n",
    "\n",
    "- Using `fit_sample()` method of `'rus'`, undersample `'X_train'` and `'y_train'` and store the new samples in variables `'X_sample2'` and `'y_sample2'`.\n",
    "\n",
    "\n",
    "- Initialise a logistic regression model with `LogisticRegression()` with `random_state=0` and save it to a variable called `'model_rus'`.\n",
    "\n",
    "\n",
    "- Fit the model on the training data `'X_sample2'` and `'y_sample2'` using the `'fit()'` method.\n",
    "\n",
    "- Store the prediction of `'X_test'` by `'model_rus'` in a variable called `'y_pred'`\n",
    "\n",
    "- Find out the accuracy between `X_test` and `'y_test'` using the `'score()'` method and save it in a variable called `'accuracy_rus'`\n",
    "\n",
    "\n",
    "- Find out the recall score between `y_test` and `'y_pred'` using the `'recall_score()'` method and store it in a variable called `'recall_rus'`\n",
    "\n",
    "- Find out the precision score between `y_test` and `'y_pred'` using the `'precision_score()'` method and store it in a variable called `'precision_rus'`\n",
    "\n",
    "\n",
    "- Find out the f1 score between `y_test` and `'y_pred'` using the `'f1_score()'` method and store it in a variable called `'f1_rus'`\n",
    "\n",
    "- Find out the confusion matrix between `y_test` and `'y_pred'` using the `'confusion_matrix()'` method and store it in a variable called `'confusion_mat_rus'`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9639816250694911\n",
      "recall: 0.9152542372881356\n",
      "precision: 0.0421875\n",
      "f1_score: 0.08065720687079911\n",
      "Confusion Matrix:\n",
      " [[32892  1226]\n",
      " [    5    54]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Code starts here\n",
    "# Create random under sampler object\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "\n",
    "#Undersampling the train data\n",
    "X_sample2, y_sample2 =  rus.fit_sample(X_train, y_train)\n",
    "sns.countplot(y_sample2)\n",
    "\n",
    "#Initiating a logistic regression model\n",
    "model_rus = LogisticRegression(random_state=0)\n",
    "\n",
    "#Fitting the model with sampled data\n",
    "model_rus.fit(X_sample2, y_sample2)\n",
    "\n",
    "#Making prediction of test values\n",
    "y_pred=model_rus.predict(X_test)\n",
    "\n",
    "#Finding the accuracy score\n",
    "accuracy_rus=model_rus.score(X_test,y_test)\n",
    "print(\"Accuracy:\",accuracy_rus)       \n",
    "\n",
    "#Finding the recall score\n",
    "recall_rus=recall_score(y_test, y_pred)\n",
    "print (\"recall:\",recall_rus)\n",
    "\n",
    "#Finding the precision score\n",
    "precision_rus=precision_score(y_test, y_pred)\n",
    "print (\"precision:\",precision_rus)\n",
    "\n",
    "#Finding the f1 score\n",
    "f1_rus=f1_score(y_test, y_pred)\n",
    "print (\"f1_score:\", f1_rus)\n",
    "\n",
    "#Finding the confusion matrix\n",
    "confusion_mat_rus=confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix:\\n\",confusion_mat_rus)\n",
    "\n",
    "#Code starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Cluster Centroids\n",
    "***\n",
    "This technique undersamples by replacing a cluster of majority samples.\n",
    "\n",
    "This method first finds the clusters of majority class with K-means algorithms.(You will learn about clustering algorithms later)\n",
    "\n",
    "In brief, what K-means algorithm does is, groups data points into `K` different groups(or clusters).\n",
    "\n",
    "\n",
    "Following is an example of data being clustered into 3 different clusters :\n",
    "\n",
    "![](../images/k_means.jpg)\n",
    "\n",
    "In cluster centroid undersampling,  only the cluster centroids(mid-points) of the K clusters are kept and considered as the new majority samples.    \n",
    "\n",
    "\n",
    "For e.g.\n",
    "\n",
    "Suppose you had a dataset where: \n",
    "    \n",
    "    * Size of minority class: 200\n",
    "    \n",
    "    * Size of majority class: 1000\n",
    "    \n",
    "\n",
    "Cluster centroids method works by creating 200(size of minority class) clusters of the majority class and returning the centroids of each of the clusters. \n",
    "\n",
    "Hence, rather than sampling from the original data points we get new representative sample. \n",
    "\n",
    "\n",
    "![cluster_centroid](../images/cluster_centroid.png)\n",
    "\n",
    "\n",
    "**Python Implementation**\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "    \n",
    "#Dataset creation\n",
    "X, y = create_dataset(n_samples=5000, weights=(0.01, 0.05, 0.94), class_sep=0.8)   ###\n",
    "\n",
    "                                \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 10))\n",
    "\n",
    "clf = make_pipeline(sampler, LinearSVC())                                  ###\n",
    "clf.fit(X, y)\n",
    "\n",
    "plot_decision_function(X, y, clf, ax1)                                     ###\n",
    "ax1.set_title('Original datapoints')\n",
    "\n",
    "\n",
    "#Cluster Centroids object\n",
    "sampler = ClusterCentroids(random_state=0)\n",
    "\n",
    "#Fitting and transforming data points\n",
    "X_res, y_res = sampler.fit_sample(X, y)\n",
    "\n",
    "#Plotting them\n",
    "plot_resampling(X_res, y_res, ax2)                                         ###\n",
    "ax2.set_title('Resampling using {}'.format(sampler.__class__.__name__))\n",
    "fig.tight_layout()\n",
    "    \n",
    "```\n",
    "**Output**\n",
    "\n",
    "\n",
    "![](../images/cc_2.png)\n",
    "\n",
    "\n",
    "**To know the working of functions accompanied by '###' , you can check out the [imblearn documentation](https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/under-sampling/plot_comparison_under_sampling.html#sphx-glr-auto-examples-under-sampling-plot-comparison-under-sampling-py)**\n",
    "\n",
    "\n",
    "**Drawback:**\n",
    "\n",
    "This method though theoretically is better at choosing than random undersampling, it results in creation of new datapoints(which at times not capture all the information) and hence results in indirect information loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task : Cluster Centroids\n",
    "\n",
    "Let's now try to see if cluster centroids will fare better than random undersampling.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Initialise a `ClusterCentroids()` object with `random_state=0` and save it to a variable called `'cc'`.\n",
    "\n",
    "\n",
    "- Using `fit_sample()` method of `'cc'`, undersample `'X_train'` and `'y_train'` and store the new samples in variables `'X_sample3'` and `'y_sample3'`.\n",
    "\n",
    "\n",
    "- Initialise a logistic regression model with `LogisticRegression()` with `random_state=0` and save it to a variable called `'model_cc'`.\n",
    "\n",
    "\n",
    "- Fit the model on the training data `'X_sample3'` and `'y_sample3'` using the `'fit()'` method.\n",
    "\n",
    "- Store the prediction of `'X_test'` by `'model_cc'` in a variable called `'y_pred'`\n",
    "\n",
    "- Find out the accuracy between `X_test` and `'y_test'` using the `'score()'` method and save it in a variable called `'accuracy_cc'`\n",
    "\n",
    "\n",
    "- Find out the recall score between `y_test` and `'y_pred'` using the `'recall_score()'` method and store it in a variable called `'recall_cc'`\n",
    "\n",
    "- Find out the precision score between `y_test` and `'y_pred'` using the `'precision_score()'` method and store it in a variable called `'precision_cc'`\n",
    "\n",
    "\n",
    "- Find out the f1 score between `y_test` and `'y_pred'` using the `'f1_score()'` method and store it in a variable called `'f1_cc'`\n",
    "\n",
    "- Find out the confusion matrix between `y_test` and `'y_pred'` using the `'confusion_matrix()'` method and store it in a variable called `'confusion_mat_cc'`\n",
    "\n",
    "## Note: Will take time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.894870819557012\n",
      "recall: 0.9661016949152542\n",
      "precision: 0.015625\n",
      "f1_score: 0.03075263015915835\n",
      "Confusion Matrix:\n",
      " [[30527  3591]\n",
      " [    2    57]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "\n",
    "#Code starts here\n",
    "\n",
    "#Initialising the cluster centroid model\n",
    "cc = ClusterCentroids(random_state=0)\n",
    "\n",
    "#Undersampling the data using cluster centroids\n",
    "X_sample3, y_sample3 = cc.fit_sample(X_train, y_train)\n",
    "sns.countplot(y_sample3)\n",
    "\n",
    "\n",
    "#Initialising logistic regression model\n",
    "model_cc = LogisticRegression(random_state=0)\n",
    "\n",
    "#Fitting the model with sampled data\n",
    "model_cc.fit(X_sample3, y_sample3)\n",
    "\n",
    "#Making predictions on test data\n",
    "y_pred=model_cc.predict(X_test)\n",
    "\n",
    "#Finding the accuracy score\n",
    "accuracy_cc=model_cc.score(X_test,y_test)\n",
    "print(\"Accuracy:\",accuracy_cc)       \n",
    "\n",
    "#Finding the recall score\n",
    "recall_cc=recall_score(y_test, y_pred)\n",
    "print (\"recall:\",recall_cc)\n",
    "\n",
    "#Finding the precision score\n",
    "precision_cc=precision_score(y_test, y_pred)\n",
    "print (\"precision:\",precision_cc)\n",
    "\n",
    "#Finding the f1 score\n",
    "f1_cc=f1_score(y_test, y_pred)\n",
    "print (\"f1_score:\", f1_cc)\n",
    "\n",
    "#Finding the confusion matrix\n",
    "confusion_mat_cc=confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix:\\n\",confusion_mat_cc)\n",
    "\n",
    "#Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Tomek Undersampling\n",
    "\n",
    "**Definition**\n",
    "\n",
    "Another way of undersampling the majority class is using 'Tomek Links'.\n",
    "\n",
    "Tomek Links are pairs of instances of opposite classes who are their own nearest neighbors.\n",
    "\n",
    "![](../images/tomek_1.jpeg)\n",
    "\n",
    "This technique of undersampling identifies Tomek Links and gets rid of the majority samples.\n",
    "The idea is to clarify the border between the minority and majority classes, making the minority region(s) more distinct. \n",
    "\n",
    "\n",
    "![](../images/tomek_2.jpeg)\n",
    "\n",
    "\n",
    "In the above diagram, `+` is the majority class and `O` is the minority class. Tomek links of `O` are identified and removed, thereby making it easier to define the minority class region of `+`.\n",
    "\n",
    "\n",
    "**Python Implementation**\n",
    "```python\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import TomekLinks \n",
    "\n",
    "#Creation of synthetic dataset\n",
    "X, y = make_classification(n_classes=2, class_sep=2,\n",
    "weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,\n",
    "n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\n",
    "\n",
    "#Original dataset target variable\n",
    "print('Distribution of target variable before Tomek Sampling:', Counter(y))\n",
    "\n",
    "#Tomeklink object creation\n",
    "tomek = TomekLinks()\n",
    "\n",
    "#Tomek Undersampling\n",
    "X_sample, y_sample = tomek.fit_sample(X, y)\n",
    "\n",
    "#After Tomek \n",
    "print('\\nDistribution of target variable after Tomek Sampling:', Counter(y_sample))\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**Output**\n",
    "\n",
    "```python\n",
    "Distribution of target variable before Tomek Sampling: Counter({1: 900, 0: 100})\n",
    "\n",
    "Distribution of target variable after Tomek Sampling: Counter({1: 897, 0: 100})\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Tomek Undersampling\n",
    "\n",
    "Let's see how well our model performs when we undersample using Tomek Links\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Initialise a `TomekLinks()` object with `random_state=0` and save it to a variable called `'tl'`.\n",
    "\n",
    "\n",
    "- Using `fit_sample()` method of `'tl'`, undersample `'X_train'` and `'y_train'` and store the new samples in variables `'X_sample4'` and `'y_sample4'`.\n",
    "\n",
    "\n",
    "- Initialise a logistic regression model with `LogisticRegression()` with `random_state=0` and save it to a variable called `'model_tl'`.\n",
    "\n",
    "\n",
    "- Fit the model on the training data `'X_sample4'` and `'y_sample4'` using the `'fit()'` method.\n",
    "\n",
    "- Store the prediction of `'X_test'` by `'model_tl'` in a variable called `'y_pred'`\n",
    "\n",
    "- Find out the accuracy between `X_test` and `'y_test'` using the `'score()'` method and save it in a variable called `'accuracy_tl'`\n",
    "\n",
    "\n",
    "- Find out the recall score between `y_test` and `'y_pred'` using the `'recall_score()'` method and store it in a variable called `'recall_tl'`\n",
    "\n",
    "- Find out the precision score between `y_test` and `'y_pred'` using the `'precision_score()'` method and store it in a variable called `'precision_tl'`\n",
    "\n",
    "\n",
    "- Find out the f1 score between `y_test` and `'y_pred'` using the `'f1_score()'` method and store it in a variable called `'f1_tl'`\n",
    "\n",
    "- Find out the confusion matrix between `y_test` and `'y_pred'` using the `'confusion_matrix()'` method and store it in a variable called `'confusion_mat_tl'`\n",
    "\n",
    "\n",
    "**Drawback:**\n",
    "\n",
    "This method is effective owing to its creation of better decision but if decision boundary is not clear it can result in removal of lot of samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999473330017263\n",
      "recall: 0.7796610169491526\n",
      "precision: 0.9019607843137255\n",
      "f1_score: 0.8363636363636364\n",
      "Confusion Matrix:\n",
      " [[34113     5]\n",
      " [   13    46]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Code starts here\n",
    "\n",
    "#Initialising Tomek Links object\n",
    "tl = TomekLinks(random_state=0)\n",
    "\n",
    "#Undersamlpling the train data\n",
    "X_sample4, y_sample4 = tl.fit_sample(X_train, y_train)\n",
    "sns.countplot(y_sample4)\n",
    "\n",
    "#Initialising the logistic regression model\n",
    "model_tl = LogisticRegression(random_state=0)\n",
    "\n",
    "#Fitting the model with sampled data\n",
    "model_tl.fit(X_sample4, y_sample4)\n",
    "\n",
    "#Making the predictions with test data\n",
    "y_pred=model_tl.predict(X_test)\n",
    "\n",
    "#Finding the accuracy score\n",
    "accuracy_tl=model_tl.score(X_test,y_test)\n",
    "print(\"Accuracy:\",accuracy_tl)       \n",
    "\n",
    "#Finding the recall score\n",
    "recall_tl=recall_score(y_test, y_pred)\n",
    "print (\"recall:\",recall_tl)\n",
    "\n",
    "#Finding the precision score\n",
    "precision_tl=precision_score(y_test, y_pred)\n",
    "print (\"precision:\",precision_tl)\n",
    "\n",
    "#Finding the f1 score\n",
    "f1_tl=f1_score(y_test, y_pred)\n",
    "print (\"f1_score:\", f1_tl)\n",
    "\n",
    "#Finding the confusion matrix\n",
    "confusion_mat_tl=confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix:\\n\",confusion_mat_tl)\n",
    "\n",
    "#Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Oversampling\n",
    "\n",
    "## 4.1 What is Oversampling?\n",
    "\n",
    "As opposed to undersamping, oversampling techniques try to make the classes balanced by enhancing the minority class using different techniques.\n",
    "\n",
    "![](../images/image29.png)\n",
    "\n",
    "There are different approaches with which you can oversample. \n",
    "\n",
    "Few of the popular ones include:\n",
    "\n",
    "* Random Oversampling\n",
    "\n",
    "* SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Random Oversampling\n",
    "\n",
    "Opposite to Random Undersampling, in Random Oversampling minority class samples are selected with replacement(repeated occurences) resulting in higher proportion of minority class samples.\n",
    "\n",
    "\n",
    "![ros](../images/ros.png)\n",
    "\n",
    "\n",
    "Let's understand better with numerical examples\n",
    "\n",
    "**Example 1**\n",
    "\n",
    "* Total number of observations: 1000\n",
    "* Total number of classes: 2 (A, B)\n",
    "* Size of class A: 975\n",
    "* Size of class B: 25\n",
    "* Proportion of Minor class: 2.5%\n",
    "\n",
    "\n",
    "Sampled Dataset\n",
    "* From A, select all 975 points\n",
    "* From B, select 225 points with replacement\n",
    "* Proportion of Minor class: 18.75%\n",
    "\n",
    "\n",
    "**Example 2**\n",
    "\n",
    "* Total number of observations: 1000\n",
    "* Total number of classes: 3 (A, B, C)\n",
    "* Size of class A: 925\n",
    "* Size of class B: 25\n",
    "* Size of class C: 50\n",
    "* Proportion of Minor classes: 2.5% (B) and 5% (C)\n",
    "\n",
    "**Sampled Dataset**\n",
    "* From A, select all 925 points\n",
    "* From B, select 225 points with replacement\n",
    "* From C, select 450 points with replacement\n",
    "* Proportion of Minor class: ~14% (B) and ~28% (C)\n",
    "\n",
    "\n",
    "\n",
    "**Python implementation**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "lis=np.zeros(970)\n",
    "\n",
    "y= np.ones(40) \n",
    "\n",
    "d=np.append(lis,y)\n",
    "\n",
    "e=np.asarray(list(range(0,len(lis)+len(y))))\n",
    "DF=pd.DataFrame({'Feature':e,'Class':d})\n",
    "\n",
    "# Before sampling \n",
    "print('\\nDistribution of target variable before Random OverSampling:', Counter(DF['Class']))\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "\n",
    "x_sample,y_sample =  ros.fit_sample(DF['Feature'].values.reshape(-1,1),DF['Class'])\n",
    "    \n",
    "    \n",
    "#After Sampling    \n",
    "print('\\nDistribution of target variable after Random OverSampling:', Counter(y_sample))\n",
    "    \n",
    "```\n",
    "**Output**\n",
    "\n",
    "```python\n",
    "Distribution of target variable before Random OverSampling: Counter({0.0: 970, 1.0: 40})\n",
    "\n",
    "Distribution of target variable after Random OverSampling: Counter({0.0: 970, 1.0: 970})\n",
    "```\n",
    "\n",
    "**Drawback:**\n",
    "\n",
    "Unlike random undersampling, no info loss happens. But in random oversampling(where the training and validation set contain the same sample) we can easily end up overfitting and having misleading results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Random Oversampling\n",
    "\n",
    "As mentioned, Oversampling has an advantage over undersampling in the form of no information loss.\n",
    "Let's see if our logistic regression model works better after random oversampling\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Initialise a `RandomOverSampler()` object with `random_state=0` and save it to a variable called `'ros'`.\n",
    "\n",
    "\n",
    "- Using `fit_sample()` method of `'ros'`, undersample `'X_train'` and `'y_train'` and store the new samples in variables `'X_sample5'` and `'y_sample5'`.\n",
    "\n",
    "\n",
    "- Initialise a logistic regression model with `LogisticRegression()` with `random_state=0` and save it to a variable called `'model_ros'`.\n",
    "\n",
    "\n",
    "- Fit the model on the training data `'X_sample5'` and `'y_sample5'` using the `'fit()'` method.\n",
    "\n",
    "- Store the prediction of `'X_test'` by `'model_ros'` in a variable called `'y_pred'`\n",
    "\n",
    "- Find out the accuracy between `X_test` and `'y_test'` using the `'score()'` method and save it in a variable called `'accuracy_ros'`\n",
    "\n",
    "\n",
    "- Find out the recall score between `y_test` and `'y_pred'` using the `'recall_score()'` method and store it in a variable called `'recall_ros'`\n",
    "\n",
    "\n",
    "- Find out the precision score between `y_test` and `'y_pred'` using the `'precision_score()'` method and store it in a variable called `'precision_ros'`\n",
    "\n",
    "\n",
    "- Find out the f1 score between `y_test` and `'y_pred'` using the `'f1_score()'` method and store it in a variable called `'f1_ros'`\n",
    "\n",
    "- Find out the confusion matrix between `y_test` and `'y_pred'` using the `'confusion_matrix()'` method and store it in a variable called `'confusion_mat_ros'`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9753402853364231\n",
      "recall: 0.891156462585034\n",
      "precision: 0.05895589558955896\n",
      "f1_score: 0.11059518784297172\n",
      "Confusion Matrix:\n",
      " [[83205  2091]\n",
      " [   16   131]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Code starts here\n",
    "\n",
    "#Initialising the random over sampler object\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "\n",
    "#Sampling the train data using random over sampling method\n",
    "X_sample5, y_sample5 = ros.fit_sample(X_train, y_train)\n",
    "sns.countplot(y_sample5)\n",
    "\n",
    "#Initialising a logsitic regression model\n",
    "model_ros = LogisticRegression(random_state=0)\n",
    "\n",
    "#Fitting the model with train data\n",
    "model_ros.fit(X_sample5, y_sample5)\n",
    "\n",
    "#Making predictions of the train data\n",
    "y_pred=model_ros.predict(X_test)\n",
    "\n",
    "#Finding the accuracy score\n",
    "accuracy_ros=model_ros.score(X_test,y_test)\n",
    "print(\"Accuracy:\",accuracy_ros)       \n",
    "\n",
    "#Finding the recall score\n",
    "recall_ros=recall_score(y_test, y_pred)\n",
    "print (\"recall:\",recall_ros)\n",
    "\n",
    "#Finding the precison score\n",
    "precision_ros=precision_score(y_test, y_pred)\n",
    "print (\"precision:\",precision_ros)\n",
    "\n",
    "#Finding the f1 score\n",
    "f1_ros=f1_score(y_test, y_pred)\n",
    "print (\"f1_score:\", f1_ros)\n",
    "\n",
    "#Finding the confusion matrix \n",
    "confusion_mat_ros=confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix:\\n\",confusion_mat_ros)\n",
    "\n",
    "#Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 SMOTE (Synthetic Minority Oversampling Technique)\n",
    "\n",
    "\n",
    "This method was introduced in the paper: [SMOTE: Synthetic Minority Over-sampling Technique](https://arxiv.org/pdf/1106.1813.pdf)\n",
    "\n",
    "\n",
    "**Definition**\n",
    "\n",
    "In this technique, the minority class is over-sampled by creating synthetic examples rather than by over-sampling with replacement. It does it by generating synthetic examples in a less application-specific manner i.e. by operating in feature space rather than data space.\n",
    "\n",
    "That way minority class is over-sampled by taking each minority class sample and introducing synthetic examples along the line segments joining any/all of the k minority class nearest neighbors.\n",
    "\n",
    "\n",
    "**Working**\n",
    "***\n",
    "![](../images/image32.png)\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "Given the following data distribution:\n",
    "\n",
    "![](../images/smote_1.png)\n",
    "\n",
    "Step 1: Ignore the majority class\n",
    "\n",
    "\n",
    "![](../images/smote_2.png)\n",
    "\n",
    "Step 2: Select one of the minority samples and chose its k nearest neighbours(or points)\n",
    "\n",
    "\n",
    "![](../images/smote_3.png)\n",
    "\n",
    "Depending upon the amount of over-sampling required, neighbors from the k nearest neighbors are randomly chosen.\n",
    "For instance, if the amount of over-sampling needed is 200%, only two neighbors from the five nearest neighbors are chosen and one sample is generated in the direction of each.\n",
    "\n",
    "\n",
    "**NOTE:** this k becomes a hyperparameter for SMOTE algorithm\n",
    "\n",
    "Step 3: SMOTE draws lines between existing minority instances like this.\n",
    "\n",
    "\n",
    "![](../images/smote_5.png)\n",
    "\n",
    "Step 4: SMOTE then imagines new, synthetic minority instances somewhere on these lines.\n",
    "\n",
    "\n",
    "![](../images/smote_6.png)\n",
    "\n",
    "Step 5: Repeat steps 2-4 for all the minority points\n",
    "\n",
    "\n",
    "**Python Implementation**\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "    \n",
    "#Dataset creation\n",
    "X, y = create_dataset(n_samples=10000, weights=(0.01, 0.05, 0.94))   ###\n",
    "\n",
    "                                \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 10))\n",
    "\n",
    "clf = make_pipeline(sampler, LinearSVC())                                  ###\n",
    "clf.fit(X, y)\n",
    "\n",
    "plot_decision_function(X, y, clf, ax1)                                     ###\n",
    "ax1.set_title('Original datapoints')\n",
    "\n",
    "\n",
    "#SMOTE object\n",
    "sampler = SMOTE(random_state=0)\n",
    "\n",
    "#Fitting and transforming data points\n",
    "X_res, y_res = sampler.fit_sample(X, y)\n",
    "\n",
    "#Plotting them\n",
    "plot_resampling(X_res, y_res, ax2)                                         ###\n",
    "ax2.set_title('Resampling using {}'.format(sampler.__class__.__name__))\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**Output**\n",
    "![SMOTE](../images/smote.png)\n",
    "\n",
    "\n",
    "**Drawback:**\n",
    "\n",
    "Because it operates by interpolating between rare examples, it can only generate examples within the body of available examples—never outside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: SMOTE Sampling\n",
    "\n",
    "Let's see if an advanced technique like SMOTE gives a better performance.\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Initialise a `SMOTE()` object with `random_state=0` and save it to a variable called `'smote'`.\n",
    "\n",
    "\n",
    "- Using `fit_sample()` method of `'smote'`, undersample `'X_train'` and `'y_train'` and store the new samples in variables `'X_sample6'` and `'y_sample6'`.\n",
    "\n",
    "\n",
    "- Initialise a logistic regression model with `LogisticRegression()` with `random_state=0` and save it to a variable called `'model_smote'`.\n",
    "\n",
    "\n",
    "- Fit the model on the training data `'X_sample6'` and `'y_sample6'` using the `'fit()'` method.\n",
    "\n",
    "- Store the prediction of `'X_test'` by `'model_smote'` in a variable called `'y_pred'`\n",
    "\n",
    "- Find out the accuracy between `X_test` and `'y_test'` using the `'score()'` method and save it in a variable called `'accuracy_smote'`\n",
    "\n",
    "\n",
    "- Find out the recall score between `y_test` and `'y_pred'` using the `'recall_score()'` method and store it in a variable called `'recall_smote'`\n",
    "\n",
    "- Find out the precision score between `y_test` and `'y_pred'` using the `'precision_score()'` method and store it in a variable called `'precision_smote'`\n",
    "\n",
    "\n",
    "- Find out the f1 score between `y_test` and `'y_pred'` using the `'f1_score()'` method and store it in a variable called `'f1_smote'`\n",
    "\n",
    "- Find out the confusion matrix between `y_test` and `'y_pred'` using the `'confusion_matrix()'` method and store it in a variable called `'confusion_mat_smote'`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9842936226490174\n",
      "recall: 0.8843537414965986\n",
      "precision: 0.08934707903780069\n",
      "f1_score: 0.16229712858926343\n",
      "Confusion Matrix:\n",
      " [[83971  1325]\n",
      " [   17   130]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "#Code starts here\n",
    "\n",
    "#Initialising a SMOTE object\n",
    "smote = SMOTE(random_state=0)\n",
    "\n",
    "#Sampling the data using SMOTE\n",
    "X_sample6, y_sample6 = smote.fit_sample(X_train, y_train)\n",
    "sns.countplot(y_sample6)\n",
    "\n",
    "#Initialising Logistic Regression model\n",
    "model_smote = LogisticRegression(random_state=0)\n",
    "\n",
    "#Fitting the model on train data\n",
    "model_smote.fit(X_sample6, y_sample6)\n",
    "\n",
    "#Making predictions on test data\n",
    "y_pred=model_smote.predict(X_test)\n",
    "\n",
    "#Finding the accuracy score \n",
    "accuracy_smote=model_smote.score(X_test,y_test)\n",
    "print(\"Accuracy:\",accuracy_smote)       \n",
    "\n",
    "\n",
    "#Finding the recall score\n",
    "recall_smote=recall_score(y_test, y_pred)\n",
    "print (\"recall:\",recall_smote)\n",
    "\n",
    "#Finding the precision score\n",
    "precision_smote=precision_score(y_test, y_pred)\n",
    "print (\"precision:\",precision_smote)\n",
    "\n",
    "#Finding the f1 score\n",
    "f1_smote=f1_score(y_test, y_pred)\n",
    "print (\"f1_score:\", f1_smote)\n",
    "\n",
    "#Finding the confusion matrix\n",
    "confusion_mat_smote=confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix:\\n\",confusion_mat_smote)\n",
    "\n",
    "#Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Summary\n",
    "\n",
    "Before we go ahead to the next chapter, let's summarise the performance of all resampling methods for our credit card problem.\n",
    "\n",
    "|Resampling Method|Accuracy|Precision|Recall|F1 Score|\n",
    "|-----|-----|-----|-----|----|\n",
    "|None|0.99|0.89|0.69|0.78|\n",
    "|Random Undersampling|0.96|0.04|0.92|0.08|\n",
    "|Cluster Centroids|0.89|0.02|0.97|0.03|\n",
    "|Tomek Links|0.99|0.90|0.78|0.83|\n",
    "|Random Oversampling|0.98|0.06|0.89|0.11|\n",
    "|SMOTE|0.98|0.09|0.88|0.16|\n",
    "\n",
    "**Things to ponder**\n",
    "\n",
    "1. Despite having **similar accuracy** scores, you can clearly see how different their **precision** and **recall** scores are.\n",
    "\n",
    "\n",
    "2. Recall is the highest in Cluster Centroids. So is that the best resampling method for our problem?\n",
    "\n",
    "\n",
    "3. Someone tells you Tomek Links looks like the best resampling method for our problem. Do you agree or disagree? Why?\n",
    "\n",
    "The importance of knowing which sampling method to use is as important knowing if using sampling methods will achieve increase in model performance. \n",
    "\n",
    "As a thumb rule, use sampling methods only when you have `enough` and `varied` samples of minority class.\n",
    "Sampling usually helps when the model is biased towards majority class despite having a good sample of minority class. It's wishful thinking to assume sampling methods will magically improve the quality of minority target class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Chapter 5: Algorithmic Approach\n",
    "***\n",
    "\n",
    "## 5.1 Different Algorithmic approaches\n",
    "\n",
    "Algorithmic approach involves using different techniques to tweak the algorithms and make them learn minority classes \n",
    "\n",
    "Some of them include:\n",
    "\n",
    "- Cost Sensitive Training (Penalised Training)\n",
    "\n",
    "- Choice of Algorithm\n",
    "\n",
    "\n",
    "\n",
    "**Cost Sensitive Training (Penalised Training):** \n",
    "***\n",
    "\n",
    "This step involves creating a custom metric which penalizes wrong predictions in the minority class.\n",
    "\n",
    "For eg:\n",
    "\n",
    "For our credit card problem, since false negative is more undesirable than false positive, our metric could be something like:\n",
    "* metric=(5 ∗ false negative + 1 ∗ false positive) / 6\n",
    "\n",
    "Such metrics could be used in handling the imbalanced datasets and [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html) provides a method to device custom metrics.\n",
    "\n",
    "**Choice of Algorithm:**\n",
    "***\n",
    "Ensemble methods, especially Random Forests are found to be good at handling imbalanced datasets. These methods are able to learn classes based on importance assigned to them.\n",
    "\n",
    "Sklearn's implementations of these algorithms provides option to handle imbalanced dataset by setting the **`class_weight`** parameter.\n",
    "\n",
    "```python\n",
    "#Creating list of class weights\n",
    "class_wts = range(50)\n",
    "\n",
    "f1s = []\n",
    "auc = []\n",
    "#Loop to iterate different weights to the minority class(1) \n",
    "for wt in class_wts:\n",
    "    rf7 = RandomForestClassifier(random_state=0, class_weight={0:1,1:wt})\n",
    "    rf7.fit(X_train, y_train)\n",
    "    f1s.append(f1_score(y_test, rf7.predict(X_test)))\n",
    "    auc.append(roc_auc_score(y_test, rf7.predict(X_test)))\n",
    "    \n",
    "    \n",
    "#Selecting the max f1 score    \n",
    "max_scorer = f1s.index(np.max(f1s))\n",
    "\n",
    "#Selecting the model with the max score\n",
    "rf7 = RandomForestClassifier(random_state=9, class_weight={0:1,1:max_scorer})\n",
    "rf7.fit(X_train, y_train)\n",
    "\n",
    "print (\"F1 score:\", f1_score(y_test, rf7.predict(X_test)))\n",
    "print (\"Precision:\",precision_score(y_test, rf7.predict(X_test)))\n",
    "print (\"Recall:\",recall_score(y_test, rf7.predict(X_test)))\n",
    "print (\"ROC Score:\",roc_auc_score(y_test, rf7.predict(X_test)))\n",
    "print (\"Confusion Matrix:\\n\",confusion_matrix(y_test, rf7.predict(X_test)))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(class_wts, f1s, label=\"F1 scores\")\n",
    "plt.plot(class_wts, auc, label=\"AUC scores\")\n",
    "plt.xlabel(\"class weight\")\n",
    "plt.ylabel(\"scores\")\n",
    "plt.title(\"Effect of Class Wt. in Imbalanced Classes\")\n",
    "plt.ylim(0.45,1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Output**\n",
    "\n",
    "```python\n",
    "F1 score: 0.8095238095238095\n",
    "\n",
    "Precision: 0.8947368421052632\n",
    "\n",
    "Recall: 0.7391304347826086\n",
    "\n",
    "ROC Score: 0.8694948840110821\n",
    "\n",
    "Confusion Matrix:\n",
    "[[14216     2]\n",
    " [    6    17]]\n",
    "\n",
    "```\n",
    "\n",
    "![class_wt](../images/class_wt.png)\n",
    "\n",
    "\n",
    "**Other useful tips**\n",
    "***\n",
    "\n",
    "* While carrying out cross-validation, make stratified folds to make sure the presence of minority class in all folds.\n",
    "\n",
    "\n",
    "* Instead of predictions, get probabilities from the trained classifier. \n",
    "\n",
    "\n",
    "* Study the AUC-ROC curve and adjust the prediction threshold.\n",
    "\n",
    "\n",
    "Phew! That's a lot of imbalance-data handling methods to onboard. \n",
    "\n",
    "\n",
    "Even then, there are a lot more techniques that can be employed. \n",
    "\n",
    "So, if you do struggle, it might be worth checking out `imblearn's` [official documentation](https://imbalanced-learn.readthedocs.io/en/stable/index.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 :Other Challenges\n",
    "\n",
    "## 6.1 Handling Other Challenges \n",
    "After concluding the discussion on imbalanced datasets, let's discuss other challenges that might pop up.\n",
    "\n",
    "**6.1 Dealing with Smaller Datasets:**\n",
    "***\n",
    "\n",
    "Sometimes, challenge arises not because of too much data, but because of too less data. Such a scenario is known as  **the curse of dimensionality**, which essentially means **number of features >> number of observations**\n",
    "\n",
    "In case of such small datasets, following are some of the techniques that could come in handy\n",
    "    \n",
    "    * Exploit Bootstrapping\n",
    "    \n",
    "    * Use Simpler, Regularized Models\n",
    "    \n",
    "    * Use Ensemble Techniques(Discussed in the next modules)\n",
    "    \n",
    "    * Use Support Vector Machines(Discussed in next modules)\n",
    "    \n",
    "    \n",
    "**6.2 Value of K in K-Folds**\n",
    "\n",
    "One challenge also arises in deciding the value of k in k-fold validation.\n",
    "\n",
    "***\n",
    "Why do we use cross-validation?\n",
    "\n",
    "Cross Validation is used to assess the predictive performance of the models by testing it on unseen data or test data\n",
    "\n",
    "The motivation to use cross validation techniques is that when we fit a model, we are fitting it to a training dataset. Without cross validation we only have information on how does our model perform to our in-sample data. Ideally we would like to see how does the model perform when we have a new data in terms of accuracy of its predictions. \n",
    "***\n",
    "***\n",
    "What is K-Fold validation?\n",
    "\n",
    "It's a form of cross validation where a given data sample is split into k number of groups.\n",
    "\n",
    "\n",
    "Following are it's steps\n",
    "\n",
    "- Split the dataset into k groups\n",
    "\n",
    "\n",
    "- For each unique group:\n",
    "\n",
    "    - Take that group as a hold out or test data set\n",
    "    \n",
    "    - Take the remaining groups as a training data set\n",
    "    \n",
    "    - Fit the specific model on the training set and evaluate it on the test set\n",
    "    \n",
    "    - Retain the evaluation score and discard the model\n",
    "    \n",
    "    - Aggregate all the evaluation scores to summarize\n",
    "    \n",
    "    \n",
    "![k-folds](../images/kfold.png)    \n",
    "\n",
    "***\n",
    "The problem that comes with choosing 'k' is the tradeoff:\n",
    "\n",
    "\n",
    "* Higher K: More samples to train, more cross-validation, results in less bias, high variance but requires more computations\n",
    "\n",
    "\n",
    "* Lower K: Less samples to train, less cross-validation, results in more bias, low variance but requires less computations\n",
    "\n",
    "\n",
    "According to paper [A Study of Cross Validation and Bootstrap for Accuracy Estimation and Model Selection](http://robotics.stanford.edu/~ronnyk/accEst.pdf), value of k=10 is a good balance between accuracy and training time.\n",
    "\n",
    "**6.3. Optimum Algorithm**\n",
    "\n",
    "Age old question of 'Which Algorithm to use' is only rivalled by 'What to eat for dinner?'\n",
    "\n",
    "\n",
    "Studying a bunch of algorithms is fascinating and interesting, but choosing which one to use is not! \n",
    "\n",
    "Let's understand which algorithms perform better in which scenarios.\n",
    "\n",
    "***\n",
    "**A perspective from a research paper**\n",
    "\n",
    "\n",
    "In [this](http://jmlr.org/papers/volume15/delgado14a/delgado14a.pdf) paper, the researchers evaluated **179 classifiers** arising from **17 families**, implemented in Weka, R, C and Matlab.\n",
    "\n",
    "They used **121 datasets**, which represent the whole UCI database and other real problems, in order to achieve significant conclusions about the classifier behavior, not dependent on the data set collection.\n",
    "\n",
    "\n",
    "**Key Findings:**\n",
    "\n",
    "* The classifiers most likely to outperform are the random forest (RF) versions, the best of which achieves 94.1% of the maximum accuracy overcoming 90% in the 84.3% (102 out of 121) of the data sets.\n",
    "\n",
    "\n",
    "* The SVM with Gaussian kernel achieves 92.3% of the maximum accuracy.\n",
    "\n",
    "**Paper Summary**\n",
    "\n",
    "The random forest was found to be clearly the best family of classifiers (3 out of 5 best classifiers are RF), followed by SVM (4 classifiers in the top-10), neural networks and boosting ensembles (5 and 3 members in the top-20 respectively).\n",
    "\n",
    "***\n",
    "\n",
    "**Practical Tips**\n",
    "\n",
    "So far from the bunch of algorithms we have learnt, they are of two types.\n",
    "\n",
    "* Linear Models\n",
    "* Ensemble Models\n",
    "\n",
    "\n",
    "\n",
    "The question is then which algorithm to use and when? Let’s have a look at some quick ideas\n",
    "\n",
    "\n",
    "One useful way to decide is using the below chart of `Size v Complexity`\n",
    "\n",
    "![](../images/image35.png)\n",
    "\n",
    "\n",
    "\n",
    "Still, let's understand in a little more detail, the pros and cons of each.\n",
    "\n",
    "###### Linear Models\n",
    "\n",
    "Penalized linear methods have the advantage that they train very quickly. That helps us for 2 reasons\n",
    "\n",
    "* Training times on large data sets can extend to hours, days, or even weeks.\n",
    "\n",
    "* Long training times can stall development and deployment on large problems.\n",
    "\n",
    "Training usually needs to be done several times before a deployable solution is arrived at. Hence, rapid training time for penalized linear methods makes them useful for the obvious reason that shorter is better. However, depending on the problem, these methods may suffer some performance disadvantages relative to ensemble methods.\n",
    "\n",
    "\n",
    "Therefore, penalized linear methods can be a useful first step in your development process even in the circumstance where they yield inferior performance to ensemble methods.\n",
    "\n",
    "\n",
    "###### Ensemble Methods\n",
    "\n",
    "Ensemble methods, on the other hand, bring to the table the ability to work with nonlinear data.\n",
    "We can also easily control the complexity of ensemble models by tuning the hyperparameters\n",
    "\n",
    "\n",
    "Also, ensemble methods come with the ability to tell apart important features from relatively redundant ones(Huge advantage of ensemble methods)\n",
    "\n",
    "\n",
    "Hence, ensemble methods could be used as the final predictors after feature engineering and feature selection has been carried out.\n",
    "\n",
    "Following is a useful chart that summarises the above points\n",
    "\n",
    "![](../images/image34.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
