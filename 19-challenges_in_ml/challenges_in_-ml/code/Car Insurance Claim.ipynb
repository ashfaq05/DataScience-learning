{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Car Insurance Claim\n",
    "\n",
    "As you are working in the insurance company. Company wants to know the reason why claim was not made. Doing so would allow insurance comapny to improve there policy for giving loan to the customer. In this is project you are dealing with various feature such as `age`, `occupation` etc. based on that let's get back to the final conculsion.\n",
    "\n",
    "\n",
    "## About the Dataset:\n",
    "The dataset has details of 10302 Insurance claim with the following 25 features.\n",
    "\n",
    "|Feature|Description|\n",
    "|-------|--------|\n",
    "|ID|Claim ID|\n",
    "|KIDSDRIV|Number of kids person having|\n",
    "|AGE|Age of the customer|\n",
    "|HOMEKIDS|Number of kids in the home|\n",
    "|YOJ|Year of joining of the customer (employee/unemployee)|\n",
    "|INCOME|Anual income of the customer|\n",
    "|PARENT1|parent is alive or not|\n",
    "|HOME_VAL|Home value of the customer|\n",
    "|MSTATUS|Marital status|\n",
    "|GENDER|Male/Female|\n",
    "|EDUCATION|Degree holds by the customer|\n",
    "|OCCUPATION|Job title|\n",
    "|TRAVTIME|Traveling time|\n",
    "|CAR_USE|purpose of the car (private/commercial)|\n",
    "|BLUEBOOK|Legal citation system in the United States|\n",
    "|CAR_TYPE|Type of car(SUV/Pick up)|\n",
    "|RED_CAR|Colour of the car|\n",
    "|OLDCLAIM|Old calim of the car|\n",
    "|CLM_FREQ|Number of times claims taken|\n",
    "|REVOKED|Claim revoked|\n",
    "|MVR_PTS|Claim points|\n",
    "|CLM_AMT|Claim amount|\n",
    "|CAR_AGE|Age of the car|\n",
    "|CLAIM_FLAG|Target variable (YES/NO)|\n",
    "\n",
    "## Why solve this project?\n",
    "\n",
    "This is imbalanced dataset . Here `0 - Claim was not made `, `1 - Claim made`.  After completing this project, you will have the better understanding of how to build deal with imbalanced dataset. In this project, you will apply the following concepts.\n",
    "\n",
    " \n",
    "- Train-test split\n",
    "- Standard scaler\n",
    "- Logistic Regression\n",
    "- SMOTE\n",
    "- feature scaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and cleaning\n",
    "\n",
    "The first step - you know the drill by now - load the dataset and see how it looks like. Additionally, replace the `$` and `,` symbol and split dataset into train and test set. \n",
    "\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "* Load dataset using pandas read_csv api in variable `df` and give file path as `path`.\n",
    "* Display first 5 columns of dataframe `df`.\n",
    "* Print df.info\n",
    "* store the columns ``\n",
    "* Remove the `$` and `,` from columns  `'INCOME','HOME_VAL','BLUEBOOK','OLDCLAIM','CLM_AMT'` which are there in the dataframe\n",
    "\n",
    "* Store all the features(independent values) in  a variable called `X`\n",
    "* Store the target variable `CLAIM_FLAG` (dependent value) in a variable called `y`\n",
    "* Calculate the value counts of target variable and store it in variable `count`\n",
    "* Split the dataframe into `X_train,X_test,y_train,y_test` using `train_test_split()` function. Use `test_size = 0.3` and `random_state = 6 `\n",
    "\n",
    "\n",
    "## Hints:\n",
    "\n",
    "* Use `for col in columns:\n",
    "          df[col].replace({'\\$': '', ',': ''}, regex=True,inplace=True)`\n",
    "    to replace the `$` and `,`\n",
    "\n",
    "\n",
    "## Test case\n",
    "\n",
    "* df:\n",
    "    - check the variable declaration\n",
    "    - check the df.shape == (10302, 25)\n",
    "    - df type == pandas.core.frame.DataFrame\n",
    "    \n",
    "* type(X) == pandas.core.frame.DataFrame\n",
    "* type(y) == pandas.core.frame.Series\n",
    "* X.shape == (10302, 24)\n",
    "* y.shape == (10302, )\n",
    "* variable check X_train,X_test,y_train,y_test,count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('car_insurance_claim.csv')\n",
    "\n",
    "# replace the $ symbol\n",
    "columns = ['INCOME','HOME_VAL','BLUEBOOK','OLDCLAIM','CLM_AMT']\n",
    "\n",
    "for col in columns:\n",
    "    df[col].replace({'\\$': '', ',': ''}, regex=True,inplace=True)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# store independent variable\n",
    "X = df.drop(['CLAIM_FLAG'],axis=1)\n",
    "\n",
    "# store dependent variable\n",
    "y = df['CLAIM_FLAG']\n",
    "\n",
    "# Check the value counts\n",
    "count = y.value_counts()\n",
    "\n",
    "# spliting the dataset\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y ,test_size=0.33,random_state=6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Message \n",
    "\n",
    "Congrats !\n",
    "\n",
    "You have successfully loaded the dataset and split it into `train` and `test` set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Datatype\n",
    "\n",
    "As we can see that because of the `$` symbol most of the fatures are consider as object type. All the values are numeric so we need to convert  it into numeric type. So in this task your are going to cheange the type of the `object` features  to `floating` type. Also lets check is there any null values in the `X_train` and `X_test`\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "* Convert the `'INCOME','HOME_VAL','BLUEBOOK','OLDCLAIM','CLM_AMT'` to floating type in `X_train`.\n",
    "* Convert the `'INCOME','HOME_VAL','BLUEBOOK','OLDCLAIM','CLM_AMT'` to floating type in `X_test`.\n",
    "* Check the null value for `X_train`\n",
    "* Check the null value for `X_test`\n",
    "\n",
    "## Hints:\n",
    "* Use `X_train[['INCOME','HOME_VAL','BLUEBOOK','OLDCLAIM','CLM_AMT']]=X_train[['INCOME','HOME_VAL','BLUEBOOK','OLDCLAIM','CLM_AMT']].astype(float)` to convert object type into floating type\n",
    "\n",
    "## Test Case:\n",
    "\n",
    "* X_train.INCOME.dtype == dtype('float64')\n",
    "* X_test.INCOME.dtype == dtype('float64')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            total_missing  perc_missing\n",
      "ID                      0      0.000000\n",
      "KIDSDRIV                0      0.000000\n",
      "AGE                     3      0.043466\n",
      "HOMEKIDS                0      0.000000\n",
      "YOJ                   375      5.433208\n",
      "INCOME                375      5.433208\n",
      "PARENT1                 0      0.000000\n",
      "HOME_VAL              382      5.534628\n",
      "MSTATUS                 0      0.000000\n",
      "GENDER                  0      0.000000\n",
      "EDUCATION               0      0.000000\n",
      "OCCUPATION            451      6.534338\n",
      "TRAVTIME                0      0.000000\n",
      "CAR_USE                 0      0.000000\n",
      "BLUEBOOK                0      0.000000\n",
      "TIF                     0      0.000000\n",
      "CAR_TYPE                0      0.000000\n",
      "RED_CAR                 0      0.000000\n",
      "OLDCLAIM                0      0.000000\n",
      "CLM_FREQ                0      0.000000\n",
      "REVOKED                 0      0.000000\n",
      "MVR_PTS                 0      0.000000\n",
      "CLM_AMT                 0      0.000000\n",
      "CAR_AGE               420      6.085193\n",
      "            total_missing  perc_missing\n",
      "ID                      0      0.000000\n",
      "KIDSDRIV                0      0.000000\n",
      "AGE                     3      0.088235\n",
      "HOMEKIDS                0      0.000000\n",
      "YOJ                   375     11.029412\n",
      "INCOME                375     11.029412\n",
      "PARENT1                 0      0.000000\n",
      "HOME_VAL              382     11.235294\n",
      "MSTATUS                 0      0.000000\n",
      "GENDER                  0      0.000000\n",
      "EDUCATION               0      0.000000\n",
      "OCCUPATION            451     13.264706\n",
      "TRAVTIME                0      0.000000\n",
      "CAR_USE                 0      0.000000\n",
      "BLUEBOOK                0      0.000000\n",
      "TIF                     0      0.000000\n",
      "CAR_TYPE                0      0.000000\n",
      "RED_CAR                 0      0.000000\n",
      "OLDCLAIM                0      0.000000\n",
      "CLM_FREQ                0      0.000000\n",
      "REVOKED                 0      0.000000\n",
      "MVR_PTS                 0      0.000000\n",
      "CLM_AMT                 0      0.000000\n",
      "CAR_AGE               420     12.352941\n"
     ]
    }
   ],
   "source": [
    "# Convert object type to float on X_train\n",
    "X_train[['INCOME','HOME_VAL','BLUEBOOK','OLDCLAIM','CLM_AMT']]=X_train[['INCOME','HOME_VAL','BLUEBOOK','OLDCLAIM','CLM_AMT']].astype(float)\n",
    "\n",
    "# Convert object type to float on X_test\n",
    "X_test[['INCOME','HOME_VAL','BLUEBOOK','OLDCLAIM','CLM_AMT']]=X_test[['INCOME','HOME_VAL','BLUEBOOK','OLDCLAIM','CLM_AMT']].astype(float)\n",
    "\n",
    "# Missing values in X_train\n",
    "print(pd.DataFrame({'total_missing': X_train.isnull().sum(), 'perc_missing': (X_train.isnull().sum()/6902)*100}))\n",
    "\n",
    "# Missing values in X_test\n",
    "print(pd.DataFrame({'total_missing': X_train.isnull().sum(), 'perc_missing': (X_train.isnull().sum()/3400)*100}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Message:\n",
    "\n",
    "Congratulations!\n",
    "\n",
    "You have successfully coverted datatype `object` to datatype `float`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with the missing values\n",
    "\n",
    "\n",
    "Dealing with the missing value is very important. If the feature is having less number of missing value we will remove the row which contain missing value. Also we are going to fill null value of the numerical variable with `mean`. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Obervation:\n",
    "\n",
    "* We can see that the features `['YOJ','OCCUPATION']`  varies person to person. We can not deal with that type of missing value so we are going to remove the row from this column.\n",
    "* `AGE`,`CAR_AGE`,`INCOME` and `HOME_VAL` contains the numerical values.\n",
    "\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "* Drop the rows from columns `['YOJ','OCCUPATION']` which contains the `NaN` values from `X_train`\n",
    "* Drop the rows from columns `['YOJ','OCCUPATION']` which contains the `NaN` values from `X_test`\n",
    "* Drop the index from y_train `y_train[X_train.index]` and store it in variable `y_train`\n",
    "* Drop the index from y_test `y_test[X_train.index]` and store it in variable `y_test`\n",
    "* Fill the missing values for columns `AGE`,`CAR_AGE`,`INCOME` and `HOME_VAL` with mean on `X_train` and use `inplace = True`.\n",
    "* Fill the missing values for columns `AGE`,`CAR_AGE`,`INCOME` and `HOME_VAL` with mean on `X_test` and use `inplace = True`.\n",
    "\n",
    "\n",
    "## Hints:\n",
    "\n",
    "* Use `X_train.dropna(subset=['YOJ','OCCUPATION'],inplace=True)` to drop the rows.\n",
    "* Use `X_train['AGE'].fillna((X_train['AGE'].mean()), inplace=True)` to fill the missing values with the mean.\n",
    "\n",
    "\n",
    "\n",
    "## Testcase:\n",
    "\n",
    "* X_train.shape == (6101, 24)\n",
    "* X_test.shape == (3024, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop missing values\n",
    "X_train.dropna(subset=['YOJ','OCCUPATION'],inplace=True)\n",
    "X_test.dropna(subset=['YOJ','OCCUPATION'],inplace=True)\n",
    "\n",
    "\n",
    "y_train=y_train[X_train.index]\n",
    "y_test=y_test[X_test.index]\n",
    "\n",
    "\n",
    "\n",
    "# fill missing values with mean\n",
    "X_train['AGE'].fillna((X_train['AGE'].mean()), inplace=True)\n",
    "X_test['AGE'].fillna((X_test['AGE'].mean()), inplace=True)\n",
    "\n",
    "X_train['CAR_AGE'].fillna((X_train['CAR_AGE'].mean()), inplace=True)\n",
    "X_test['CAR_AGE'].fillna((X_test['CAR_AGE'].mean()), inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "X_train['INCOME'].fillna((X_train['INCOME'].mean()), inplace=True)\n",
    "X_test['INCOME'].fillna((X_test['INCOME'].mean()), inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "X_train['HOME_VAL'].fillna((X_train['HOME_VAL'].mean()), inplace=True)\n",
    "X_test['HOME_VAL'].fillna((X_test['HOME_VAL'].mean()), inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Message:\n",
    "\n",
    "Congrats!\n",
    "\n",
    "You have successfully deal with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the categorical values to numeric value\n",
    "\n",
    "\n",
    "You can see that some of the features of `PARENT1`, `MSTATUS`, `GENDER`, `EDUCATION`, `OCCUPATION`, `CAR_USE`, `CAR_TYPE`, `RED_CAR`  and `REVOKED` in the data are textual in nature but any prediction model only work well in the numerical data so we need to  convert that features into the numerical format. Let's convert them using label  encoding.\n",
    "\n",
    "\n",
    "\n",
    "## Instruction:\n",
    "\n",
    "* You have given the `columns`\n",
    "* Apply the `for` loop on the columns. \n",
    "* Instantiate lable encoder and store it in variable `le`\n",
    "* `fit_transform` lable encoder on `X_train` use `astype(str)`.\n",
    "* `transform` label encoder on `X_test` use `astype(str)`.\n",
    "\n",
    "## Hints:\n",
    "\n",
    "* Use `X_train[col]=le.fit_transform(X_train[col].astype(str))` to `fit_transform` on X_train.\n",
    "\n",
    "## Test Case:\n",
    "\n",
    "* X_test.OCCUPATION[105] == 2\n",
    "* X_train.OCCUPATION[7595] == 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Columns are given\n",
    "columns = [\"PARENT1\",\"MSTATUS\",\"GENDER\",\"EDUCATION\",\"OCCUPATION\",\"CAR_USE\",\"CAR_TYPE\",\"RED_CAR\",\"REVOKED\"]\n",
    "\n",
    "# Code starts here\n",
    "for col in columns:\n",
    "    # Instantiate label encoder\n",
    "    le = LabelEncoder()\n",
    "    # fit and transform label encoder on X_train\n",
    "    X_train[col]=le.fit_transform(X_train[col].astype(str))\n",
    "    # transform label encoder on X_test\n",
    "    X_test[col]=le.transform(X_test[col].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Message:\n",
    "\n",
    "Congratulations!\n",
    "\n",
    "You have successfully applied label encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction check\n",
    "\n",
    "Now let's come to the actual task, using logistic regression to predict that whether the person is eligible for `CLAIM`. Here as bank employee our main focus is whether to give insurance to that person or not. \n",
    "\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "\n",
    "- Instantiate a logistic regression model with `LogisticRegression()` and save it to a variable called `'model'`.\n",
    "\n",
    "- Fit the model on the training data `X_train and y_train`.\n",
    "- Make predictions on the `X_test` features and save the results in a variable called `'y_pred'`.\n",
    "- Calculate the `accuracy_score` and store it in variable `score`\n",
    "- Calculate the `precision_score` and store it in variable `precision`\n",
    "\n",
    "## Hint :\n",
    "\n",
    "* Use `accuracy_score(y_test, y_pred)` to calculate the `accuracy_score`.\n",
    "\n",
    "\n",
    "\n",
    "## Test case :\n",
    "\n",
    "- check the variable `model`,`score`,`y_pred`\n",
    "- lr == LogisticRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
    "- np.round(score,2) == np.round(0.7423941798941799,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7423941798941799\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "# code starts here \n",
    "\n",
    "# Instantiate logistic regression\n",
    "model = LogisticRegression(random_state = 6)\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# predict the result\n",
    "y_pred =model.predict(X_test)\n",
    "\n",
    "# calculate the f1 score\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(score)\n",
    "\n",
    "# calculate the precision score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(precision)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Message:\n",
    "\n",
    "Congrats!\n",
    "You have successfully applied `Logistic Regression Model`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Imbalnced data\n",
    "\n",
    "As on the above task, we have seen that `73%` claim was not made  and `27%` claim made. So if you applied model on this dataset it will give us a bad prediction. To overcome we need to use the technic Oversampling or Undersampling technic. Oversampling in data analysis is techniques used to adjust the class distribution of an imbalanced dataset. In this task, you are going to apply the `SMOTE` to adjust the class distribution of the data set. While working with the learning model, it is important to scale the features to a range which is centered around zero so that the variance of the features are in the same range. If the feature’s variance is orders of magnitude more than the variance of other features, that particular feature might dominate other features in the dataset and our model will not train well which gives us bad model\n",
    "\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "- Instantiate a `SMOTE` with `SMOTE(random state = 6)` and save it to a variable called `'smote'`.\n",
    "- fit the sample on `X_train , y_train` and store it in variable `X_train` and `y_train`.\n",
    "- Instantiate a `StandardScaler` with `StandardScaler()` and save it to a variable called `'scaler'`.\n",
    "- Fit and transform it on `X_train`and store it in variable `X_train`.\n",
    "- Transform it on `X_test` and store it in variable `X_test`.\n",
    "\n",
    "\n",
    "## Hints:\n",
    "\n",
    "* Use `X_train,y_train = smote.fit_sample(X_train, y_train)` to fit the samples on training set.\n",
    "* Use `scaler.fit_transform(X_train)` to do the fit and transform operation.\n",
    "\n",
    "## Test case:\n",
    "- variable check `scaler`,`X_train`,`X_test`\n",
    "- variable check `smote`, `X_train`, `y_train`\n",
    "- X_train.shape == (8896, 24)\n",
    "- y_train.shape == (8896,)\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# code starts here\n",
    "\n",
    "# Instantiate SMOTE \n",
    "smote = SMOTE(random_state=9)\n",
    "\n",
    "# fit smote on training set\n",
    "X_train, y_train = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "# code ends here\n",
    "\n",
    "# Instantiate a standardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply transform to the test set.\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Message:\n",
    "\n",
    "Congratulations!\n",
    "\n",
    "\n",
    "Now you know how to deal with imbanlaced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Check\n",
    "\n",
    "In the previous task we applied the model without doing any operation on imbalanced data. Now lets apply `Logistic regression ` and check the accuracy.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "\n",
    "- Instantiate a logistic regression model with `LogisticRegression()` and save it to a variable called `'model'`.\n",
    "\n",
    "- Fit the model on the training data `X_train and y_train`.\n",
    "- Make predictions on the `X_test` features and save the results in a variable called `'y_pred'`.\n",
    "- Calculate the `accuracy_score` and store it in variable `score`\n",
    "\n",
    "\n",
    "## Hint :\n",
    "\n",
    "* Use `accuracy_score(y_test, y_pred)` to calculate the `accuracy_score`.\n",
    "\n",
    "\n",
    "\n",
    "## Test case :\n",
    "\n",
    "- check the variable `model`,`score`,`y_pred`\n",
    "- lr == LogisticRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
    "- np.round(score,2) == np.round(0.9897486772486772,2)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9887566137566137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score,confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "# code starts here \n",
    "\n",
    "# Instantiate logistic regression\n",
    "model = LogisticRegression(random_state = 6)\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# predict the result\n",
    "y_pred =model.predict(X_test)\n",
    "\n",
    "# calculate the f1 score\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(score)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Message:\n",
    "\n",
    "You have successfully deal with the imbalanced dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
